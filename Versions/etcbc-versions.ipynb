{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"right\" src=\"tf-small.png\"/>\n",
    "\n",
    "# ETCBC versions\n",
    "\n",
    "In this notebook we try to map the nodes between the versions 4, 4b and 4c of the ETCBC dataset.\n",
    "\n",
    "If we succeed, then text-fabric notebooks that are based on an older version of the data, can also be used unmodified on newer versions of the data.\n",
    "\n",
    "In general, node mappings between versions can not be perfect. We try and see how far we get.\n",
    "\n",
    "Let us start with *slot* mappings.\n",
    "We map the slots of a version to the slots of the next version.\n",
    "Mappings go from old to new, and they are between successive versions.\n",
    "\n",
    "We have data in text-fabric format for the ETCBC Hebrew Bible Database, versions 4, 4b, and 4c.\n",
    "\n",
    "Stephen Ku has prepared a Strong number mapping for version 4, based on \n",
    "[OpenScriptures Bible Lexicon](https://github.com/openscriptures/HebrewLexicon).\n",
    "\n",
    "This provides us with a nice use case: can we apply the Strong number mapping for version 4 to versions 4b and 4c\n",
    "as well?\n",
    "See notebook\n",
    "[strong](https://github.com/ETCBC/text-fabric/blob/master/Versions/strong.ipynb)\n",
    "for how we add Strong numbers to the ETCBC dataset.\n",
    "\n",
    "Below we will get a pretty good view on the differences between the versions.\n",
    "We use the\n",
    "[ETCBC transcription](https://shebanq.ancient-data.org/shebanq/static/docs/ETCBC4-transcription.pdf)\n",
    "to write down the diffs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os,collections\n",
    "from tf.fabric import Fabric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load all versions in one go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Text-Fabric 2.2.1\n",
      "Api reference : https://github.com/ETCBC/text-fabric/wiki/Api\n",
      "Tutorial      : https://github.com/ETCBC/text-fabric/blob/master/docs/tutorial.ipynb\n",
      "Data sources  : https://github.com/ETCBC/text-fabric-data\n",
      "Data docs     : https://etcbc.github.io/text-fabric-data\n",
      "Shebanq docs  : https://shebanq.ancient-data.org/text\n",
      "Slack team    : https://shebanq.slack.com/signup\n",
      "Questions? Ask shebanq@ancient-data.org for an invite to Slack\n",
      "110 features found and 0 ignored\n",
      "  0.00s loading features ...\n",
      "   |     0.16s B g_word               from /Users/dirk/github/text-fabric-data-legacy/hebrew/etcbc4\n",
      "   |     0.13s B lex                  from /Users/dirk/github/text-fabric-data-legacy/hebrew/etcbc4\n",
      "   |     0.00s Feature overview: 105 nodes; 4 edges; 1 configs; 7 computeds\n",
      "  5.19s All features loaded/computed - for details use loadLog()\n",
      "This is Text-Fabric 2.2.1\n",
      "Api reference : https://github.com/ETCBC/text-fabric/wiki/Api\n",
      "Tutorial      : https://github.com/ETCBC/text-fabric/blob/master/docs/tutorial.ipynb\n",
      "Data sources  : https://github.com/ETCBC/text-fabric-data\n",
      "Data docs     : https://etcbc.github.io/text-fabric-data\n",
      "Shebanq docs  : https://shebanq.ancient-data.org/text\n",
      "Slack team    : https://shebanq.slack.com/signup\n",
      "Questions? Ask shebanq@ancient-data.org for an invite to Slack\n",
      "111 features found and 0 ignored\n",
      "  0.00s loading features ...\n",
      "   |     0.16s B g_word               from /Users/dirk/github/text-fabric-data-legacy/hebrew/etcbc4b\n",
      "   |     0.15s B lex                  from /Users/dirk/github/text-fabric-data-legacy/hebrew/etcbc4b\n",
      "   |     0.00s Feature overview: 105 nodes; 5 edges; 1 configs; 7 computeds\n",
      "  6.07s All features loaded/computed - for details use loadLog()\n",
      "This is Text-Fabric 2.2.1\n",
      "Api reference : https://github.com/ETCBC/text-fabric/wiki/Api\n",
      "Tutorial      : https://github.com/ETCBC/text-fabric/blob/master/docs/tutorial.ipynb\n",
      "Data sources  : https://github.com/ETCBC/text-fabric-data\n",
      "Data docs     : https://etcbc.github.io/text-fabric-data\n",
      "Shebanq docs  : https://shebanq.ancient-data.org/text\n",
      "Slack team    : https://shebanq.slack.com/signup\n",
      "Questions? Ask shebanq@ancient-data.org for an invite to Slack\n",
      "107 features found and 0 ignored\n",
      "  0.00s loading features ...\n",
      "   |     0.17s B g_word               from /Users/dirk/github/text-fabric-data/hebrew/etcbc4c\n",
      "   |     0.16s B lex                  from /Users/dirk/github/text-fabric-data/hebrew/etcbc4c\n",
      "   |     0.00s Feature overview: 102 nodes; 4 edges; 1 configs; 7 computeds\n",
      "  5.73s All features loaded/computed - for details use loadLog()\n"
     ]
    }
   ],
   "source": [
    "locations = {\n",
    "    '4': '~/github/text-fabric-data-legacy',\n",
    "    '4b': '~/github/text-fabric-data-legacy',\n",
    "    '4c': '~/github/text-fabric-data', \n",
    "}\n",
    "versions = ['4', '4b', '4c']\n",
    "TF = {}\n",
    "api = {}\n",
    "for v in versions:\n",
    "    TF[v] = Fabric(locations=locations[v], modules='hebrew/etcbc{}'.format(v))\n",
    "    api[v] = TF[v].load('''\n",
    "        g_word lex\n",
    "    ''')\n",
    "A4 = api['4']\n",
    "A4b = api['4b']\n",
    "A4c = api['4c']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the amount of slots in all versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'4': 426555, '4b': 426568, '4c': 426581}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nSlots = {}\n",
    "for v in versions:\n",
    "    nSlots[v] = api[v].F.otype.maxSlot\n",
    "nSlots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method\n",
    "\n",
    "When we compare two versions, we inspect the lexemes found at corresponding positions in the versions.\n",
    "We start at the beginning, and when the lexemes do not match, we have a closer look.\n",
    "\n",
    "However, in order not to be disturbed by minor discrepancies in the lexemes, we mask the lexemes: we\n",
    "apply a few transformations to it, such as removing alefs and waws, and finally even turning them into\n",
    "ordered sets of letters, thereby loosing the order and multiplicity of letter.\n",
    "We also strip the disambiguation marks.\n",
    "\n",
    "We maintain a current mapping between the slots of the two versions, and we update it if we encounter\n",
    "disturbances. \n",
    "Initially, this map is the identity map.\n",
    "\n",
    "What we encounter as remaining differences boils down to the following:\n",
    "\n",
    "* a lexeme is split into two lexemes with the same total material, typically involving `H`, `MN`, or `B`\n",
    "* the lexeme is part of a special case, listed in the `cases` table (which has been found by repeatedly\n",
    "  chasing for the first remaining difference.\n",
    "* the both lexemes differ, but that's it, no map updates have to be done.\n",
    "  \n",
    "The first two types of cases can be solved by splitting a lexeme into `k` parts or combining `k` lexemes into one.\n",
    "After that the mapping has to be shifted to the right or to the left from a certain point onwards.\n",
    "\n",
    "The loop then is as follows:\n",
    "\n",
    "* find the first slot with a lexeme in the first version that is different from the lexeme at the mapped slot\n",
    "  in the second version\n",
    "* analyse what is the case:\n",
    "  * if the disturbance is recognized on the basis of existing patterns and cases, update the map and\n",
    "    consider this case solved\n",
    "  * if the disturbance is not recognized, the case is unsolved, and we break out of the loop.\n",
    "    More analysis is needed, and the outcome of that has to be coded as an extra pattern or case.\n",
    "* if the status is solved, go back to the first step\n",
    "\n",
    "We end up with a mapping from the slots of the first version to those of the other version that links\n",
    "slots with approximately equal lexemes together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by defining our masking function, and compile lists of all lexemes and masked lexemes for all versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.00s Masking lexemes\n",
      "   |     2.72s version 4 done\n",
      "   |     2.67s version 4b done\n",
      "   |     2.73s version 4c done\n",
      "  8.12s Done\n"
     ]
    }
   ],
   "source": [
    "masks = [\n",
    "    (lambda lex: lex.rstrip('[/='),                         'strip disambiguation'),\n",
    "    (lambda lex: lex[0:-2] if lex.endswith('JM') else lex,  'remove JM'),\n",
    "    (lambda lex: lex[0:-2] if lex.endswith('WT') else lex,  'remove WT'),\n",
    "    (lambda lex: lex.rstrip('HT'),                          'strip HT'),\n",
    "    (lambda lex: lex.replace('J', ''),                      'remove J'),\n",
    "    (lambda lex: lex.replace('>', ''),                      'remove Alef'),\n",
    "    (lambda lex: lex.replace('W', ''),                      'remove W'),\n",
    "    (lambda lex: lex.replace('Z', 'N'),                     'identify Z and N'),\n",
    "    (lambda lex: (''.join(sorted(set(set(lex)))))+'_'*lex.count('_'), 'ignore order and multiplicity'),\n",
    "]\n",
    "\n",
    "def mask(lex, trans=None):\n",
    "    if trans != None:\n",
    "        return masks[trans][0](lex)\n",
    "    for (fun, desc) in masks:\n",
    "        lex = fun(lex)\n",
    "    return lex\n",
    "\n",
    "lexemes = {}\n",
    "\n",
    "A4.indent(level=0, reset=True)\n",
    "A4.info('Masking lexemes')\n",
    "for v in versions:\n",
    "    A4.indent(level=1, reset=True)\n",
    "    lexemes[v] = collections.OrderedDict()\n",
    "    for n in api[v].F.otype.s('word'):\n",
    "        lex = api[v].F.lex.v(n)\n",
    "        lexemes[v][n] = (lex, mask(lex, trans=0), mask(lex))\n",
    "    A4.info('version {} done'.format(v))\n",
    "A4.indent(level=0)\n",
    "A4.info('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `cases` we store special cases that we stumbled upon.\n",
    "Every time we encountered a disturbance which did not follow a recognized pattern,\n",
    "we turned it into a case.\n",
    "The number is the slot number in the first version where the case will be applied.\n",
    "Cases will only be applied at these exact slot number and nowhere else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cases = {}\n",
    "mappings = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm\n",
    "\n",
    "Here is the code that directly implements the method.\n",
    "Every pair of distinct versions can be mapped.\n",
    "We store the mappings in a dictionary, keyed by tuples like `(4, 4b)`, \n",
    "for the mapping from version `4` to `4b`, for instance.\n",
    "\n",
    "The loop is in `doDiffs` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inspect(v1, v2, start, end):\n",
    "    mapKey = (v1, v2)\n",
    "    mp = mappings[mapKey]\n",
    "    for n in range(start, end):\n",
    "        print('{:>6}: {:<8} {:<8}'.format(\n",
    "            n, \n",
    "            api[v1].F.lex.v(n),\n",
    "            api[v2].F.lex.v(mp[n]),\n",
    "\n",
    "        ))\n",
    "\n",
    "def firstDiff(v1, v2, start):\n",
    "    mapKey = (v1, v2)\n",
    "    mp = mappings[mapKey]\n",
    "\n",
    "    fDiff = None\n",
    "    for (n, (lx1, sxl, mx1)) in lexemes[v1].items():\n",
    "        if n < start: continue\n",
    "        if mx1 != lexemes[v2][mp[n]][2]:\n",
    "            fDiff = n\n",
    "            break\n",
    "    return fDiff\n",
    "\n",
    "def printDiff(v1, v2, n):\n",
    "    mapKey = (v1, v2)\n",
    "    mp = mappings[mapKey]\n",
    "\n",
    "    (lx1, sx1, mx1) = lexemes[v1][n]\n",
    "    (lx2, sx2, mx2) = lexemes[v2][mp[n]]\n",
    "    if n < api[v1].F.otype.maxSlot:\n",
    "        (lx1n, sx1n, mx1n) = lexemes[v1][n+1]\n",
    "    else:\n",
    "        (lx1n, sx1n, mx1n) = ('max', 'max', 'max')\n",
    "    if mp[n] < api[v2].F.otype.maxSlot:\n",
    "        (lx2n, sx2n, mx2n) = lexemes[v2][mp[n+1]]\n",
    "    else:\n",
    "        (lx2n, sx2n, mx2n) = ('max', 'max', 'max')\n",
    "    if n > 1:\n",
    "        (lx1p, sx1p, mx1p) = lexemes[v1][n-1]\n",
    "    else:\n",
    "        (lx1p, sx1p, mx1p) = ('min', 'min', 'min')\n",
    "    if mp[n] > 1:\n",
    "        (lx2p, sx2p, mx2p) = lexemes[v2][mp[n-1]]\n",
    "    else:\n",
    "        (lx2p, sx2p, mx2p) = ('min', 'min', 'min')\n",
    "\n",
    "    #print('''{} {}:{} ==> slot {} ==> {}\n",
    "    #{:<2}: {:<6} ~ |{:<6}| ~ {:<6}   {:<6} ~ |{:<6}| ~ {:<6}   {:<6} ~ |{:<6}| {:<6}\n",
    "    #{:<2}: {:<6} ~ |{:<6}| ~ {:<6}   {:<6} ~ |{:<6}| ~ {:<6}   {:<6} ~ |{:<6}| {:<6}'''.format(\n",
    "    #    *api[v1].T.sectionFromNode(n),\n",
    "    #    n, mp[n],\n",
    "    #    v1, lx1p, lx1, lx1n, sx1p, sx1, sx1n, mx1p, mx1, mx1n,\n",
    "    #    v2, lx2p, lx2, lx2n, sx2p, sx2, sx2n, mx2p, mx2, mx2n,\n",
    "    #)) \n",
    "    print('''{} {}:{} ==> slot {} ==> {}\n",
    "    {:<2}: {:<8} ~ |{:<8}| ~ {:<8}\n",
    "    {:<2}: {:<8} ~ |{:<8}| ~ {:<8}'''.format(\n",
    "        *api[v1].T.sectionFromNode(n),\n",
    "        n, mp[n],\n",
    "        v1, lx1p, lx1, lx1n, \n",
    "        v2, lx2p, lx2, lx2n,\n",
    "    )) \n",
    "\n",
    "\n",
    "MAX_ITER = 100\n",
    "\n",
    "def doDiffs(v1, v2):\n",
    "    mapKey = (v1, v2)\n",
    "    mappings[mapKey] = dict(((n, n) for n in api[v1].F.otype.s('word')))\n",
    "    mp = mappings[mapKey]\n",
    "    cs = cases.get(mapKey, {})\n",
    "    it = 0\n",
    "    start = 1\n",
    "    while True:\n",
    "        n = firstDiff(v1, v2, start)\n",
    "\n",
    "        if n == None:\n",
    "            print('No more differences.\\nFound {} points of disturbance'.format(it))\n",
    "            break\n",
    "\n",
    "        if it > MAX_ITER: \n",
    "            print('There might be more disturbances: increase MAX_ITER')\n",
    "            break\n",
    "            \n",
    "        it += 1\n",
    "\n",
    "        printDiff(v1, v2, n)\n",
    "\n",
    "        (lx1, sx1, mx1) = lexemes[v1][n]\n",
    "        (lx2, sx2, mx2) = lexemes[v2][mp[n]]\n",
    "        (lx1n, sx1n, mx1n) = lexemes[v1][n+1]\n",
    "        (lx2n, sx2n, mx2n) = lexemes[v2][mp[n+1]]\n",
    "\n",
    "        solved = None\n",
    "        skip = 0\n",
    "        if n in cs:\n",
    "            (action, param) = cs[n]\n",
    "            if action == 'collapse':\n",
    "                solved = '{} {} slots'.format(action, param)\n",
    "                skip = param\n",
    "                for m in range(api[v1].F.otype.maxSlot, n + param -1, -1):\n",
    "                    mp[m] = mp[m-param+1]\n",
    "                for m in range(n+1, n+param):\n",
    "                    mp[m] = mp[n]\n",
    "            elif action == 'split':\n",
    "                solved = '{} into {} slots'.format(action, param)\n",
    "                for m in range(n+1, api[v1].F.otype.maxSlot+1):\n",
    "                    mp[m] = mp[m] + param -1\n",
    "            elif action == 'ok':\n",
    "                solved = 'innocent variation in lexeme'\n",
    "        elif lx1 == lx2 + lx2n:\n",
    "            if lx2 == 'H':\n",
    "                solved = 'split article off'\n",
    "                for m in range(n+1, api[v1].F.otype.maxSlot+1):\n",
    "                    mp[m] = mp[m] + 1\n",
    "        elif set(mx1) == set(mx2) | set(mx2n):\n",
    "            if lx2 == 'B' or lx2 == 'MN':\n",
    "                solved = 'split preposition off'\n",
    "                for m in range(n+1, api[v1].F.otype.maxSlot+1):\n",
    "                    mp[m] = mp[m] + 1\n",
    "        print('Action: {}\\n'.format(solved if solved else 'BLOCKED'))\n",
    "\n",
    "        if not solved: break\n",
    "        \n",
    "        start = n + 1 + skip\n",
    "\n",
    "    if not solved:\n",
    "        print('Blocking difference in {} iterations'.format(it))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mappings itself are needed elsewhere in Text-Fabric, let us write them to file.\n",
    "We write them into the dataset corresponding to the target version.\n",
    "So the map `4-4b` ends up in dataset `etcbc4b`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def writeMaps():\n",
    "    for ((v1, v2), mp) in mappings.items():\n",
    "        module = 'hebrew/etcbc{}'.format(v2)\n",
    "        fName = 'omap@{}-{}'.format(v1, v2)\n",
    "        edgeFeatures = {\n",
    "            fName: dict(((n, (mp[n],)) for n in range(1, api[v1].F.otype.maxSlot + 1)))\n",
    "        }\n",
    "        metaData = {\n",
    "            fName: {\n",
    "                'about': 'Mapping from the slots of ETCBC version {} to version {}'.format(v1, v2),\n",
    "                'see': 'https://github.com/ETCBC/text-fabric/blob/master/Versions/etcbc-versions.ipynb',\n",
    "                'valueType': 'str',\n",
    "            }\n",
    "        }\n",
    "        TF[v2].save(\n",
    "            nodeFeatures={},\n",
    "            edgeFeatures=edgeFeatures,\n",
    "            metaData=metaData,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running\n",
    "\n",
    "Here we run the mapping between `4` and `4b`.\n",
    "The points of disturbance will be written into the output cell.\n",
    "\n",
    "## 4 => 4b\n",
    "\n",
    "Here are the special cases for this conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cases.update({\n",
    "    ('4', '4b'): {\n",
    "        214730: ('collapse', 4),\n",
    "        260028: ('split', 2),\n",
    "        289948: ('ok', None),\n",
    "        307578: ('split', 2),\n",
    "        323067: ('ok', None),\n",
    "        407543: ('split', 2),\n",
    "        408429: ('split', 2),\n",
    "    },\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genesis 24:65 ==> slot 12369 ==> 12369\n",
      "    4 : >JC/     ~ |HLZH    | ~ H       \n",
      "    4b: >JC/     ~ |H       | ~ LZH     \n",
      "Action: split article off\n",
      "\n",
      "Genesis 37:19 ==> slot 20514 ==> 20515\n",
      "    4 : XLWM/    ~ |HLZH    | ~ BW>[    \n",
      "    4b: XLWM/    ~ |H       | ~ LZH     \n",
      "Action: split article off\n",
      "\n",
      "Judges 6:20 ==> slot 130846 ==> 130848\n",
      "    4 : SL</     ~ |HLZ     | ~ W       \n",
      "    4b: SL</     ~ |H       | ~ LZ      \n",
      "Action: split article off\n",
      "\n",
      "1_Samuel 14:1 ==> slot 148319 ==> 148322\n",
      "    4 : <BR/     ~ |HLZ     | ~ W       \n",
      "    4b: <BR/     ~ |H       | ~ LZ      \n",
      "Action: split article off\n",
      "\n",
      "1_Samuel 17:26 ==> slot 151331 ==> 151335\n",
      "    4 : PLCTJ/   ~ |HLZ     | ~ W       \n",
      "    4b: PLCTJ/   ~ |H       | ~ LZ      \n",
      "Action: split article off\n",
      "\n",
      "1_Samuel 20:19 ==> slot 153816 ==> 153821\n",
      "    4 : >BN/     ~ |H>ZL/   | ~ W       \n",
      "    4b: >BN/     ~ |H       | ~ >ZL/    \n",
      "Action: split article off\n",
      "\n",
      "2_Kings 4:25 ==> slot 196975 ==> 196981\n",
      "    4 : CWNMJ/   ~ |HLZ     | ~ <TH     \n",
      "    4b: CWNMJ/   ~ |H       | ~ LZ      \n",
      "Action: split article off\n",
      "\n",
      "2_Kings 23:17 ==> slot 210326 ==> 210333\n",
      "    4 : YJWN=/   ~ |HLZ     | ~ >CR     \n",
      "    4b: YJWN=/   ~ |H       | ~ LZ      \n",
      "Action: split article off\n",
      "\n",
      "Isaiah 8:1 ==> slot 214730 ==> 214738\n",
      "    4 : L        ~ |MHR[    | ~ CLL/    \n",
      "    4b: L        ~ |MHR_CLL_XC_BZ/| ~ W       \n",
      "Action: collapse 4 slots\n",
      "\n",
      "Jeremiah 46:20 ==> slot 260028 ==> 260033\n",
      "    4 : <GLH/    ~ |JPHPJ/  | ~ MYRJM/  \n",
      "    4b: <GLH/    ~ |JPH/    | ~ PJH/    \n",
      "Action: split into 2 slots\n",
      "\n",
      "Ezekiel 16:7 ==> slot 271124 ==> 271130\n",
      "    4 : BW>[     ~ |B<D/    | ~ <DJ/    \n",
      "    4b: BW>[     ~ |B       | ~ <DJ/    \n",
      "Action: split preposition off\n",
      "\n",
      "Ezekiel 36:35 ==> slot 283104 ==> 283111\n",
      "    4 : >RY/     ~ |HLZW    | ~ H       \n",
      "    4b: >RY/     ~ |H       | ~ LZW     \n",
      "Action: split article off\n",
      "\n",
      "Ezekiel 47:13 ==> slot 289948 ==> 289956\n",
      "    4 : JHWH/    ~ |ZH      | ~ GBWL/   \n",
      "    4b: JHWH/    ~ |G>/     | ~ GBWL/   \n",
      "Action: innocent variation in lexeme\n",
      "\n",
      "Zechariah 2:8 ==> slot 305480 ==> 305488\n",
      "    4 : N<R/     ~ |HLZ     | ~ L       \n",
      "    4b: N<R/     ~ |H       | ~ LZ      \n",
      "Action: split article off\n",
      "\n",
      "Zechariah 9:8 ==> slot 307578 ==> 307587\n",
      "    4 : BJT/     ~ |MYBH=/  | ~ MN      \n",
      "    4b: BJT/     ~ |MN      | ~ YB>/    \n",
      "Action: split into 2 slots\n",
      "\n",
      "Psalms 75:7 ==> slot 323067 ==> 323077\n",
      "    4 : MDBR/    ~ |RWM[    | ~ KJ      \n",
      "    4b: MDBR/    ~ |HR/     | ~ KJ      \n",
      "Action: innocent variation in lexeme\n",
      "\n",
      "Daniel 8:16 ==> slot 375529 ==> 375539\n",
      "    4 : L        ~ |HLZ     | ~ >T      \n",
      "    4b: L        ~ |H       | ~ LZ      \n",
      "Action: split article off\n",
      "\n",
      "2_Chronicles 2:12 ==> slot 407543 ==> 407554\n",
      "    4 : L        ~ |XWRM_>BJ/| ~ BN/     \n",
      "    4b: L        ~ |XWRM/   | ~ >B/     \n",
      "Action: split into 2 slots\n",
      "\n",
      "2_Chronicles 4:16 ==> slot 408429 ==> 408441\n",
      "    4 : <FH[     ~ |XWRM_>BJ/| ~ L       \n",
      "    4b: <FH[     ~ |XWRM/   | ~ >B/     \n",
      "Action: split into 2 slots\n",
      "\n",
      "No more differences.\n",
      "Found 19 points of disturbance\n"
     ]
    }
   ],
   "source": [
    "doDiffs('4', '4b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just have a look at the first point of disturbance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genesis 24:65 node 12370: H versus LZH becomes H\n"
     ]
    }
   ],
   "source": [
    "(v1, v2) = ('4', '4b')\n",
    "(n, m) = [x for x in mappings[(v1, v2)].items() if x[0] != x[1]][0]\n",
    "print('{} {}:{} node {}: {} versus {} becomes {}'.format(\n",
    "    *api[v1].T.sectionFromNode(n),\n",
    "    n,\n",
    "    api[v1].F.lex.v(n),\n",
    "    api[v2].F.lex.v(n),\n",
    "    api[v2].F.lex.v(m),\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4b => 4c\n",
    "\n",
    "We need other cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cases.update({\n",
    "    ('4b', '4c'): {\n",
    "         28423: ('split', 3),\n",
    "         28455: ('split', 3),\n",
    "         91193: ('split', 2),\n",
    "         91197: ('split', 2),\n",
    "        122218: ('split', 2),\n",
    "        122247: ('split', 2),\n",
    "        123160: ('split', 2),\n",
    "        184086: ('split', 2),\n",
    "        394186: ('collapse', 2),\n",
    "        395150: ('ok', None),\n",
    "        395190: ('ok', None),\n",
    "        401036: ('split', 3),\n",
    "        404503: ('ok', None),\n",
    "        419138: ('split', 3),\n",
    "    },    \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genesis 50:10 ==> slot 28423 ==> 28423\n",
      "    4b: <D       ~ |GRN_>VD/| ~ >CR     \n",
      "    4c: <D       ~ |GRN/    | ~ H       \n",
      "Action: split into 3 slots\n",
      "\n",
      "Genesis 50:11 ==> slot 28455 ==> 28457\n",
      "    4b: B        ~ |GRN_>VD/| ~ W       \n",
      "    4c: B        ~ |GRN/    | ~ H       \n",
      "Action: split into 3 slots\n",
      "\n",
      "Numbers 33:45 ==> slot 91193 ==> 91197\n",
      "    4b: B        ~ |DJBWN_GD/| ~ W       \n",
      "    4c: B        ~ |DJBN/   | ~ GD==/   \n",
      "Action: split into 2 slots\n",
      "\n",
      "Numbers 33:46 ==> slot 91197 ==> 91202\n",
      "    4b: MN       ~ |DJBWN_GD/| ~ W       \n",
      "    4c: MN       ~ |DJBN/   | ~ GD==/   \n",
      "Action: split into 2 slots\n",
      "\n",
      "Joshua 16:3 ==> slot 122218 ==> 122224\n",
      "    4b: GBWL/    ~ |BJT_XRWN_TXTWN/| ~ W       \n",
      "    4c: GBWL/    ~ |BJT_XWRWN/| ~ TXTWN/  \n",
      "Action: split into 2 slots\n",
      "\n",
      "Joshua 16:5 ==> slot 122247 ==> 122254\n",
      "    4b: <D       ~ |BJT_XRWN_<LJWN/| ~ W       \n",
      "    4c: <D       ~ |BJT_XWRWN/| ~ <LJWN/  \n",
      "Action: split into 2 slots\n",
      "\n",
      "Joshua 18:13 ==> slot 123160 ==> 123168\n",
      "    4b: L        ~ |BJT_XRWN_TXTWN/| ~ W       \n",
      "    4c: L        ~ |BJT_XWRWN/| ~ TXTWN/  \n",
      "Action: split into 2 slots\n",
      "\n",
      "1_Kings 9:17 ==> slot 184086 ==> 184095\n",
      "    4b: >T       ~ |BJT_XRWN_TXTWN/| ~ W       \n",
      "    4c: >T       ~ |BJT_XWRWN/| ~ TXTWN/  \n",
      "Action: split into 2 slots\n",
      "\n",
      "1_Chronicles 6:13 ==> slot 394186 ==> 394196\n",
      "    4b: BKR/     ~ |W       | ~ CNJ/    \n",
      "    4c: BKR/     ~ |WCNJ/   | ~ W       \n",
      "Action: collapse 2 slots\n",
      "\n",
      "1_Chronicles 7:12 ==> slot 395150 ==> 395159\n",
      "    4b: W        ~ |CPM==/  | ~ W       \n",
      "    4c: W        ~ |CPJM/   | ~ W       \n",
      "Action: innocent variation in lexeme\n",
      "\n",
      "1_Chronicles 7:15 ==> slot 395190 ==> 395199\n",
      "    4b: L        ~ |CPM==/  | ~ W       \n",
      "    4c: L        ~ |CPJM/   | ~ W       \n",
      "Action: innocent variation in lexeme\n",
      "\n",
      "1_Chronicles 18:12 ==> slot 401036 ==> 401045\n",
      "    4b: B        ~ |GJ>_MLX/| ~ CMNH/   \n",
      "    4c: B        ~ |GJ>/    | ~ H       \n",
      "Action: split into 3 slots\n",
      "\n",
      "1_Chronicles 26:16 ==> slot 404503 ==> 404514\n",
      "    4b: L        ~ |CPM==/  | ~ W       \n",
      "    4c: L        ~ |CPJM/   | ~ W       \n",
      "Action: innocent variation in lexeme\n",
      "\n",
      "2_Chronicles 25:11 ==> slot 419138 ==> 419149\n",
      "    4b: HLK[     ~ |GJ>_MLX/| ~ W       \n",
      "    4c: HLK[     ~ |GJ>/    | ~ H       \n",
      "Action: split into 3 slots\n",
      "\n",
      "No more differences.\n",
      "Found 14 points of disturbance\n"
     ]
    }
   ],
   "source": [
    "doDiffs('4b', '4c')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bit below is very handy if you need a closer look to what is the case in some range of slots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "419135: <M/      <M/     \n",
      "419136: W        W       \n",
      "419137: HLK[     HLK[    \n",
      "419138: GJ>_MLX/ GJ>/    \n",
      "419139: W        W       \n",
      "419140: NKH[     NKH[    \n",
      "419141: >T       >T      \n",
      "419142: BN/      BN/     \n",
      "419143: F<JR====/ F<JR====/\n",
      "419144: <FRH=/   <FRH=/  \n"
     ]
    }
   ],
   "source": [
    "inspect('4b', '4c', 419135, 419145)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just have a look at the first point of disturbance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genesis 50:10 node 28424: >CR versus H becomes >CR\n"
     ]
    }
   ],
   "source": [
    "(v1, v2) = ('4b', '4c')\n",
    "(n, m) = [x for x in mappings[(v1, v2)].items() if x[0] != x[1]][0]\n",
    "print('{} {}:{} node {}: {} versus {} becomes {}'.format(\n",
    "    *api[v1].T.sectionFromNode(n),\n",
    "    n,\n",
    "    api[v1].F.lex.v(n),\n",
    "    api[v2].F.lex.v(n),\n",
    "    api[v2].F.lex.v(m),\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.00s Exporting 0 node and 1 edge and 0 config features to /Users/dirk/github/text-fabric-data-legacy/hebrew/etcbc4b:\n",
      "   |     1.33s T omap@4-4b            to /Users/dirk/github/text-fabric-data-legacy/hebrew/etcbc4b\n",
      "  1.33s Exported 0 node features and 1 edge features and 0 config features to /Users/dirk/github/text-fabric-data-legacy/hebrew/etcbc4b\n",
      "  0.00s Exporting 0 node and 1 edge and 0 config features to /Users/dirk/github/text-fabric-data/hebrew/etcbc4c:\n",
      "   |     1.31s T omap@4b-4c           to /Users/dirk/github/text-fabric-data/hebrew/etcbc4c\n",
      "  1.31s Exported 0 node features and 1 edge features and 0 config features to /Users/dirk/github/text-fabric-data/hebrew/etcbc4c\n"
     ]
    }
   ],
   "source": [
    "writeMaps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(mappings.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
