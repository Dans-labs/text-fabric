{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os, re, collections\n",
    "from glob import glob\n",
    "\n",
    "from tf.fabric import Fabric\n",
    "from tf.timestamp import Timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "REPO = os.path.expanduser('~/github/sanskrit_text_dcs')\n",
    "TEXT_DIR = '{}/corpora'.format(REPO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Text-Fabric 2.3.7\n",
      "Api reference : https://github.com/ETCBC/text-fabric/wiki/Api\n",
      "Tutorial      : https://github.com/ETCBC/text-fabric/blob/master/docs/tutorial.ipynb\n",
      "Data sources  : https://github.com/ETCBC/text-fabric-data\n",
      "Data docs     : https://etcbc.github.io/text-fabric-data\n",
      "Shebanq docs  : https://shebanq.ancient-data.org/text\n",
      "Slack team    : https://shebanq.slack.com/signup\n",
      "Questions? Ask shebanq@ancient-data.org for an invite to Slack\n",
      "0 features found and 0 ignored\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0.01s Grid feature \"otype\" not found in\n",
      "\n",
      "  0.01s Grid feature \"oslots\" not found in\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.01s Grid feature \"otext\" not found. Working without Text-API\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tm = Timestamp()\n",
    "TF = Fabric('~/github/text-fabric-data/sanskrit/dcs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "errors = collections.defaultdict(list)\n",
    "slotNum = 0\n",
    "nodeFeatures = collections.defaultdict(dict)\n",
    "edgeFeatures = collections.defaultdict(dict)\n",
    "\n",
    "CHAR = 'char'\n",
    "TRAILER='trailer'\n",
    "WORD = 'word'\n",
    "BOOK = 'book'\n",
    "SECTION = 'chapter'\n",
    "LINE = 'verse'\n",
    "nodes = collections.defaultdict(list)\n",
    "\n",
    "def showErrorSummary():\n",
    "    errorTexts = sorted(errors.keys())[0:3]\n",
    "    for errorText in errorTexts:\n",
    "        for error in errors[errorText][0:3]:\n",
    "            print(error)\n",
    "\n",
    "def readCorpus():\n",
    "    tm.indent(reset=True)\n",
    "    tm.info('Reading corpus')\n",
    "    os.chdir(TEXT_DIR)\n",
    "    errors.clear()\n",
    "    nodeFeatures.clear()\n",
    "    edgeFeatures.clear()\n",
    "    nodes.clear()\n",
    "    global slotNum\n",
    "    slotNum = 0\n",
    "    textFiles = sorted(os.path.splitext(f)[0] for f in glob('*.txt'))\n",
    "    print('{} texts'.format(len(textFiles)))\n",
    "    for textFile in textFiles:\n",
    "        readText(textFile)\n",
    "    if len(errors):\n",
    "        print('There were {} errors'.format(sum(len(errors[textFile]) for textFile in errors)))\n",
    "        showErrorSummary()\n",
    "    else:\n",
    "        print('No errors')\n",
    "    print('''\n",
    "{} slots\n",
    "{} words in source\n",
    "{} lines\n",
    "{} sections\n",
    "{} books\n",
    "'''.format(\n",
    "        slotNum,\n",
    "        len(nodes[WORD]),\n",
    "        len(nodes[LINE]),\n",
    "        len(nodes[SECTION]),\n",
    "        len(nodes[BOOK]),\n",
    "    ))\n",
    "    tm.info('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "linePat = re.compile('^\\s*([^\\/]*)\\/+\\s*\\(([^.)]+).([^)]+)\\)\\s*')\n",
    "emptyLinePat = re.compile('^\\s*$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readText(textFile):\n",
    "    global slotNum\n",
    "    with open('{}.txt'.format(textFile)) as f:\n",
    "        bookName = textFile\n",
    "        bookStart = slotNum + 1\n",
    "        curSection = None\n",
    "        sectionStart = slotNum + 1\n",
    "        for (n, line) in enumerate(f):\n",
    "            lineStart = slotNum + 1\n",
    "            line = line.rstrip('\\n')\n",
    "            if emptyLinePat.match(line): continue\n",
    "            match = linePat.match(line)\n",
    "            if not match:\n",
    "                errors[textFile].append('{}:{} - unexpected line\\n\\t{}\\n'.format(textFile, n + 1, line))\n",
    "                continue\n",
    "            text = match.group(1).rstrip()\n",
    "            sectionNr = match.group(2)\n",
    "            if sectionNr == None:\n",
    "                break\n",
    "            if curSection != sectionNr:\n",
    "                if curSection != None:\n",
    "                    sectionEnd = slotNum\n",
    "                    nodes[SECTION].append((sectionStart, sectionEnd, {SECTION: curSection, BOOK: bookName}))\n",
    "                curSection = sectionNr\n",
    "                sectionStart = slotNum + 1                \n",
    "            lineNr = match.group(3)\n",
    "            words = text.split()\n",
    "            for word in words:\n",
    "                wordStart = slotNum + 1\n",
    "                for letter in word:\n",
    "                    slotNum += 1                 \n",
    "                    nodeFeatures[CHAR][slotNum] = letter\n",
    "                    nodeFeatures[TRAILER][slotNum] = ''\n",
    "                wordEnd = slotNum\n",
    "                nodeFeatures[TRAILER][slotNum] = ' '\n",
    "                nodes[WORD].append((wordStart, wordEnd, {WORD: word}))\n",
    "            lineEnd = slotNum\n",
    "            nodes[LINE].append((lineStart, lineEnd, {LINE: lineNr, SECTION: curSection, BOOK: bookName}))\n",
    "        sectionEnd = slotNum\n",
    "        if curSection == None:\n",
    "            print('Empty book {}'.format(textFile))\n",
    "        else:    \n",
    "            nodes[SECTION].append((sectionStart, sectionEnd, {SECTION: curSection, BOOK: bookName}))\n",
    "            bookEnd = slotNum\n",
    "            nodes[BOOK].append((bookStart, bookEnd, {BOOK: bookName}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversion notes\n",
    "\n",
    "190 texts\n",
    "\n",
    "### Empty Texts\n",
    "\n",
    "Empty book Gřḍhārthaprakāśaka\n",
    "Empty book Kaulāvalīnirṇaya\n",
    "Empty book Mṛgendraṭīkā\n",
    "Empty book Nyāyacandrikāpaṇjikā\n",
    "Empty book Śārṅgadharasaṃhitādīpikā\n",
    "Empty book Tantrasaṃgraha\n",
    "Empty book Tantrāloka\n",
    "\n",
    "**Action taken**\n",
    "\n",
    "Skipped them altogether\n",
    "\n",
    "### Irregular lines\n",
    "\n",
    "There were 3 errors\n",
    "Agastīyaratnaparīkṣā:55 - unexpected line\n",
    "\t\t[... auein Vers / Satzjh] // (27.2)hariśvetaṃ tathā vaṃśe pītaśvetaṃ ca śūkare // (28.1)\n",
    "\n",
    "Gokarṇapurāṇasāraḥ:185 - unexpected line\n",
    "\t\titi śrīskānde gokarṇakhaṇḍe śrīgokarṇamāhātmye sāroddhāre prathamo 'dhyāyaḥ / // (88.1)\n",
    "\n",
    "Rasādhyāya:130 - unexpected line\n",
    "\t\t[... auein Vers / Satzjh] // (64.2)tāmrāt sūtaṃ rasāttāmraṃ pātanāya pṛthakkṛtam / (65.1)\n",
    "        \n",
    "**Action taken**\n",
    "\n",
    "Case 1 and 3: inserted a newline, changed the first / into an `~`\n",
    "\n",
    "Case 2: removed the `//`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.00s Reading corpus\n",
      "190 texts\n",
      "Empty book Gřḍhārthaprakāśaka\n",
      "Empty book Kaulāvalīnirṇaya\n",
      "Empty book Mṛgendraṭīkā\n",
      "Empty book Nyāyacandrikāpaṇjikā\n",
      "Empty book Śārṅgadharasaṃhitādīpikā\n",
      "Empty book Tantrasaṃgraha\n",
      "Empty book Tantrāloka\n",
      "No errors\n",
      "\n",
      "1161379 slots\n",
      "136409 words in source\n",
      "25729 lines\n",
      "13010 sections\n",
      "183 books\n",
      "\n",
      "  0.95s Done\n"
     ]
    }
   ],
   "source": [
    "readCorpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "metaData = {\n",
    "    '': dict(\n",
    "        createdBy='Tylor Neill and Dirk Roorda',\n",
    "        name='Sanskrit_Corpus_DCS',\n",
    "        title='Sanskrit Corpus',\n",
    "        provenance='[DCS](http://kjc-fs-cluster.kjc.uni-heidelberg.de/dcs/index.php)',\n",
    "        description='DCS, the Digital Corpus of Sanskrit, is a searchable collection of lemmatized Sanskrit texts. It offers free internet access to a part of the database of the linguistic program SanskritTagger, which has been under constant development since 1999.'\n",
    "    ),\n",
    "    'otext': {\n",
    "        'sectionFeatures': ','.join((BOOK, SECTION, LINE)),\n",
    "        'sectionTypes': ','.join((BOOK, SECTION, LINE)),\n",
    "        'fmt:text-orig-full': '{{{}}}'.format(CHAR),\n",
    "        'fmt:text-orig-segmented': '{{{}}}{{{}}}'.format(CHAR, TRAILER),\n",
    "    },\n",
    "    'otype': {\n",
    "        'valueType': 'str',        \n",
    "    },\n",
    "    'oslots': {\n",
    "        'valueType': 'str',\n",
    "    },\n",
    "    'book@sa': {\n",
    "        'valueType': 'str',\n",
    "        'language': 'Saṃskṛtam',\n",
    "        'languageCode': 'sa',\n",
    "        'languageEnglish': 'sanskrit',\n",
    "    },\n",
    "    'trailer': {\n",
    "        'valueType': 'str',\n",
    "    }\n",
    "}\n",
    "nodeFeatures['book@sa'] = nodeFeatures[BOOK]\n",
    "\n",
    "for (sectionType) in (CHAR, WORD, LINE, SECTION, BOOK):\n",
    "    metaData.setdefault(sectionType, {})['valueType'] = 'int' if sectionType in {LINE, SECTION} else 'str'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def computeStatistics():\n",
    "    tm.info('Computing statistics')\n",
    "    wstats = {\n",
    "        'freq': collections.Counter(),\n",
    "        'rank': {},\n",
    "    }\n",
    "    word = {}\n",
    "\n",
    "    words = [n[0] for n in nodeFeatures['otype'].items() if n[1] == WORD]\n",
    "\n",
    "    for w in words:\n",
    "        occ = nodeFeatures[WORD][w]\n",
    "        wstats['freq'][occ] += 1\n",
    "    rank = -1\n",
    "    prev_n = -1\n",
    "    amount = 1\n",
    "    for (x, n) in sorted(wstats['freq'].items(), key=lambda y: (-y[1], y[0])):\n",
    "        if n == prev_n:\n",
    "            amount += 1\n",
    "        else:\n",
    "            rank += amount\n",
    "            amount = 1\n",
    "        prev_n = n\n",
    "        wstats['rank'][x] = rank\n",
    "    tm.info('Done')\n",
    "\n",
    "    tm.info('Adding statistics as features')\n",
    "    occFeatures = {}\n",
    "    for ft in ('freq', 'rank'):\n",
    "        occFeatures[ft] = {}\n",
    "        metaData.setdefault(ft, {})['valueType'] = 'int'\n",
    "\n",
    "    for w in words:\n",
    "        occ = nodeFeatures[WORD][w]\n",
    "        for ft in ['freq', 'rank']:\n",
    "            occFeatures[ft][w] = str(wstats[ft][occ])\n",
    "\n",
    "    nodeFeatures.update(occFeatures)\n",
    "    tm.info('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def makeTextFabric():\n",
    "    tm.indent(reset=True)\n",
    "    tm.info('Generating text-fabric dataset')\n",
    "    nodeFeatures['otype'] = dict((n, 'letter') for n in range(1, slotNum + 1))\n",
    "    nodeNum = slotNum\n",
    "    for (nodeType) in (WORD, LINE, SECTION, BOOK):\n",
    "        for (start, end, feats) in nodes[nodeType]:\n",
    "            nodeNum += 1\n",
    "            nodeFeatures['otype'][nodeNum] = nodeType\n",
    "            for feat in feats:\n",
    "                nodeFeatures[feat][nodeNum] = feats[feat]\n",
    "            edgeFeatures['oslots'][nodeNum] = list(range(start, end + 1))\n",
    "    computeStatistics()\n",
    "    TF.save(nodeFeatures=nodeFeatures, edgeFeatures=edgeFeatures, metaData=metaData)\n",
    "    tm.info('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.00s Generating text-fabric dataset\n",
      "  0.64s Computing statistics\n",
      "  1.20s Done\n",
      "  1.20s Adding statistics as features\n",
      "  1.43s Done\n",
      "  0.00s Exporting 10 node and 1 edge and 1 config features to /Users/dirk/github/text-fabric-data/sanskrit/dcs:\n",
      "   |     0.08s T book                 to /Users/dirk/github/text-fabric-data/sanskrit/dcs\n",
      "   |     0.08s T book@sa              to /Users/dirk/github/text-fabric-data/sanskrit/dcs\n",
      "   |     0.07s T chapter              to /Users/dirk/github/text-fabric-data/sanskrit/dcs\n",
      "   |     2.01s T char                 to /Users/dirk/github/text-fabric-data/sanskrit/dcs\n",
      "   |     0.30s T freq                 to /Users/dirk/github/text-fabric-data/sanskrit/dcs\n",
      "   |     0.67s T otype                to /Users/dirk/github/text-fabric-data/sanskrit/dcs\n",
      "   |     0.22s T rank                 to /Users/dirk/github/text-fabric-data/sanskrit/dcs\n",
      "   |     1.70s T trailer              to /Users/dirk/github/text-fabric-data/sanskrit/dcs\n",
      "   |     0.06s T verse                to /Users/dirk/github/text-fabric-data/sanskrit/dcs\n",
      "   |     0.25s T word                 to /Users/dirk/github/text-fabric-data/sanskrit/dcs\n",
      "   |     1.19s T oslots               to /Users/dirk/github/text-fabric-data/sanskrit/dcs\n",
      "   |     0.00s M otext                to /Users/dirk/github/text-fabric-data/sanskrit/dcs\n",
      "  6.66s Exported 10 node features and 1 edge features and 1 config features to /Users/dirk/github/text-fabric-data/sanskrit/dcs\n",
      "  8.10s Done\n"
     ]
    }
   ],
   "source": [
    "makeTextFabric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
