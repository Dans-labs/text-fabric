{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Format of TF files\n",
    "A `.tf` feature file starts with a *header*, and is followed by the actual data.\n",
    "The whole file is a plain text in UNICODE-utf8.\n",
    "\n",
    "## Header\n",
    "The header consists of two portions: *metadata* and *comment*.\n",
    "\n",
    "### Metadata\n",
    "A `.tf` feature file always starts with one or more lines of the form\n",
    "\n",
    "    @key\n",
    "\n",
    "or\n",
    "\n",
    "    @key=value\n",
    "\n",
    "The first line must be either\n",
    "\n",
    "    @node\n",
    "\n",
    "or \n",
    "\n",
    "    @edge\n",
    "\n",
    "This tells Text-Fabric whether the data in the feature file is a *node* feature or an *edge* feature.\n",
    "The rest of the metadata is optional for now, but it is recommended to put a date stamp in it like this\n",
    "\n",
    "    @dateCreated=2016-11-20T13:26:59Z\n",
    "\n",
    "The time format should be [ISO 8601](https://en.wikipedia.org/wiki/ISO_8601).\n",
    "    \n",
    "## Data\n",
    "After the metadata, there must be exactly one blank line, and everything there after are data lines.\n",
    "\n",
    "The form of a data line is\n",
    "\n",
    "    node_spec value\n",
    "\n",
    "for node features, and\n",
    "\n",
    "    node_spec node_spec value\n",
    "\n",
    "for edge features.\n",
    "\n",
    "These fields are separated by single tabs.\n",
    "\n",
    "### Node Spec\n",
    "Every line contains a feature value that pertains to all nodes defined by its *node_spec*, or to\n",
    "all edges defined by its pair of *node_spec*s.\n",
    "\n",
    "A node spec denotes a *set* of nodes.\n",
    "\n",
    "The simplest form of a node spec is just a single integer. Examples:\n",
    "\n",
    "    3\n",
    "    45\n",
    "    425000\n",
    "\n",
    "Ranges are also allowed. Examples\n",
    "\n",
    "    1-10\n",
    "    5-13\n",
    "    28-57045\n",
    "\n",
    "The nodes denoted by a range are all numbers between the endpoints of the range (including at both sides).\n",
    "So\n",
    "\n",
    "    2-4\n",
    "\n",
    "denotes the nodes `2`, `3`, and `4`.\n",
    "\n",
    "You can also combine numbers and ranges arbitrarily by separating them with commas. Examples\n",
    "\n",
    "    1-3,5-10,15,23-37\n",
    "\n",
    "Such a specification denotes the union of what is denoted by each comma-separated part.\n",
    "\n",
    "**NB** As node specs denote *sets* of nodes, the following node specs are in fact equivalent\n",
    "\n",
    "    1,1 and 1\n",
    "    2-3 and 3,2\n",
    "    1-5,2-7 and 1-7\n",
    "\n",
    "We will also be tolerant in that you may specify the end points of ranges in arbitrary order:\n",
    "\n",
    "    1-3 is the same as 3-1\n",
    "    \n",
    "#### Edges\n",
    "An edge is specified by an *ordered* pair of nodes. The edge is *from* the first node in the pair *to* the second one.\n",
    "An edge spec consists of two node specs. It denotes all edges that are *from* a node denoted by the first node spec\n",
    "and *to* a node denoted by the second node spec.\n",
    "An edge might be labeled, in that case the label of the edge is specified by the *value* after the two node specs.\n",
    "\n",
    "### Value\n",
    "\n",
    "The value is arbitrary text. \n",
    "We do not distinguish types: all values are taken as unicode utf8 strings.\n",
    "There are a few escapes:\n",
    "* `\\\\` backslash\n",
    "* `\\t` tab\n",
    "* `\\n` newline\n",
    "Thes characters MUST always be escaped in a value string, otherwise the line as a whole might be ambiguous.\n",
    "\n",
    "## Consistency requirements\n",
    "\n",
    "There are a few additional requirementson feature data.\n",
    "\n",
    "### Single values\n",
    "It is assumed that a node feature assigns only one value to each node.\n",
    "It is an error if the data contains multiple assignments to a node.\n",
    "\n",
    "Likewise, it is assumed that an edge feature assigns only one value to each edge.\n",
    "It is an error if the data contains multiple assignments to an edge.\n",
    "\n",
    "Violations maybe reported,\n",
    "but processing may continue without warnings\n",
    "if the last encountered value for each node or edge is chosen.\n",
    "\n",
    "## Optimizations\n",
    "\n",
    "### Using the implicit node\n",
    "You may leave out the node spec for node features, and the first node spec for edge features. In that case, you also must leave out the tab following the node spec.\n",
    "If you leave it out, the node denoted is the singleton set consisting of the *implicit node*. \n",
    "Here are the rules for implicit nodes.\n",
    "\n",
    "* On a line where there is an explicit node spec, the implicit node is equal to the highest node\n",
    "  denoted by the explicit node spec.\n",
    "* On the first line, the implicit node is just `0`\n",
    "* On all other lines, if there is no explicit node spec, the implicit node spec is equal to the \n",
    "  implicit node spec of the previous line plus 1\n",
    "\n",
    "For edges, this optimization only happens for the *first* node spec.\n",
    "The second node spec must always be explicit.\n",
    "\n",
    "This optimizes some feature files greatly, e.g. the feature that contains the actual text of each word.\n",
    "\n",
    "Instead of\n",
    "\n",
    "    0 be\n",
    "    1 reshit\n",
    "    2 bara\n",
    "    3 elohim\n",
    "    4 et\n",
    "    5 ha\n",
    "    6 shamajim\n",
    "    7 we\n",
    "    8 et\n",
    "    9 ha\n",
    "    10 arets\n",
    "\n",
    "you can just say\n",
    "\n",
    "    be\n",
    "    reshit\n",
    "    bara\n",
    "    elohim\n",
    "    et\n",
    "    ha\n",
    "    shamajim\n",
    "    we\n",
    "    et\n",
    "    ha\n",
    "    arets\n",
    "    \n",
    "This optimization is not obligatory. It is a device that may be used\n",
    "if you want to optimize the size of data files that you want to distribute.\n",
    "\n",
    "\n",
    "### Omitting empty values\n",
    "\n",
    "If the value is the empty string, you may also leave out the preceding tab (if there is one).\n",
    "This is especially good for edge features, because most edges just consist of a node pair without any value.\n",
    "\n",
    "This optimization will cause a conceptual ambiguity if there is only 1 field present, or if there are only two fields in an edge feature. It could mean that the (first) node spec has been left out, or that the value has been left out.\n",
    "In those cases we will assume that the node spec has been left out for node features, and that the value has been\n",
    "left out for edge features.\n",
    "\n",
    "So, in a node feature a line like this\n",
    "\n",
    "    42\n",
    "\n",
    "means that the implicit node gets value `42`, and not that node `42` gets the empty value.\n",
    "\n",
    "Likewise, an edge feature line like this\n",
    "\n",
    "    42 43\n",
    " \n",
    "means that there is an edge from `42` to `43` with empty value, and not that there is an edge from the implicit node\n",
    "to `42` with value 43.\n",
    "\n",
    "An an edge feature line like this\n",
    "\n",
    "    42\n",
    "\n",
    "means that there is an edge from the implicit node to `42` with the empty value, and not that there is an\n",
    "edge from the implicit node to itself with the value `42`.\n",
    "\n",
    "The reason for these conventions is practical: edge features usually have empty labels, and there are many edges.\n",
    "In case of the ETCBC database, there are 1.5 million edges, so every extra character that is needed on a data line\n",
    "means that the filesize increases with 1.5 MB.\n",
    "\n",
    "Nodes on the other hand, usually do not have empty values, and they are often specified in a consecutive way,\n",
    "especially word nodes. There are quite many distinct word features, and it would be a waste to have a column of half a million incremental integers in those files.\n",
    "\n",
    "## Examples\n",
    "\n",
    "Here are a few more and less contrived examples of legal feature data lines.\n",
    "\n",
    "### Node features\n",
    "\n",
    "1. `\\t\\n`\n",
    "1. `1 2\\t3`\n",
    "1. `foo\\nbar`\n",
    "1. `1 Escape \\\\t as \\\\\\\\t`\n",
    "\n",
    "meaning\n",
    "\n",
    "1. node 0 has value tab-newline\n",
    "1. node 1 has value 2 tab 3\n",
    "1. node 2 has value foo newline bar\n",
    "1. node 1 gets a new value: the string `Escape \\t as \\\\t`\n",
    "\n",
    "### Edge features\n",
    "\n",
    "1. `1 2\\tfoo`\n",
    "1. `1 2 foo`\n",
    "1. `0-1 1-2 bar`\n",
    "\n",
    "meaning\n",
    "\n",
    "1. edge from 0 to 1 with value 2 tab foo\n",
    "1. edge from 1 to 2 with value foo\n",
    "1. four edges: 0->1, 0->2, 1->1, 1->2, all with value bar.\n",
    "   Note that edges can go from a node to itself.\n",
    "   Note also that two edges get new values here: 0->1 and 1->2.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skeleton Features\n",
    "\n",
    "Certain features should always be present in connection with a TF data source: these are the *skeleton features*.\n",
    "\n",
    "Here is a specification of the skeleton features.\n",
    "\n",
    "## otype\n",
    "\n",
    "A node feature, which maps each node to a label. The label typically is the kind of object that the node represents, \n",
    "with typical values\n",
    "\n",
    "    book\n",
    "    chapter\n",
    "    verse\n",
    "    sentence\n",
    "    clause\n",
    "    phrase\n",
    "    word\n",
    "\n",
    "There is a special kind of object type, the *monad type*, which is the atomic building block of the text objects.\n",
    "It is assumed that the complete text is built from a sequence of *monads*, from monad 0 till the last monad, where \n",
    "the monads are numbered consecutatively.\n",
    "\n",
    "All other objects are defined with respect to the *monads* they contain.\n",
    "\n",
    "The monad type does not have to be called `monad` literally. \n",
    "If your basic entity is `word`, you may also call it `word`, or anything else.\n",
    "If your basic entity is not the word, but the character, that is fine to.\n",
    "The only requirement is that all monads correspond exactly with the first so many nodes.\n",
    "It is also assumed that there is at least one monad in the dataset.\n",
    "\n",
    "So the `otype` feature will map node `0` on an object type, and this object type is the type of the monads.\n",
    "\n",
    "We do not have to hard code the monad type in our program, we can find it in the skeleton data by looking at\n",
    "\n",
    "    otype[0]\n",
    "\n",
    "## monads\n",
    "\n",
    "An edge feature, with an edge from each node to each monad it contains.\n",
    "From this we can compute a nice node ordering, and node embedding relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from tf.fabric import Fabric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.00s Looking for available data features:\n",
      "  0.00s   __otype__            from /Users/dirk/github/text-fabric/notebooks/__otype__.tf\n",
      "  0.00s   monads               from /Users/dirk/github/text-fabric/tests/monads.tf\n",
      "  0.00s   monads_meta          from /Users/dirk/github/text-fabric/tests/monads_meta.tf\n",
      "  0.01s   myOtype              from /Users/dirk/github/text-fabric/tests/myOtype.tf\n",
      "  0.01s   otype                from /Users/dirk/github/text-fabric/tests/otype.tf\n",
      "  0.01s   psp                  from /Users/dirk/github/text-fabric/tests/psp.tf\n",
      "  0.01s   sp                   from /Users/dirk/github/text-fabric/tests/sp.tf\n",
      "  0.01s 7 features found\n"
     ]
    }
   ],
   "source": [
    "TF = Fabric(locations='../tests')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   |     0.06s B __order__            from otype, monads, __levels__\n",
      "   |     0.04s B __rank__             from otype, __order__\n",
      "   |     1.01s B __levUp__            from otype, monads, __rank__\n",
      "   |     0.81s B __levDown__          from otype, __levUp__, __rank__\n",
      "   |     0.03s B otype                from /Users/dirk/github/text-fabric/tests/otype.tf\n",
      "   |     0.15s B psp                  from /Users/dirk/github/text-fabric/tests/psp.tf\n",
      "  4.19s All features loaded/computed\n"
     ]
    }
   ],
   "source": [
    "API = TF.load('psp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "F = API['F']\n",
    "L = API['L']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From 0 up\n",
      "1367533         book\n",
      "From 0 down\n",
      "\n",
      "From 1413681 up\n",
      "1367533         book\n",
      "From 1413681 down\n",
      "605143          phrase\n",
      "605144          phrase\n",
      "605145          phrase\n",
      "605146          phrase\n"
     ]
    }
   ],
   "source": [
    "for n in [0, 1413681]:\n",
    "    print('From {} up'.format(n))\n",
    "    print('\\n'.join(['{:<15} {}'.format(u,F['otype'].v(u)) for u in L.u('book', n)]))\n",
    "    print('From {} down'.format(n))\n",
    "    print('\\n'.join(['{:<15} {}'.format(u,F['otype'].v(u)) for u in L.d('phrase', n)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{3, 4}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monadsInv = {1: {1,2,3,4}, 2: {2,3,4,5}, 3: {3,4,5,6}, 4: {4,5,6,7}, 5: {5,6,7,8,}}\n",
    "mSet = {1,2,3}\n",
    "mList = list(mSet)\n",
    "functools.reduce(lambda x,y: x & monadsInv[y], mList[1:], monadsInv[mList[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-98affcd5bd7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mAPI\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'keys'"
     ]
    }
   ],
   "source": [
    "API.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "API['F'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('book', 10937.97435897436),\n",
       " ('chapter', 459.1829924650161),\n",
       " ('verse', 18.376814715891957),\n",
       " ('half_verse', 9.441810535635236),\n",
       " ('sentence', 6.710413717162184),\n",
       " ('sentence_atom', 6.6302087380904275),\n",
       " ('clause', 4.847511363636364),\n",
       " ('clause_atom', 4.71037521256156),\n",
       " ('phrase', 1.6849321020325942),\n",
       " ('phrase_atom', 1.5946059099489749),\n",
       " ('subphrase', 1.4241071428571428),\n",
       " ('word', 1.0)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "API['P']['__levels__'].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array('I', [0, 1367533, 1367572, 1413681, 1125832, 1189402, 426581, 514581, 1368501, 605143])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "API['P']['__order__'].data[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array('I', [0, 11, 12, 15, 18, 23, 24, 25, 26, 28])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "API['P']['__rank__'].data[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
