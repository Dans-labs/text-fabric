{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text-Fabric data model\n",
    "Text with annotations is modeled as a sequence of text positions, started with 0, without gaps.\n",
    "These are the *monads*. Text objects:\n",
    "\n",
    "* are arbitrary compositions of monads. Monads themselves also function as text objects;\n",
    "* are identified by numbers, starting just after the last monad;\n",
    "* carry a *type* (just a string label), and all monads carry the same type, the *monad type*;\n",
    "* can be annotated by *features* (key-value pairs)\n",
    "* can be linked (directionally, labeled) to other text objects;\n",
    "\n",
    "This model suffices to represent intricate text with many complicated and structured annotations.\n",
    "\n",
    "The data in Text-Fabric describes an annotated directed graph with a bit of additional structure.\n",
    "The correspondence is\n",
    "\n",
    "* text objects => nodes\n",
    "* links between text objects => edges\n",
    "* information associated with text objects  => node features\n",
    "* labels on links between text objects => edge features\n",
    "* types of text objects => a special node feature called `otype`\n",
    "* extent of text objects in terms of textual positions => a special edge feature called `monads`\n",
    "* together, the `otype` and `monads` feature are called the **skeleton** of a Text-Fabric dataset\n",
    "\n",
    "We represent the elements that make up such a graph as follows:\n",
    "\n",
    "* nodes are integers, starting with 0, without gaps\n",
    "* edges are ordered pairs of integers\n",
    "* values (for nodes and for edges) are strings (Unicode, utf8)\n",
    "* node features are mappings of integers to strings\n",
    "* edge features are mappings of pairs of integers to strings\n",
    "* the `otype` feature maps the integers `0..maxMonad` (including) to the *monad type*, \n",
    "  where `maxMonad` is the last *monad*, and the integers `maxMonad+1..maxNode` (including)\n",
    "  to the relevant text obbject types\n",
    "* the `monads` feature is an unlabeled edge feature, mapping all non-monad nodes to the set of monads\n",
    "  corresponding to them. So there is an edge between each non-monad node and each monad \"contained\" by that node\n",
    "* a Text-Fabric dataset is a collection of node features and edge features containing at least the\n",
    "  skeleton features `otype` and `monads`.\n",
    "\n",
    "When Text-Fabric works with a dataset, it reads feature data files, and offers an API to process that feature data.\n",
    "The main task of Text-Fabric is to make processing efficient, so that it can be done in interactive ways,\n",
    "such as here in a Jupyter notebook. To that end, Text-Fabric\n",
    "\n",
    "* optimizes feature data after reading it for the first time and stores it in binary form\n",
    "  so that it can load fast in next invocations;\n",
    "* precomputes additional data from the skeleton features in order to provide convenient API functions\n",
    "\n",
    "In Text-Fabric, we have various ways of encoding this model:\n",
    "\n",
    "* as plain text in `.tf` feature files\n",
    "* as python datastructures in memory\n",
    "* as compressed serializations of the same datastructures inside `.tfx` files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Format of TF files\n",
    "A `.tf` feature file starts with a *header*, and is followed by the actual data.\n",
    "The whole file is a plain text in UNICODE-utf8.\n",
    "\n",
    "## Header\n",
    "A `.tf` feature file always starts with one or more metadata lines of the form\n",
    "\n",
    "    @key\n",
    "\n",
    "or\n",
    "\n",
    "    @key=value\n",
    "\n",
    "The first line must be either\n",
    "\n",
    "    @node\n",
    "\n",
    "or \n",
    "\n",
    "    @edge\n",
    "\n",
    "This tells Text-Fabric whether the data in the feature file is a *node* feature or an *edge* feature.\n",
    "The rest of the metadata is optional for now, but it is recommended to put a date stamp in it like this\n",
    "\n",
    "    @dateCreated=2016-11-20T13:26:59Z\n",
    "\n",
    "The time format should be [ISO 8601](https://en.wikipedia.org/wiki/ISO_8601).\n",
    "    \n",
    "## Data\n",
    "After the metadata, there must be exactly one blank line, and everything there after are data lines.\n",
    "\n",
    "We continue the description of the `.tf` format.\n",
    "\n",
    "The form of a data line is\n",
    "\n",
    "    node_spec value\n",
    "\n",
    "for node features, and\n",
    "\n",
    "    node_spec node_spec value\n",
    "\n",
    "for edge features.\n",
    "\n",
    "These fields are separated by single tabs.\n",
    "\n",
    "**NB**: This is the default format. Under *Optimizations* below we shall describe the bits that can be left\n",
    "out, which will lead to significant improvement in space demands and speed of processing.\n",
    "\n",
    "### Node Spec\n",
    "Every line contains a feature value that pertains to all nodes defined by its *node_spec*, or to\n",
    "all edges defined by its pair of *node_spec*s.\n",
    "\n",
    "A node spec denotes a *set* of nodes.\n",
    "\n",
    "The simplest form of a node spec is just a single integer. Examples:\n",
    "\n",
    "    3\n",
    "    45\n",
    "    425000\n",
    "\n",
    "Ranges are also allowed. Examples\n",
    "\n",
    "    1-10\n",
    "    5-13\n",
    "    28-57045\n",
    "\n",
    "The nodes denoted by a range are all numbers between the endpoints of the range (including at both sides).\n",
    "So\n",
    "\n",
    "    2-4\n",
    "\n",
    "denotes the nodes `2`, `3`, and `4`.\n",
    "\n",
    "You can also combine numbers and ranges arbitrarily by separating them with commas. Examples\n",
    "\n",
    "    1-3,5-10,15,23-37\n",
    "\n",
    "Such a specification denotes the union of what is denoted by each comma-separated part.\n",
    "\n",
    "**NB** As node specs denote *sets* of nodes, the following node specs are in fact equivalent\n",
    "\n",
    "    1,1 and 1\n",
    "    2-3 and 3,2\n",
    "    1-5,2-7 and 1-7\n",
    "\n",
    "We will also be tolerant in that you may specify the end points of ranges in arbitrary order:\n",
    "\n",
    "    1-3 is the same as 3-1\n",
    "    \n",
    "#### Edges\n",
    "An edge is specified by an *ordered* pair of nodes. The edge is *from* the first node in the pair *to* the second one.\n",
    "An edge spec consists of two node specs. It denotes all edges that are *from* a node denoted by the first node spec\n",
    "and *to* a node denoted by the second node spec.\n",
    "An edge might be labeled, in that case the label of the edge is specified by the *value* after the two node specs.\n",
    "\n",
    "### Value\n",
    "\n",
    "The value is arbitrary text. \n",
    "We do not distinguish types: all values are taken as unicode utf8 strings.\n",
    "There are a few escapes:\n",
    "* `\\\\` backslash\n",
    "* `\\t` tab\n",
    "* `\\n` newline\n",
    "Thes characters MUST always be escaped in a value string, otherwise the line as a whole might be ambiguous.\n",
    "\n",
    "## Consistency requirements\n",
    "\n",
    "There are a few additional requirementson feature data, having to do with the fact that feature data\n",
    "annotates nodes or edges of a graph.\n",
    "\n",
    "### Single values\n",
    "It is assumed that a node feature assigns only one value to each node.\n",
    "If the data contains multiple assignments to a node, only the last assignment will be honoured, the previous\n",
    "ones will be discarded.\n",
    "\n",
    "Likewise, it is assumed that an edge feature assigns only one value to each edge.\n",
    "If the data contains multiple assignments to an edge, only the last assignment will be honoured.\n",
    "\n",
    "Violations maybe reported, but processing may continue without warnings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizations\n",
    "\n",
    "It is important to avoid an explosion of redundant data in `.tf` files.\n",
    "We want the `.tf` format to be suitable for archiving, transparent to the human eye, and easy(fast) to process.\n",
    "\n",
    "### Using the implicit node\n",
    "You may leave out the node spec for node features, and the first node spec for edge features.\n",
    "When leaving out a node spec, you also must leave out the tab following the node spec.\n",
    "\n",
    "A line with a left-out node spec denotes the singleton node set consisting of the *implicit node*. \n",
    "Here are the rules for implicit nodes.\n",
    "\n",
    "* On a line where there is an explicit node spec, the implicit node is equal to the highest node\n",
    "  denoted by the explicit node spec;\n",
    "* On a line without an explicit node spec, the implicit node is determined from the previous line as follows:\n",
    "  * if there is no previous line, take `0`\n",
    "  * else take the implicit node of the previous line and increment by 1\n",
    "\n",
    "For edges, this optimization only happens for the *first* node spec.\n",
    "The second node spec must always be explicit.\n",
    "\n",
    "This optimizes some feature files greatly, e.g. the feature that contains the actual text of each word.\n",
    "\n",
    "Instead of\n",
    "\n",
    "    0 be\n",
    "    1 reshit\n",
    "    2 bara\n",
    "    3 elohim\n",
    "    4 et\n",
    "    5 ha\n",
    "    6 shamajim\n",
    "    7 we\n",
    "    8 et\n",
    "    9 ha\n",
    "    10 arets\n",
    "\n",
    "you can just say\n",
    "\n",
    "    be\n",
    "    reshit\n",
    "    bara\n",
    "    elohim\n",
    "    et\n",
    "    ha\n",
    "    shamajim\n",
    "    we\n",
    "    et\n",
    "    ha\n",
    "    arets\n",
    "    \n",
    "This optimization is not obligatory. It is a device that may be used\n",
    "if you want to optimize the size of data files that you want to distribute.\n",
    "\n",
    "### Omitting empty values\n",
    "\n",
    "If the value is the empty string, you may also leave out the preceding tab (if there is one).\n",
    "This is especially good for edge features, because most edges just consist of a node pair without any value.\n",
    "\n",
    "This optimization will cause a conceptual ambiguity if there is only one field present in a node feature,\n",
    "or if there are only two fields in an edge feature. \n",
    "It could mean that the (first) node spec has been left out, or that the value has been left out.\n",
    "\n",
    "In those cases we will assume that the node spec has been left out for node features, and that the value has been\n",
    "left out for edge features.\n",
    "\n",
    "So, in a node feature a line like this\n",
    "\n",
    "    42\n",
    "\n",
    "means that the implicit node gets value `42`, and not that node `42` gets the empty value.\n",
    "\n",
    "Likewise, an edge feature line like this\n",
    "\n",
    "    42 43\n",
    " \n",
    "means that there is an edge from `42` to `43` with empty value, and not that there is an edge from the implicit node\n",
    "to `42` with value 43.\n",
    "\n",
    "An an edge feature line like this\n",
    "\n",
    "    42\n",
    "\n",
    "means that there is an edge from the implicit node to `42` with the empty value, and not that there is an\n",
    "edge from the implicit node to itself with the value `42`.\n",
    "\n",
    "The reason for these conventions is practical: edge features usually have empty labels, and there are many edges.\n",
    "In case of the ETCBC database, there are 1.5 million edges, so every extra character that is needed on a data line\n",
    "means that the filesize increases with 1.5 MB.\n",
    "\n",
    "Nodes on the other hand, usually do not have empty values, and they are often specified in a consecutive way,\n",
    "especially word nodes. There are quite many distinct word features, and it would be a waste to have a column of half a million incremental integers in those files.\n",
    "\n",
    "## Examples\n",
    "\n",
    "Here are a few more and less contrived examples of legal feature data lines.\n",
    "\n",
    "### Node features\n",
    "\n",
    "1. `\\t\\n`\n",
    "1. `1 2\\t3`\n",
    "1. `foo\\nbar`\n",
    "1. `1 Escape \\\\t as \\\\\\\\t`\n",
    "\n",
    "meaning\n",
    "\n",
    "1. node 0 has value tab-newline\n",
    "1. node 1 has value 2 tab 3\n",
    "1. node 2 has value foo newline bar\n",
    "1. node 1 gets a new value: the string `Escape \\t as \\\\t`\n",
    "\n",
    "### Edge features\n",
    "\n",
    "1. `1`\n",
    "1. `1 2`\n",
    "1. `1 2 foo`\n",
    "1. `0-1 1-2 bar`\n",
    "\n",
    "meaning\n",
    "\n",
    "1. edge from 0 to 1 with no value\n",
    "1. edge from 1 to 2 with no value\n",
    "1. edge from 1 to 2 with value foo\n",
    "1. four edges: 0->1, 0->2, 1->1, 1->2, all with value bar.\n",
    "   Note that edges can go from a node to itself.\n",
    "   Note also that two edges get new values here: 0->1 and 1->2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skeleton Features\n",
    "\n",
    "Remember that the node feature `otype` and the edge feature `monads` constitute the *skeleton* of a Text-Fabric dataset.\n",
    "\n",
    "## skeleton: otype\n",
    "\n",
    "A node feature, which maps each node to a label. The label typically is the kind of object that the node represents, \n",
    "with typical values\n",
    "\n",
    "    book\n",
    "    chapter\n",
    "    verse\n",
    "    sentence\n",
    "    clause\n",
    "    phrase\n",
    "    word\n",
    "\n",
    "There is a special kind of object type, the *monad type*, which is the atomic building block of the text objects.\n",
    "It is assumed that the complete text is built from a sequence of *monads*, from monad 0 till the last monad, where \n",
    "the monads are numbered consecutatively. There must be at least one monad.\n",
    "\n",
    "All other objects are defined with respect to the *monads* they contain.\n",
    "\n",
    "The monad type does not have to be called `monad` literally. \n",
    "If your basic entity is `word`, you may also call it `word`, or anything else.\n",
    "If your basic entity is not the word, but the character, that is fine to.\n",
    "The only requirement is that all monads correspond exactly with the first so many nodes.\n",
    "It is also assumed that there is at least one monad in the dataset.\n",
    "\n",
    "So the `otype` feature will map node `0` on an object type, and this object type is the type of the monads.\n",
    "\n",
    "We do not have to hard code the monad type in our program, we can find it in the skeleton data by looking at\n",
    "\n",
    "    otype[0]\n",
    "\n",
    "since there is always at least one monad.\n",
    "\n",
    "## skeleton: monads\n",
    "\n",
    "An edge feature, with an edge from each node to each monad it contains.\n",
    "From this we can compute a nice node ordering, and node embedding relationships."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API\n",
    "\n",
    "## Importing and calling Text-Fabric\n",
    "\n",
    "    from tf.fabric import Fabric\n",
    "    TF = Fabric(locations=directories)\n",
    "\n",
    "Here directory is a single directory name as string, or an iterable of directories.\n",
    "These directories will be searched for `.tf` files (non-recursively), and an index of features will be made.\n",
    "If a `.tf` file name occurs in multiple directories, the last one encountered will be used.\n",
    "\n",
    "The locations list is prepended with a few standard directories, namely\n",
    "\n",
    "    ~/Downloads\n",
    "    ~\n",
    "    ~/text-fabric-data\n",
    "    .\n",
    "    \n",
    "in that order. \n",
    "So if you have stored your main LAF-Fabric dataset in `text-fabric-data` in your home directory,\n",
    "you do not have to pass a location to Fabric.\n",
    "If you want to add features from outside this dataset, you can add the directories that contain them\n",
    "to the `locations` parameter.\n",
    "In this way you can easily override certain features in the main dataset by your own features.\n",
    "\n",
    "## Loading features\n",
    "\n",
    "    T = TF.load(features)\n",
    "\n",
    "where `features` is a string containing space separated feature names, or an iterable of feature names.\n",
    "The feature names are just the file names without directory information and without extension.\n",
    "\n",
    "## Sorting nodes\n",
    "\n",
    "    T.sorted(nodeset)\n",
    "    \n",
    "delivers `nodeset` as a tuple sorted by the canonical ordering.\n",
    "Briefly:\n",
    "\n",
    "* embedders come before embeddees,\n",
    "* earliers stuff comes before later stuff,\n",
    "* if a verse coincides with a sentence, the verse comes before the sentence, because verses generally\n",
    "  contain sentences and not the other way round\n",
    "* if two objects are intersecting, but none embeds the other, the one with the smallest monad that does not occur\n",
    "  in the other, comes before\n",
    "  \n",
    "## Walking through nodes\n",
    "\n",
    "    for n in T.N():\n",
    "        action\n",
    "\n",
    "A generator that walks through all nodes in the canonical order.\n",
    "\n",
    "**NB**: Later, under *Features* there is another convenient way to walk through nodes.\n",
    "\n",
    "## Node features\n",
    "\n",
    "    T.Fall()\n",
    "\n",
    "Returns a sorted list of all usable, loaded feature names.\n",
    "\n",
    "    T.F.feature.v(node)\n",
    "    \n",
    "Get the value of a `feature` for `node`.\n",
    "The feature name can be used unquoted if it is a valid python identifier.\n",
    "If not, you should say:\n",
    "\n",
    "    T.Fs('feature').v(node)\n",
    "\n",
    "This works for all feature names, so you can call features programmatically.\n",
    "\n",
    "    T.F.feature.s(value)\n",
    "    \n",
    "This is the other way to walk through nodes: it returns a generator of all nodes in the canonical order\n",
    "that have the value `value` for the feature `feature`.\n",
    "\n",
    "### Skeleton feature otype\n",
    "\n",
    "`otype` is a special node feature and has additional capabilities.\n",
    "\n",
    "* `T.F.otype.monadType` is the node type of the monads (usually: `word`)\n",
    "* `T.F.otype.maxMonad` is the largest monad number\n",
    "* `T.F.otype.maxNode` is the largest node number\n",
    "\n",
    "## Edge features\n",
    "\n",
    "    T.Eall()\n",
    "\n",
    "Returns a sorted list of all usable, loaded edge names.\n",
    "\n",
    "    T.E.feature.f(node)\n",
    "    \n",
    "Get the nodes reached by edges **from** `node`.\n",
    "The result is an order tuple (again, in the canonical node ordering).\n",
    "The members of the result are just nodes, if `feature` describes edges without labels.\n",
    "Otherwise the members are pairs (tuples) of a node and a value.\n",
    "\n",
    "    T.E.feature.t(node)\n",
    "\n",
    "Same as `.f`, but now you get the nodes that are **to** `node`.\n",
    "\n",
    "Again, `T.Es('feature')` is the same as `T.E.feature`, but works also if `feature` is not a valid python\n",
    "identifier.\n",
    "\n",
    "### Skeleton feature monads\n",
    "\n",
    "`monads` is a special edge feature and is mainly used to construct other parts of the API.\n",
    "It has less capabilities, and you will rarely need it.\n",
    "It does not have `.f` and `.t` methods, but a `.m` method instead.\n",
    "\n",
    "    T.E.monads.m(node)\n",
    "    \n",
    "Gives the sorted list of monad numbers linked to `node`.\n",
    "\n",
    "## Layers\n",
    "\n",
    "Here are the methods by which you can navigate easily from a node to its embedders and embeddees.\n",
    "\n",
    "    T.L.u(node, otype=nodetype)\n",
    "    \n",
    "Produces an ordered tuple of nodes **upward** from `node`, i.e. embedder nodes of `node`.\n",
    "\n",
    "    T.L.d(node, otype=nodetype)\n",
    "    \n",
    "Produces an ordered tuple of nodes **downward** from `node`, i.e. embedded nodes of `node`.\n",
    "\n",
    "In both the `.u` and `.d` methods, if the `otype` parameter is present, the result is filtered\n",
    "and only nodes with `otype=nodetype` are retained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from tf.fabric import Fabric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.00s Looking for available data features:\n",
      "  0.00s   __otype__            from /Users/dirk/github/text-fabric/notebooks/__otype__.tf\n",
      "  0.00s   monads               from /Users/dirk/tf/text-fabric-data/monads.tf\n",
      "  0.01s   otype                from /Users/dirk/tf/text-fabric-data/otype.tf\n",
      "  0.01s   sp                   from /Users/dirk/tf/text-fabric-data/sp.tf\n",
      "  0.01s 4 features found\n"
     ]
    }
   ],
   "source": [
    "TF = Fabric(locations='~/tf/text-fabric-data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   |     0.00s B __levels__           from otype, monads\n",
      "   |     0.07s B __order__            from otype, monads, __levels__\n",
      "   |     0.05s B __rank__             from otype, __order__\n",
      "   |     1.01s B __levUp__            from otype, monads, __rank__\n",
      "   |     0.81s B __levDown__          from otype, __levUp__, __rank__\n",
      "   |     0.04s B otype                from /Users/dirk/tf/text-fabric-data/otype.tf\n",
      "   |     0.54s B monads               from /Users/dirk/tf/text-fabric-data/monads.tf\n",
      "   |     0.15s B sp                   from /Users/dirk/tf/text-fabric-data/sp.tf\n",
      "  4.56s All features loaded/computed\n"
     ]
    }
   ],
   "source": [
    "T = TF.load('sp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "monadType=word\n",
      "maxMonad=426580\n",
      "maxNode=1436894\n",
      "All otypes:\n",
      "\tbook\n",
      "\tchapter\n",
      "\tverse\n",
      "\thalf_verse\n",
      "\tsentence\n",
      "\tsentence_atom\n",
      "\tclause\n",
      "\tclause_atom\n",
      "\tphrase\n",
      "\tphrase_atom\n",
      "\tsubphrase\n",
      "\tword\n"
     ]
    }
   ],
   "source": [
    "print('monadType={}\\nmaxMonad={}\\nmaxNode={}'.format(\n",
    "    T.F.otype.monadType,\n",
    "    T.F.otype.maxMonad,\n",
    "    T.F.otype.maxNode,\n",
    "))\n",
    "print('All otypes:\\n\\t{}'.format('\\n\\t'.join(T.F.otype.all)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.00s Counting nodes ...\n",
      "  0.32s 1436894 nodes"
     ]
    }
   ],
   "source": [
    "T.zero()\n",
    "T.info('Counting nodes ...\\n')\n",
    "i = 0\n",
    "for n in T.N(): i += 1\n",
    "T.info('{} nodes'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[426581,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 426582,\n",
       " 426583,\n",
       " 426584,\n",
       " 426585,\n",
       " 426586,\n",
       " 426587,\n",
       " 426588,\n",
       " 426589]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T.sorted(list(range(T.F.otype.maxMonad+1, T.F.otype.maxMonad+10))+list(range(10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.00s counting objects ...\n",
      "  0.13s      39 books\n",
      "  0.25s     929 chapters\n",
      "  0.38s   23213 verses\n",
      "  0.52s   45180 half_verses\n",
      "  0.67s   63570 sentences\n",
      "  0.82s   64339 sentence_atoms\n",
      "  0.98s   88000 clauses\n",
      "  1.14s   90562 clause_atoms\n",
      "  1.38s  253174 phrases\n",
      "  1.63s  267515 phrase_atoms\n",
      "  1.81s  113792 subphrases\n",
      "  1.87s  426581 words\n"
     ]
    }
   ],
   "source": [
    "T.zero()\n",
    "T.info('counting objects ...\\n')\n",
    "for otype in T.F.otype.all:\n",
    "    i = 0\n",
    "    for n in T.F.otype.s(otype): i+=1\n",
    "    T.info('{:>7} {}s\\n'.format(i, otype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1367572,\n",
       " 1367573,\n",
       " 1367574,\n",
       " 1367575,\n",
       " 1367576,\n",
       " 1367577,\n",
       " 1367578,\n",
       " 1367579,\n",
       " 1367580,\n",
       " 1367581,\n",
       " 1367582,\n",
       " 1367583,\n",
       " 1367584,\n",
       " 1367585,\n",
       " 1367586,\n",
       " 1367587,\n",
       " 1367588,\n",
       " 1367589,\n",
       " 1367590,\n",
       " 1367591,\n",
       " 1367592,\n",
       " 1367593,\n",
       " 1367594,\n",
       " 1367595,\n",
       " 1367596,\n",
       " 1367597,\n",
       " 1367598,\n",
       " 1367599,\n",
       " 1367600,\n",
       " 1367601,\n",
       " 1367602,\n",
       " 1367603,\n",
       " 1367604,\n",
       " 1367605,\n",
       " 1367606,\n",
       " 1367607,\n",
       " 1367608,\n",
       " 1367609,\n",
       " 1367610,\n",
       " 1367611,\n",
       " 1367612,\n",
       " 1367613,\n",
       " 1367614,\n",
       " 1367615,\n",
       " 1367616,\n",
       " 1367617,\n",
       " 1367618,\n",
       " 1367619,\n",
       " 1367620,\n",
       " 1367621)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T.L.u(0, otype='book')\n",
    "T.L.d(1367533, otype='chapter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From 0 up\n",
      "605143          phrase\n",
      "858317          phrase_atom\n",
      "1368501         half_verse\n",
      "514581          clause_atom\n",
      "426581          clause\n",
      "1413681         verse\n",
      "1189402         sentence_atom\n",
      "1125832         sentence\n",
      "1367572         chapter\n",
      "1367533         book\n",
      "From 0 down\n",
      "\n",
      "From 1413681 up\n",
      "1189402         sentence_atom\n",
      "1125832         sentence\n",
      "1367572         chapter\n",
      "1367533         book\n",
      "From 1413681 down\n",
      "426581          clause\n",
      "514581          clause_atom\n",
      "1368501         half_verse\n",
      "858317          phrase_atom\n",
      "605143          phrase\n",
      "0               word\n",
      "1               word\n",
      "858318          phrase_atom\n",
      "2               word\n",
      "605144          phrase\n",
      "858319          phrase_atom\n",
      "3               word\n",
      "605145          phrase\n",
      "858320          phrase_atom\n",
      "1368502         half_verse\n",
      "605146          phrase\n",
      "1253741         subphrase\n",
      "4               word\n",
      "5               word\n",
      "6               word\n",
      "7               word\n",
      "1253742         subphrase\n",
      "8               word\n",
      "9               word\n",
      "10              word\n"
     ]
    }
   ],
   "source": [
    "for n in [0, 1413681]:\n",
    "    print('From {} up'.format(n))\n",
    "    print('\\n'.join(['{:<15} {}'.format(u, T.F.otype.v(u)) for u in T.L.u(n)]))\n",
    "    print('From {} down'.format(n))\n",
    "    print('\\n'.join(['{:<15} {}'.format(u, T.F.otype.v(u)) for u in T.L.d(n)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
