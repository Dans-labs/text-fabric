{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"right\" src=\"tf-small.png\"/>\n",
    "\n",
    "# Tutorial\n",
    "\n",
    "This notebook gets you started with\n",
    "[Text-Fabric](https://github.com/ETCBC/text-fabric) an API on annotated text.\n",
    "Below we show some of its functions in action on the DCS data set (Sanskrit).\n",
    "\n",
    "The tutorial is best understood after having familiarized yourself with the underlying\n",
    "[data model](https://github.com/ETCBC/text-fabric/wiki/Data-model).\n",
    "\n",
    "If you want to *get* this all, see the \n",
    "[home page](https://github.com/ETCBC/text-fabric/wiki)\n",
    "of Text-Fabric wiki."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys, collections\n",
    "from tf.fabric import Fabric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Call Text-Fabric\n",
    "\n",
    "Everything starts by setting up Text-Fabric.\n",
    "It needs to know where to look for data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Text-Fabric 2.3.9\n",
      "Api reference : https://github.com/ETCBC/text-fabric/wiki/Api\n",
      "Tutorial      : https://github.com/ETCBC/text-fabric/blob/master/docs/tutorial.ipynb\n",
      "Data sources  : https://github.com/ETCBC/text-fabric-data\n",
      "Data docs     : https://etcbc.github.io/text-fabric-data\n",
      "Shebanq docs  : https://shebanq.ancient-data.org/text\n",
      "Slack team    : https://shebanq.slack.com/signup\n",
      "Questions? Ask shebanq@ancient-data.org for an invite to Slack\n",
      "12 features found and 0 ignored\n"
     ]
    }
   ],
   "source": [
    "DCS = 'sanskrit/dcs'\n",
    "TF = Fabric( modules=[DCS], silent=False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we have just one module: `dcs`, the main data source. \n",
    "\n",
    "If you have additional data (features), you can just add them by pointing Text-Fabric to the right directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Features\n",
    "Specify the features to load, and receive the API to work with that data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.00s loading features ...\n",
      "   |     0.79s T otype                from /Users/dirk/github/text-fabric-data/sanskrit/dcs\n",
      "   |     5.09s T oslots               from /Users/dirk/github/text-fabric-data/sanskrit/dcs\n",
      "   |     0.18s T book                 from /Users/dirk/github/text-fabric-data/sanskrit/dcs\n",
      "   |     0.11s T chapter              from /Users/dirk/github/text-fabric-data/sanskrit/dcs\n",
      "   |     0.06s T verse                from /Users/dirk/github/text-fabric-data/sanskrit/dcs\n",
      "   |     3.85s T char                 from /Users/dirk/github/text-fabric-data/sanskrit/dcs\n",
      "   |     2.14s T trailer              from /Users/dirk/github/text-fabric-data/sanskrit/dcs\n",
      "   |      |     0.22s C __levels__           from otype, oslots\n",
      "   |      |       10s C __order__            from otype, oslots, __levels__\n",
      "   |      |     0.79s C __rank__             from otype, __order__\n",
      "   |      |       12s C __levUp__            from otype, oslots, __rank__\n",
      "   |      |     0.80s C __levDown__          from otype, __levUp__, __rank__\n",
      "   |      |     3.94s C __boundary__         from otype, oslots, __rank__\n",
      "   |     0.00s M otext                from /Users/dirk/github/text-fabric-data/sanskrit/dcs\n",
      "   |      |     0.18s C __sections__         from otype, oslots, otext, __levUp__, __levels__, book, chapter, verse\n",
      "   |     0.67s T word                 from /Users/dirk/github/text-fabric-data/sanskrit/dcs\n",
      "   |     0.28s T freq                 from /Users/dirk/github/text-fabric-data/sanskrit/dcs\n",
      "   |     0.30s T rank                 from /Users/dirk/github/text-fabric-data/sanskrit/dcs\n",
      "   |     0.17s T book@sa              from /Users/dirk/github/text-fabric-data/sanskrit/dcs\n",
      "   |     0.00s Feature overview: 10 for nodes; 1 for edges; 1 configs; 7 computed\n",
      "    41s All features loaded/computed - for details use loadLog()\n"
     ]
    }
   ],
   "source": [
    "api = TF.load('''\n",
    "    char\n",
    "    word\n",
    "    freq\n",
    "    rank\n",
    "    book\n",
    "''')\n",
    "api.makeAvailableIn(globals())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have made it so that the members of the API are directly accessible as global variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counting\n",
    "\n",
    "In order to get acquainted with the data, we start with simple tasks: counting.\n",
    "\n",
    "## Count all nodes\n",
    "We use the \n",
    "[`N()` generator](https://github.com/ETCBC/text-fabric/wiki/Api#walking-through-nodes)\n",
    "to walk us through the nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.00s Counting nodes ...\n",
      "  0.28s 1336710 nodes\n"
     ]
    }
   ],
   "source": [
    "indent(reset=True)\n",
    "info('Counting nodes ...')\n",
    "i = 0\n",
    "for n in N(): i += 1\n",
    "info('{} nodes'.format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sort some nodes\n",
    "\n",
    "Get some nodes, \n",
    "[slot](https://github.com/ETCBC/text-fabric/wiki/Data-model#summary)\n",
    "and non-slot, and sort them in the \n",
    "[canonical order](https://github.com/ETCBC/text-fabric/wiki/Api#sorting-nodes).\n",
    "\n",
    "The [`otype` feature](https://github.com/ETCBC/text-fabric/wiki/Data-model#otype-node-feature)\n",
    "is a\n",
    "[GRID feature](https://github.com/ETCBC/text-fabric/wiki/Data-model#more-about-the-grid),\n",
    "a special feature that provides defining characteristics for the\n",
    "data set as a whole. \n",
    "It tells us where the slots end and the other nodes start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1161380,\n",
       " 1,\n",
       " 2,\n",
       " 1161381,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 1161382,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 1161383,\n",
       " 1161384,\n",
       " 1161385,\n",
       " 1161386,\n",
       " 1161387,\n",
       " 1161388]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sortNodes(list(range(F.otype.maxSlot+1, F.otype.maxSlot+10))+list(range(1,11)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The slots correspond to letters. Words are a higher concept.\n",
    "In the list above you see first a word node, and then the nodes corresponding to its letters.\n",
    "These words are the words according to the word boundaries found in the source texts.\n",
    "\n",
    "It is possible to work with other word boundaries. The first step could be to create an additional feature\n",
    "which tells for each letter whether a word starts there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numbers in the otype feature\n",
    "Get more information that is readily available in the \n",
    "[GRID feature](https://github.com/ETCBC/text-fabric/wiki/Data-model#more-about-the-grid)\n",
    "[`otype`](https://github.com/ETCBC/text-fabric/wiki/Data-model#otype-node-feature),\n",
    "namely what types of objects there are in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slotType  = letter\n",
      "maxSlot  =1161379\n",
      "maxNode  =1336710\n",
      "All otypes:\n",
      "\tbook\n",
      "\tchapter\n",
      "\tverse\n",
      "\tword\n",
      "\tletter\n"
     ]
    }
   ],
   "source": [
    "info('{:<9} = {}\\n{:<9}={}\\n{:<9}={}'.format(\n",
    "    'slotType', F.otype.slotType,\n",
    "    'maxSlot', F.otype.maxSlot,\n",
    "    'maxNode', F.otype.maxNode,\n",
    "), tm=False)\n",
    "info('All otypes:\\n\\t', nl=False, tm=False)\n",
    "info('\\n\\t'.join(F.otype.all), tm=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count individual object types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.00s counting objects ...\n",
      "   |     0.00s     183 books\n",
      "   |     0.00s   13010 chapters\n",
      "   |     0.00s   25729 verses\n",
      "   |     0.02s  136409 words\n",
      "   |     0.14s 1161379 letters\n",
      "  0.17s Done\n"
     ]
    }
   ],
   "source": [
    "indent(reset=True)\n",
    "info('counting objects ...')\n",
    "for otype in F.otype.all:\n",
    "    i = 0\n",
    "    indent(level=1, reset=True)\n",
    "    for n in F.otype.s(otype): i+=1\n",
    "    info('{:>7} {}s'.format(i, otype))\n",
    "indent(level=0)\n",
    "info('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature statistics\n",
    "\n",
    "The content data resides in the features.\n",
    "The\n",
    "[`F` function](https://github.com/ETCBC/text-fabric/wiki/Api#node-features)\n",
    "gives access to that data.\n",
    "Every feature has a method\n",
    "[`freqList()`](https://github.com/ETCBC/text-fabric/wiki/Api#node-features)\n",
    "to generate a frequency list of its values, ordered by highest frequency first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('ca', 3880),\n",
       " ('tu', 1547),\n",
       " ('na', 1333),\n",
       " ('sa', 757),\n",
       " ('iti', 732),\n",
       " ('tathā', 672),\n",
       " ('vā', 529),\n",
       " ('eva', 516),\n",
       " ('hi', 420),\n",
       " ('caiva', 372))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.word.freqList()[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word distribution\n",
    "\n",
    "Let's do a bit more fancy word stuff.\n",
    "\n",
    "## Hapaxes\n",
    "\n",
    "A hapax is a word with frequency one.\n",
    "\n",
    "We count the number of hapaxes and print 10 of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53749 hapaxes found:\n",
      "\tbuddhāya\n",
      "\tsarvahatāndhakāraḥ\n",
      "\tsaṃsārapaṅkājjagadujjahāra\n",
      "\tyathārthaśāstre\n",
      "\tpravakṣyāmyabhidharmakośam\n",
      "\tprajñāmalā\n",
      "\tsānucarābhidharmaḥ\n",
      "\ttatprāptaye\n",
      "\tyāpi\n",
      "\ttasyārthato'smin\n"
     ]
    }
   ],
   "source": [
    "hapaxes = F.freq.s(1)\n",
    "print('{} hapaxes found:\\n\\t{}'.format(len(hapaxes), '\\n\\t'.join(F.word.v(w) for w in hapaxes[0:10])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Small occurrence base\n",
    "\n",
    "The occurrence base of a lexeme are the verses, chapters and books in which occurs.\n",
    "Let's look for lexemes that occur in a single book and nowhere else.\n",
    "\n",
    "Oh yes, we have already found the hapaxes, we will skip them here.\n",
    "\n",
    "We compile a dictionary, keyed by word, and with values the set of books they occur in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56788 words are confined to their book\n"
     ]
    }
   ],
   "source": [
    "wordInBooks = collections.defaultdict(set)\n",
    "\n",
    "for w in F.otype.s('word'):\n",
    "    word = F.word.v(w)\n",
    "    b = L.u(w, otype='book')[0]\n",
    "    bookName = F.book.v(b)\n",
    "    wordInBooks[word].add(bookName)\n",
    "\n",
    "singleBookWords = {word for word in wordInBooks if len(wordInBooks[word]) == 1}\n",
    "print('{} words are confined to their book'.format(len(singleBookWords)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is not surprising. But let's get some more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confined to   1 books:   56788 words\n",
      "Confined to   2 books:    5453 words\n",
      "Confined to   3 books:    1873 words\n",
      "Confined to   4 books:     934 words\n",
      "Confined to   5 books:     550 words\n",
      "Confined to   6 books:     344 words\n",
      "Confined to   7 books:     215 words\n",
      "Confined to   8 books:     178 words\n",
      "Confined to   9 books:     116 words\n",
      "Confined to  10 books:      86 words\n",
      "Confined to  11 books:      73 words\n",
      "Confined to  12 books:      60 words\n",
      "Confined to  13 books:      57 words\n",
      "Confined to  14 books:      32 words\n",
      "Confined to  15 books:      27 words\n",
      "Confined to  16 books:      20 words\n",
      "Confined to  17 books:      18 words\n",
      "Confined to  18 books:      29 words\n",
      "Confined to  19 books:      22 words\n",
      "Confined to  20 books:      10 words\n",
      "Confined to  21 books:      15 words\n",
      "Confined to  22 books:       5 words\n",
      "Confined to  23 books:      11 words\n",
      "Confined to  24 books:       6 words\n",
      "Confined to  25 books:      12 words\n",
      "Confined to  26 books:       9 words\n",
      "Confined to  27 books:       8 words\n",
      "Confined to  28 books:       7 words\n",
      "Confined to  29 books:       2 words\n",
      "Confined to  30 books:       5 words\n",
      "Confined to  31 books:       2 words\n",
      "Confined to  32 books:       4 words\n",
      "Confined to  33 books:       4 words\n",
      "Confined to  34 books:       6 words\n",
      "Confined to  35 books:       1 words\n",
      "Confined to  36 books:       5 words\n",
      "Confined to  37 books:       2 words\n",
      "Confined to  38 books:       3 words\n",
      "Confined to  39 books:       3 words\n",
      "Confined to  40 books:       2 words\n",
      "Confined to  41 books:       2 words\n",
      "Confined to  42 books:       3 words\n",
      "Confined to  43 books:       3 words\n",
      "Confined to  45 books:       1 words\n",
      "Confined to  46 books:       4 words\n",
      "Confined to  47 books:       1 words\n",
      "Confined to  48 books:       4 words\n",
      "Confined to  50 books:       2 words\n",
      "Confined to  51 books:       2 words\n",
      "Confined to  52 books:       3 words\n",
      "Confined to  55 books:       2 words\n",
      "Confined to  56 books:       1 words\n",
      "Confined to  57 books:       3 words\n",
      "Confined to  58 books:       1 words\n",
      "Confined to  61 books:       1 words\n",
      "Confined to  63 books:       1 words\n",
      "Confined to  65 books:       1 words\n",
      "Confined to  66 books:       1 words\n",
      "Confined to  67 books:       1 words\n",
      "Confined to  68 books:       1 words\n",
      "Confined to  76 books:       1 words\n",
      "Confined to  81 books:       1 words\n",
      "Confined to  82 books:       1 words\n",
      "Confined to  84 books:       1 words\n",
      "Confined to  88 books:       1 words\n",
      "Confined to  94 books:       1 words\n",
      "Confined to  97 books:       1 words\n",
      "Confined to  98 books:       1 words\n",
      "Confined to 114 books:       1 words\n",
      "Confined to 115 books:       1 words\n",
      "Confined to 118 books:       1 words\n",
      "Confined to 130 books:       1 words\n",
      "Confined to 153 books:       1 words\n"
     ]
    }
   ],
   "source": [
    "wordAmountBooks = collections.Counter()\n",
    "for (word, bookSet) in wordInBooks.items():\n",
    "    wordAmountBooks[len(bookSet)] += 1\n",
    "for (nBooks, nWords) in sorted(wordAmountBooks.items()):\n",
    "    print('Confined to {:>3} books: {:>7} words'.format(nBooks, nWords))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next thing to know is: which books are the most particular,\n",
    "in the sense that they have the highest fraction of lexemes that \n",
    "do not occur in other books?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   2    2 100.0% Cakra (?) on Suśr\n",
      "   1    1 100.0% Arthaśāstra\n",
      "   1    1 100.0% Āyurvedadīpikā\n",
      "  33   28 84.8% Vātūlanāthasūtras\n",
      " 137  109 79.6% Kādambarīsvīkaraṇasūtramañjarī\n",
      " 148  117 79.1% Aṣṭādhyāyī\n",
      "   9    7 77.8% Indu (ad AHS)\n",
      " 333  253 76.0% Trikāṇḍaśeṣa\n",
      "1239  940 75.9% Daśakumāracarita\n",
      " 282  213 75.5% Sūryaśataka\n",
      "1258  936 74.4% Haṃsadūta\n",
      "1569 1163 74.1% Nighaṇṭuśeṣa\n",
      "1018  745 73.2% Laṅkāvatārasūtra\n",
      " 269  194 72.1% Ṛtusaṃhāra\n",
      " 728  525 72.1% Nāṭyaśāstravivṛti\n",
      " 182  131 72.0% Rasikapriyā\n",
      " 224  160 71.4% Kauśikasūtradārilabhāṣya\n",
      " 363  255 70.2% Gītagovinda\n",
      "  30   21 70.0% Kāśikāvṛtti\n",
      "2336 1624 69.5% Amarakośa\n",
      " 525  364 69.3% Bījanighaṇṭu\n",
      "1610 1109 68.9% Amaruśataka\n",
      " 215  148 68.8% Kāmasūtra\n",
      "  41   28 68.3% Śivasūtra\n",
      " 141   96 68.1% Yogasūtra\n",
      "1045  700 67.0% Meghadūta\n",
      " 257  172 66.9% Rasendracūḍāmaṇi\n",
      "   9    6 66.7% Kāvyālaṃkāravṛtti\n",
      "   6    4 66.7% Rasādhyāyaṭīkā\n",
      " 650  433 66.6% Kumārasaṃbhava\n",
      " 346  230 66.5% Śatapathabrāhmaṇa\n",
      "5500 3648 66.3% Kātyāyanasmṛti\n",
      "  80   53 66.2% Sūryaśatakaṭīkā\n",
      "2141 1413 66.0% Tantrākhyāyikā\n",
      "1742 1139 65.4% Kṛṣiparāśara\n",
      " 802  524 65.3% Tarkasaṃgraha\n",
      " 149   97 65.1% Parāśarasmṛtiṭīkā\n",
      " 932  604 64.8% Buddhacarita\n",
      "  17   11 64.7% Padārthacandrikā\n",
      "3023 1938 64.1% Rasādhyāya\n",
      "  44   28 63.6% Nibandhasaṃgraha\n",
      "3121 1986 63.6% Aṣṭāṅganighaṇṭu\n",
      " 343  218 63.6% Abhidharmakośa\n",
      "1925 1223 63.5% Rasakāmadhenu\n",
      " 137   87 63.5% Paramānandīyanāmamālā\n",
      "  68   43 63.2% Nirukta\n",
      " 864  541 62.6% Nāṭyaśāstra\n",
      " 138   86 62.3% Bhramarāṣṭaka\n",
      "  70   43 61.4% Gṛhastharatnākara\n",
      "1623  995 61.3% Dhanurveda\n",
      " 492  301 61.2% Saṅghabhedavastu\n",
      " 692  421 60.8% Nāḍīparīkṣā\n",
      "  56   34 60.7% Carakatattvapradīpikā\n",
      " 430  261 60.7% Kāvyālaṃkāra\n",
      " 148   89 60.1% Kauśikasūtra\n",
      " 135   81 60.0% Nyāyasūtra\n",
      " 187  112 59.9% Gautamadharmasūtra\n",
      " 566  337 59.5% Sūryasiddhānta\n",
      "1736 1026 59.1% Gopathabrāhmaṇa\n",
      "  22   13 59.1% Nyāyabhāṣya\n",
      " 107   63 58.9% Tattvavaiśāradī\n",
      " 997  587 58.9% Kaiyadevanighaṇṭu\n",
      "2741 1612 58.8% Yājñavalkyasmṛti\n",
      " 516  303 58.7% Rasataraṅgiṇī\n",
      "2132 1244 58.3% Haribhaktivilāsa\n",
      " 314  183 58.3% Bodhicaryāvatāra\n",
      "2575 1500 58.3% Mahābhārata\n",
      " 489  283 57.9% Viṣṇusmṛti\n",
      " 388  224 57.7% Aṣṭāṅgahṛdayasaṃhitā\n",
      " 591  340 57.5% Sāṃkhyakārikā\n",
      " 946  542 57.3% Carakasaṃhitā\n",
      " 462  264 57.1% Amaraughaśāsana\n",
      " 203  116 57.1% Kirātārjunīya\n",
      " 140   80 57.1% Bhadrabāhucarita\n",
      "  84   48 57.1% Pāśupatasūtra\n",
      "1580  902 57.1% Janmamaraṇavicāra\n",
      "  93   53 57.0% Hārāṇacandara on Suśr\n",
      " 434  246 56.7% Suśrutasaṃhitā\n",
      " 756  427 56.5% Bṛhatkathāślokasaṃgraha\n",
      "1955 1104 56.5% Rasārṇavakalpa\n",
      "  62   35 56.5% Commentary on the Kādambarīsvīkaraṇasūtramañjarī\n",
      " 163   92 56.4% Sphuṭārthāvyākhyā\n",
      " 109   61 56.0% Spandakārikānirṇaya\n",
      " 226  126 55.8% Sāṃkhyatattvakaumudī\n",
      "   9    5 55.6% Rājanighaṇṭu\n",
      " 848  469 55.3% Kāvyādarśa\n",
      " 247  136 55.1% Tantrasāra\n",
      " 160   88 55.0% Viṃśatikākārikā\n",
      " 386  212 54.9% Aṣṭāṅgasaṃgraha\n",
      " 490  268 54.7% Śivapurāṇa\n",
      "1057  577 54.6% Rasaprakāśasudhākara\n",
      " 101   55 54.5% Ṭikanikayātrā\n",
      " 206  112 54.4% Smaradīpikā\n",
      "2123 1154 54.4% Madanapālanighaṇṭu\n",
      " 241  131 54.4% Kālikāpurāṇa\n",
      "  92   50 54.3% Kāṭhakagṛhyasūtra\n",
      "2762 1497 54.2% Yogaratnākara\n",
      " 198  107 54.0% Skandapurāṇa\n",
      " 198  106 53.5% Spandakārikā\n",
      " 256  137 53.5% Śāktavijñāna\n",
      " 154   82 53.2% Ānandakanda\n",
      "  98   52 53.1% Vaiśeṣikasūtra\n",
      "  87   46 52.9% Rasikasaṃjīvanī\n",
      " 455  239 52.5% Acintyastava\n",
      " 674  354 52.5% Rāmāyaṇa\n",
      "1630  849 52.1% Dhanvantarinighaṇṭu\n",
      " 471  244 51.8% Gheraṇḍasaṃhitā\n",
      "  56   29 51.8% Nyāyabindu\n",
      " 203  105 51.7% Śvetāśvataropaniṣad\n",
      "  58   30 51.7% Yogasūtrabhāṣya\n",
      " 327  169 51.7% Garuḍapurāṇa\n",
      "1601  823 51.4% Bhāvaprakāśa\n",
      " 109   56 51.4% Bhairavastava\n",
      "2595 1331 51.3% Rasendrasārasaṃgraha\n",
      " 177   90 50.8% Mugdhāvabodhinī\n",
      " 459  231 50.3% Maṇimāhātmya\n",
      "  28   14 50.0% Vātūlanāthasūtravṛtti\n",
      "   2    1 50.0% Triṃśatikāvṛtti\n",
      " 515  257 49.9% Sarvadarśanasaṃgraha\n",
      " 464  231 49.8% Vetālapañcaviṃśatikā\n",
      " 121   60 49.6% Rasaratnasamuccayaṭīkā\n",
      " 332  164 49.4% Garbhopaniṣat\n",
      " 594  293 49.3% Uḍḍāmareśvaratantra\n",
      " 292  144 49.3% Vṛddhayamasmṛti\n",
      " 618  302 48.9% Haṭhayogapradīpikā\n",
      " 260  127 48.8% Bhāgavatapurāṇa\n",
      " 189   92 48.7% Toḍalatantra\n",
      " 473  229 48.4% Ratnadīpikā\n",
      " 364  176 48.4% Varāhapurāṇa\n",
      "  56   27 48.2% Prasannapadā\n",
      "  50   24 48.0% Rasaratnasamuccayadīpikā\n",
      "1594  765 48.0% Kṛṣṇāmṛtamahārṇava\n",
      " 286  137 47.9% Rasaratnākara\n",
      " 925  441 47.7% Kūrmapurāṇa\n",
      "  61   29 47.5% Gaṇakārikā\n",
      " 966  449 46.5% Manusmṛti\n",
      " 556  256 46.0% Nāradasmṛti\n",
      " 296  136 45.9% Matsyapurāṇa\n",
      " 118   54 45.8% Baudhāyanadharmasūtra\n",
      "  77   35 45.5% Ṛgvedavedāṅgajyotiṣa\n",
      " 418  189 45.2% Rasasaṃketakalikā\n",
      "  20    9 45.0% Rājamārtaṇḍa\n",
      " 380  169 44.5% Rasendracintāmaṇi\n",
      " 276  122 44.2% Mṛgendratantra\n",
      " 769  339 44.1% Gokarṇapurāṇasāraḥ\n",
      " 683  301 44.1% Rasaratnasamuccaya\n",
      " 434  190 43.8% Skandapurāṇa (Revākhaṇḍa)\n",
      " 470  204 43.4% Sātvatatantra\n",
      " 197   85 43.1% Nādabindūpaniṣat\n",
      "  21    9 42.9% Vaiśeṣikasūtravṛtti\n",
      " 200   85 42.5% Liṅgapurāṇa\n",
      "  88   37 42.0% Rasaratnasamuccayabodhinī\n",
      "  86   36 41.9% Aitareyopaniṣad\n",
      " 540  226 41.9% Hitopadeśa\n",
      " 221   92 41.6% Sāṃkhyakārikābhāṣya\n",
      " 870  358 41.1% Gorakṣaśataka\n",
      " 202   83 41.1% Aṣṭavakragīta\n",
      " 118   48 40.7% Mūlamadhyamakārikāḥ\n",
      " 668  265 39.7% Śira'upaniṣad\n",
      " 346  137 39.6% Agastīyaratnaparīkṣā\n",
      "  81   32 39.5% Ayurvedarasāyana\n",
      " 109   43 39.4% Chāndogyopaniṣad\n",
      " 271  106 39.1% Viṣṇupurāṇa\n",
      " 169   66 39.1% Agnipurāṇa\n",
      " 200   78 39.0% Brahmabindūpaniṣat\n",
      "  72   28 38.9% Amṛtabindūpaniṣat\n",
      "  18    7 38.9% Comm. on the Kāvyālaṃkāravṛtti\n",
      " 343  133 38.8% Mahācīnatantra\n",
      "  26   10 38.5% Commentary on Amaraughaśāsana\n",
      " 197   72 36.5% Mātṛkābhedatantra\n",
      " 334  122 36.5% Rasamañjarī\n",
      " 148   53 35.8% Parāśaradharmasaṃhitā\n",
      "  65   22 33.8% Śārṅgadharasaṃhitā\n",
      " 452  149 33.0% Rasārṇava\n",
      "  75   23 30.7% Śivasūtravārtika\n",
      "  24    7 29.2% Sarvāṅgasundarā\n",
      "  59   17 28.8% Abhidharmakośabhāṣya\n",
      " 286   57 19.9% Rasahṛdayatantra\n",
      "   1    0  0.0% Ekākṣarakoṣa\n",
      "   1    0  0.0% Gaṇakārikāṭīkā\n",
      "   1    0  0.0% Gūḍhārthadīpikā\n",
      "   1    0  0.0% Nāḍīvijñāna\n",
      "   1    0  0.0% Pañcārthabhāṣya\n"
     ]
    }
   ],
   "source": [
    "bookList = []\n",
    "\n",
    "for b in F.otype.s('book'):\n",
    "    book = F.book.v(b)\n",
    "    allWords = {F.word.v(w) for w in L.d(b, otype='word')}\n",
    "    ownWords = allWords & singleBookWords\n",
    "    percentage = 100 * len(ownWords) / len(allWords)\n",
    "    bookList.append((len(allWords), len(ownWords), percentage, book))\n",
    "\n",
    "for x in sorted(bookList, key=lambda e: (-e[2], -e[0], e[3])):\n",
    "    print('{:>4} {:>4} {:>4.1f}% {}'.format(*x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layer API\n",
    "We travel upwards and downwards, forwards and backwards through the nodes.\n",
    "The Layer-API (`L`) provides functions: `u()` for going up, and `d()` for going down,\n",
    "`n()` for going to next nodes and `p()` for going to previous nodes.\n",
    "\n",
    "These directions are indirect notions: nodes are just numbers, but by means of the\n",
    "`oslots` feature they are linked to slots. One node *contains* an other node, if the one is linked to a set of slots that contains the set of slots that the other is linked to.\n",
    "And one if next or previous to an other, if its slots follow of precede the slots of the other one.\n",
    "\n",
    "`L.u(node)` **Up** is going to nodes that embed `node`.\n",
    "\n",
    "`L.d(node)` **Down** is the opposite direction, to those that are contained in `node`.\n",
    "\n",
    "`L.n(node)` **Next** are the next *adjacent* nodes, i.e. nodes whose first slot comes immediately after the last slot of `node`.\n",
    "\n",
    "`L.p(node)` **Previous** are the previous *adjacent* nodes, i.e. nodes whose last slot comes immediately before the first slot of `node`.\n",
    "\n",
    "All these functions yield nodes of all possible otypes.\n",
    "By passing an optional parameter, you can restrict the results to nodes of that type.\n",
    "\n",
    "The result is ordered in the canonical node ordering.\n",
    "The functions return always a tuple, even if there is just one node in the result.\n",
    "\n",
    "## Going up\n",
    "We go from the first letter to the book it contains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1336528\n"
     ]
    }
   ],
   "source": [
    "firstBook = L.u(1, otype='book')[0]\n",
    "print(firstBook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's see all the containing objects of letter 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "letter 3 is contained in book 1336528\n",
      "letter 3 is contained in chapter 1323518\n",
      "letter 3 is contained in verse 1297789\n",
      "letter 3 is contained in word 1161381\n"
     ]
    }
   ],
   "source": [
    "w = 3\n",
    "for otype in F.otype.all:\n",
    "    if otype == F.otype.slotType: continue\n",
    "    up = L.u(w, otype=otype)\n",
    "    upNode = 'x' if len(up) == 0 else up[0]\n",
    "    print('letter {} is contained in {} {}'.format(w, otype, upNode))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Going next\n",
    "Let's go to the next nodes of the first book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   4151: letter        first slot=4151  , last slot=4151  \n",
      "1161789: word          first slot=4151  , last slot=4155  \n",
      "1297887: verse         first slot=4151  , last slot=4199  \n",
      "1323567: chapter       first slot=4151  , last slot=4199  \n",
      "1336529: book          first slot=4151  , last slot=4726  \n"
     ]
    }
   ],
   "source": [
    "afterFirstBook = L.n(firstBook)\n",
    "for n in afterFirstBook:\n",
    "    print('{:>7}: {:<13} first slot={:<6}, last slot={:<6}'.format(\n",
    "        n, F.otype.v(n),\n",
    "        E.oslots.s(n)[0],\n",
    "        E.oslots.s(n)[-1],\n",
    "    ))\n",
    "secondBook = L.n(firstBook, otype='book')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Going previous\n",
    "\n",
    "And let's see what is right before the second book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1336528: book          first slot=1     , last slot=4150  \n",
      "1323566: chapter       first slot=4084  , last slot=4150  \n",
      "1297886: verse         first slot=4084  , last slot=4150  \n",
      "1161788: word          first slot=4140  , last slot=4150  \n",
      "   4150: letter        first slot=4150  , last slot=4150  \n"
     ]
    }
   ],
   "source": [
    "for n in L.p(secondBook):\n",
    "    print('{:>7}: {:<13} first slot={:<6}, last slot={:<6}'.format(\n",
    "        n, F.otype.v(n),\n",
    "        E.oslots.s(n)[0],\n",
    "        E.oslots.s(n)[-1],\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Going down"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We go to the chapters of the second book, and just count them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "chapters = L.d(secondBook, otype='chapter')\n",
    "print(len(chapters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The first verse\n",
    "We pick the first verse and the first word, and explore what is above and below them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 1\n",
      "   |   UP\n",
      "   |      |   1161380         word\n",
      "   |      |   1297789         verse\n",
      "   |      |   1323518         chapter\n",
      "   |      |   1336528         book\n",
      "   |   DOWN\n",
      "   |      |   \n",
      "Node 1297789\n",
      "   |   UP\n",
      "   |      |   1323518         chapter\n",
      "   |      |   1336528         book\n",
      "   |   DOWN\n",
      "   |      |   1161380         word\n",
      "   |      |   1               letter\n",
      "   |      |   2               letter\n",
      "   |      |   1161381         word\n",
      "   |      |   3               letter\n",
      "   |      |   4               letter\n",
      "   |      |   5               letter\n",
      "   |      |   6               letter\n",
      "   |      |   1161382         word\n",
      "   |      |   7               letter\n",
      "   |      |   8               letter\n",
      "   |      |   9               letter\n",
      "   |      |   10              letter\n",
      "   |      |   11              letter\n",
      "   |      |   12              letter\n",
      "   |      |   13              letter\n",
      "   |      |   14              letter\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "for n in [1, L.u(1, otype='verse')[0]]:\n",
    "    indent(level=0)\n",
    "    info('Node {}'.format(n), tm=False)\n",
    "    indent(level=1)\n",
    "    info('UP', tm=False)\n",
    "    indent(level=2)\n",
    "    info('\\n'.join(['{:<15} {}'.format(u, F.otype.v(u)) for u in L.u(n)]), tm=False)\n",
    "    indent(level=1)\n",
    "    info('DOWN', tm=False)\n",
    "    indent(level=2)\n",
    "    info('\\n'.join(['{:<15} {}'.format(u, F.otype.v(u)) for u in L.d(n)]), tm=False)\n",
    "indent(level=0)\n",
    "info('Done', tm=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text API\n",
    "\n",
    "We examine the functions of the Text API: `T`.\n",
    "\n",
    "## Formats\n",
    "First the formats that we have available to represent the actual text.\n",
    "These formats have been defined in the `otext` feature.\n",
    "This is an optional GRID config feature: it has only metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['text-orig-full', 'text-orig-segmented']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(T.formats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the formats\n",
    "Now let's use those formats to print out the first 100 characters of the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text-orig-full:\n",
      "\tomnamobuddhāyayaḥsarvathāsarvahatāndhakāraḥsaṃsārapaṅkājjagadujjahāratasmainamaskṛtyayathārthaśāstr\n",
      "text-orig-segmented:\n",
      "\tom namo buddhāya yaḥ sarvathā sarvahatāndhakāraḥ saṃsārapaṅkājjagadujjahāra tasmai namaskṛtya yathārthaśāstr\n"
     ]
    }
   ],
   "source": [
    "for fmt in sorted(T.formats):\n",
    "    print('{}:\\n\\t{}'.format(fmt, T.text(range(1,100), fmt=fmt)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we do not specify a format, the **default** format is used (`text-orig-full`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "omnamobuddhāyayaḥsarvathāsarvahatāndhakāraḥsaṃsārapaṅkājjagadujjahāratasmainamaskṛtyayathārthaśāstr\n"
     ]
    }
   ],
   "source": [
    "print(T.text(range(1,100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Whole text in all formats in just 10 seconds\n",
    "We are going to produce the complete text of the whole corpus in all available formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.00s writing plain text of whole Bible in all formats\n",
      "  5.31s done 2 formats\n",
      "text-orig-full\n",
      "omnamobuddhāya\n",
      "yaḥsarvathāsarvahatāndhakāraḥsaṃsārapaṅkājjagadujjahāra\n",
      "tasmainamaskṛtyayathārthaśāstreśāstraṃpravakṣyāmyabhidharmakośam\n",
      "prajñāmalāsānucarābhidharmaḥtatprāptayeyāpicayaccaśāstram\n",
      "tasyārthato'sminsamanupraveśātsacāśrayo'syetyabhidharmakośam\n",
      "\n",
      "text-orig-segmented\n",
      "om namo buddhāya \n",
      "yaḥ sarvathā sarvahatāndhakāraḥ saṃsārapaṅkājjagadujjahāra \n",
      "tasmai namaskṛtya yathārthaśāstre śāstraṃ pravakṣyāmyabhidharmakośam \n",
      "prajñāmalā sānucarābhidharmaḥ tatprāptaye yāpi ca yacca śāstram \n",
      "tasyārthato'smin samanupraveśāt sa cāśrayo 'syetyabhidharmakośam \n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = collections.defaultdict(list)\n",
    "indent(reset=True)\n",
    "info('writing plain text of whole Bible in all formats')\n",
    "for v in F.otype.s('verse'):\n",
    "    letters = L.d(v, 'letter')\n",
    "    for fmt in sorted(T.formats):\n",
    "        text[fmt].append(T.text(letters, fmt=fmt))\n",
    "info('done {} formats'.format(len(text)))\n",
    "for fmt in sorted(text):\n",
    "    print('{}\\n{}\\n'.format(fmt, '\\n'.join(text[fmt][0:5])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
