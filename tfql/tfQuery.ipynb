{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"right\" src=\"tf-small.png\"/>\n",
    "\n",
    "# tfQuery\n",
    "\n",
    "Do we need a query language in TF, like MQL?\n",
    "\n",
    "Yes, it is convenient to have a more declarative way of getting a set of interesting nodes to work with.\n",
    "But should it be MQL?\n",
    "\n",
    "Experience shows that MQL may give you a very good first try, \n",
    "until you realize that you may not have queried for all cases.\n",
    "You forgot to query for some elements in a different order.\n",
    "You have not reckoned with gaps.\n",
    "And the query does not give you interesting things from the context with the results.\n",
    "Also, MQL does not work nicely with object types that are scattered through other object types, such as the\n",
    "[*lexeme*](https://etcbc.github.io/text-fabric-data/features/hebrew/etcbc4c/otype.html)\n",
    "type.\n",
    "\n",
    "Look in SHEBANQ for examples how unwieldy MQL queries may become.\n",
    "\n",
    "Here is a good example:\n",
    "\n",
    "[Dirk Roorda: Yesh](https://shebanq.ancient-data.org/hebrew/query?version=4b&id=556)\n",
    "\n",
    "```\n",
    "select all objects where\n",
    "[book [chapter [verse\n",
    "[clause\n",
    "    [clause_atom\n",
    "        [phrase\n",
    "            [phrase_atom\n",
    "                [word focus lex=\"JC/\" OR lex=\">JN/\"]\n",
    "            ]\n",
    "        ]\n",
    "    ]\n",
    "]\n",
    "]]]\n",
    "```\n",
    "\n",
    "Well, this is not too complicated, but the query misses results.\n",
    "See [here](https://etcbc.github.io/text-fabric-data/features/hebrew/etcbc4c/0_mql.html)\n",
    "to see what would be needed to make it right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, I wonder: do we want a new language?\n",
    "Suppose we make a TFQL, then we need a parser for it,\n",
    "we need to define a syntax, we need to refine the syntax, update the parser, etc.\n",
    "It will become a cumbersome straight-jacket.\n",
    "\n",
    "In our case, we do not have the requirement that non-coders should be able to use TFQL in a stand-alone manner.\n",
    "\n",
    "On the contrary, TFQL should live in a programming environment, and we can take advantage of that.\n",
    "\n",
    "Here are initial thought for **tfQuery**, a query *mechanism* inside TF, not a *language*.\n",
    "\n",
    "* tfQuery defines queries as data structures in Python, more precisely: as a graph\n",
    "* it does not matter how you build up a query, tfQuery processses the value of a datastructure\n",
    "  that you pass to it. The surface syntax will not be seen by tfQuery\n",
    "* a query is a graph representation where the nodes are things like\n",
    "  \n",
    "  `('phrase', dict(det='und'))`\n",
    "  \n",
    "  or\n",
    "  \n",
    "  `('word', dict(sp='verb', gn='f', ps='3f'))`\n",
    "\n",
    "* the edges specify relations between the nodes, like: *is contained in*, *follows*,\n",
    "  *precedes*\n",
    "  \n",
    "In MQL you also specify a graph, by means of a template, but this template forces you to *overspecify*: the template often implies more constraints then you really want.\n",
    "\n",
    "So how do we specify edges? As constraints.\n",
    "\n",
    "Let us formulate a query for\n",
    "\n",
    "* clauses that are object clauses\n",
    "* containing two phrases (both undetermined)\n",
    "* one of which contains a verb in the third person feminine\n",
    "* and the other phrase contains a feminine, plural noun\n",
    "\n",
    "In MQL\n",
    "\n",
    "```\n",
    "[clause rela='Objc'\n",
    "    [phrase det='und'\n",
    "        [word sp='verb' AND gn='f' AND ps='p3']\n",
    "    ]\n",
    "    [phrase det='und'\n",
    "        [word sp='subs' AND gn='f' AND nu='pl']\n",
    "    ]\n",
    "]\n",
    "```\n",
    "\n",
    "Here is how we are going to do it,\n",
    "and note that we are going to write executable code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c = ('clause', dict(rela='Objc'))\n",
    "p1 = ('phrase', dict(det='und'))\n",
    "p2 = ('phrase', dict(det='und'))\n",
    "w1 = ('word', dict(sp='verb', gn='f', ps='p3'))\n",
    "w2 = ('word', dict(sp='subs', gn='f', nu='pl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nodes = [c, p1, p2, w1, w2]\n",
    "edges = [\n",
    "    (c, [p1,p2]),\n",
    "    (p1, [w1]),\n",
    "    (p2, [w2]),\n",
    "    (p1, p2),\n",
    "]\n",
    "\n",
    "query = (nodes, edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An edge of like `(x, [y,z])` means that `y` and `z` are embedded in `x`, but does not mean\n",
    "that `y` comes before `z`.\n",
    "\n",
    "An edge like `(x, y)` means that `x` comes before `y`.\n",
    "\n",
    "## Increased flexibility\n",
    "\n",
    "Note that it is very easy to remove the `(p1, p2)` condition, which states that the first\n",
    "phrase comes before the second one.\n",
    "\n",
    "If we wanted to do that in MQL, the query would become:\n",
    "\n",
    "```\n",
    "[clause rela='Objc'\n",
    "    [phrase det='und'\n",
    "        [word sp='verb' AND gn='f' AND ps='p3']\n",
    "    ]\n",
    "    [phrase det='und'\n",
    "        [word sp='subs' AND gn='f' AND nu='pl']\n",
    "    ]\n",
    "    OR\n",
    "    [phrase det='und'\n",
    "        [word sp='subs' AND gn='f' AND nu='pl']\n",
    "    ]\n",
    "    [phrase det='und'\n",
    "        [word sp='verb' AND gn='f' AND ps='p3']\n",
    "    ]\n",
    "]\n",
    "```\n",
    "\n",
    "This goes quickly out of hand, see e.g.\n",
    "[Dirk Roorda: Object clauses of verbless mothers](https://shebanq.ancient-data.org/hebrew/query?id=984) and accompanying\n",
    "[notebook](https://shebanq.ancient-data.org/shebanq/static/docs/tools/shebanq/VerblessMothers.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query results\n",
    "\n",
    "What should we return as query results?\n",
    "Do we want every instantiation of the nodes that satisfy the criteria?\n",
    "\n",
    "That can become overwhelming. \n",
    "If for example you search for a word in a book, an other word in the same book, and a third word in the same book without further constraints, then for a book with 10,000 words you'll get 10,000 * 10,000 * 10,000 results or 1 Tera results, which is, even for a computer, a bit much.\n",
    "\n",
    "This is why Ulrik invented the sheaf.\n",
    "\n",
    "Our way of solving this problem could be like this:\n",
    "\n",
    "* we return a collection of node lists: for each node in the query we return the \n",
    "  corresponding node list;\n",
    "* these lists consist of TF nodes which are guaranteed to occur in at least one\n",
    "  instantatiation of the whole graph;\n",
    "* we return nothing else.\n",
    "\n",
    "It is up to the user to pick one of these nodesets and to further process them.\n",
    "If he needs needs context around the result nodes, he can easily draw the info from there.\n",
    "\n",
    "It is even possible to generate the code to get full results from the original query graph.\n",
    "\n",
    "So the real result is two things:\n",
    "\n",
    "* a collection of node lists\n",
    "* a function to look up other result nodes in the context of a given result node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "\n",
    "How could we implement this search efficiently?\n",
    "\n",
    "First idea:\n",
    "\n",
    "* build for each query graph node\n",
    "  (which corresponds to a local feature condition on an object)\n",
    "  the set of nodes that satisfy the condition.\n",
    "  This is the easy part:\n",
    "  A single walk over all nodes could construct these sets in one go, in a fraction\n",
    "  of a second;\n",
    "* then work through all edges, where every edge is an instruction to weed out non-results\n",
    "  from the earlier obtained sets.\n",
    "  \n",
    "How would that work, filtering along an edge in the graph?\n",
    "\n",
    "Suppose there is an edge from node1 to node2 (in the query graph).\n",
    "This edge specifies a relationship between nodes in the result nodeset of n1 and nodes \n",
    "in the result nodeset of n2.\n",
    "\n",
    "In English: such an edge says: hey TF node in result set of n1: \n",
    "do you have a parent (or child, or older brother or younger sister)\n",
    "that occurs in the result of n2?\n",
    "\n",
    "If so: you can stay. If not: you're OUT.\n",
    "So this weeds out TF nodes from the result set of n1.\n",
    "\n",
    "But we can also reduce the nodes in the result set of n2.\n",
    "Every TF node in the result set of n2 that does not figure as the parent\n",
    "(or child or brother/sister) of a TF node in the result set of n1 is also out.\n",
    "\n",
    "In this way we can take every edge, one by one, and perform the filtering.\n",
    "This is also a fast operation, provided we can make the elementary relationship checks\n",
    "quickly. (And we can, in TF, thanks to precomputing).\n",
    "\n",
    "When we have done all edges, we probably have to iterate again over all edges.\n",
    "\n",
    "Because an edge between n2 and n3 could have weeded out additional TF nodes from the \n",
    "result set of n2, and this influences the validity of the TF nodes in the result set of n1.\n",
    "\n",
    "Probably we have to repeat until the result sets do not change anymore.\n",
    "\n",
    "Or we can find a way to order the edges, so that we can do them in one or two passes.\n",
    "\n",
    "Maybe we need a bit of math here.\n",
    "\n",
    "My gut feeling is that this is all very doable and that it corresponds to people's query\n",
    "needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys, collections\n",
    "from tf.fabric import Fabric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Text-Fabric 1.2.7\n",
      "Api reference : https://github.com/ETCBC/text-fabric/wiki/Api\n",
      "Tutorial      : https://github.com/ETCBC/text-fabric/blob/master/docs/tutorial.ipynb\n",
      "Data sources  : https://github.com/ETCBC/text-fabric-data\n",
      "Data docs     : https://etcbc.github.io/text-fabric-data/features/hebrew/etcbc4c/0_overview.html\n",
      "Shebanq docs  : https://shebanq.ancient-data.org/text\n",
      "Slack team    : https://shebanq.slack.com/signup\n",
      "Questions? Ask shebanq@ancient-data.org for an invite to Slack\n",
      "105 features found and 0 ignored\n"
     ]
    }
   ],
   "source": [
    "ETCBC = 'hebrew/etcbc4c'\n",
    "TF = Fabric( modules=ETCBC )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.00s loading features ...\n",
      "   |     0.55s B oslots               from /Users/dirk/github/text-fabric-data/hebrew/etcbc4c\n",
      "   |     0.00s M otext                from /Users/dirk/github/text-fabric-data/hebrew/etcbc4c\n",
      "   |     0.14s B lex                  from /Users/dirk/github/text-fabric-data/hebrew/etcbc4c\n",
      "   |     0.23s B typ                  from /Users/dirk/github/text-fabric-data/hebrew/etcbc4c\n",
      "   |     0.04s B code                 from /Users/dirk/github/text-fabric-data/hebrew/etcbc4c\n",
      "   |     0.08s B function             from /Users/dirk/github/text-fabric-data/hebrew/etcbc4c\n",
      "   |     0.23s B rela                 from /Users/dirk/github/text-fabric-data/hebrew/etcbc4c\n",
      "   |     0.16s B det                  from /Users/dirk/github/text-fabric-data/hebrew/etcbc4c\n",
      "  5.54s All features loaded/computed - for details use loadLog()\n"
     ]
    }
   ],
   "source": [
    "api = TF.load('''\n",
    "    lex \n",
    "    typ code function rela det\n",
    "    oslots\n",
    "''')\n",
    "api.makeAvailableIn(globals())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Freezing\n",
    "Nodes are defined as datastructures.\n",
    "If we are going to work with them, we have to refer to them, use them as dictionary keys and so on.\n",
    "So we are going to replace them by immutable datastructures. `freeze()` is going to do just that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def freeze(d):\n",
    "    if type(d) is set: return frozenset(freeze(e) for e in d)\n",
    "    if type(d) is list or type(d) is tuple: return tuple(freeze(e) for e in d)\n",
    "    if type(d) is dict: return tuple(((e[0], freeze(e[1])) for e in sorted(d.items())))\n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling\n",
    "\n",
    "We receive the nodes and edges of a query, give the nodes a number,\n",
    "and replace the *from*- and *to*-nodes\n",
    "of the edges by the numbers of those nodes.\n",
    "\n",
    "We also build a list of otypes of the nodes, in the same order as the nodes themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compileQuery(nodes, edges):\n",
    "    otypes = []\n",
    "    compiledEdges = []\n",
    "    nodeIndex = {}\n",
    "    for (i, node) in enumerate(nodes):\n",
    "        fNode = freeze(node)\n",
    "        nodeIndex[fNode] = i\n",
    "        otypes.append(node[0])\n",
    "    for (i, (nodeFrom, nodeTo)) in enumerate(edges):\n",
    "        (fNodeFrom, fNodeTo) = (freeze(nodeFrom), freeze(nodeTo))\n",
    "        if fNodeFrom not in nodeIndex:\n",
    "            error('From part in edge {} is not a node: {}'.format(i, nodeFrom))\n",
    "            continue\n",
    "        if fNodeTo not in nodeIndex:\n",
    "            error('To part in edge {} is not a node: {}'.format(i, nodeTo))\n",
    "            continue\n",
    "        fromI = nodeIndex[fNodeFrom]\n",
    "        toI = nodeIndex[fNodeTo]\n",
    "        compiledEdges.append((fromI, toI))\n",
    "    return (otypes, compiledEdges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Atoms\n",
    "\n",
    "The first stage of running a query is to run the individual nodes as filters in their associated\n",
    "object types.\n",
    "\n",
    "A node is specified by an `otype` and a features dict.\n",
    "The features specifiy any number of features, with an allowed value or set of allowed values for each of them.\n",
    "\n",
    "Running an atom means to filter the set of all nodes in its `otype` by means of its `features`.\n",
    "\n",
    "The result list is delivered in a list of result lists, corresponding to the nodes list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def runAtom(otype, features):\n",
    "    featureList = sorted(features.items())\n",
    "    result = set()\n",
    "    for n in F.otype.s(otype):\n",
    "        good = True\n",
    "        for (ft, val) in featureList:\n",
    "            fval = Fs(ft).v(n)\n",
    "            if type(val) is str or type(val) is int:\n",
    "                if fval != val:\n",
    "                    good = False\n",
    "                    break\n",
    "            else:\n",
    "                if fval not in val:\n",
    "                    good = False\n",
    "                    break\n",
    "        if good: result.add(n)\n",
    "    return result\n",
    "\n",
    "def runAtoms(nodes, otypes, results):\n",
    "    info('Getting results for {} atoms'.format(len(nodes)))\n",
    "    for node in nodes:\n",
    "        results.append(runAtom(*node))\n",
    "        info('.', tm=False, nl=False)\n",
    "    info('\\nDone')\n",
    "    showResults(otypes, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edges\n",
    "\n",
    "Once the atoms have done their work, it is time to work out the constraints posed by edges.\n",
    "\n",
    "An edge from query node `nF` to query node `nT` means\n",
    "* that the text nodes in the result of `nF` should embed a text node in the result of `nT`,\n",
    "or equivalently,\n",
    "* that the text nodes in the result of `nT` should be embedded in a text node in the result of `nF`.\n",
    "\n",
    "This will reduce the amount of nodes in both `nF` and `nT`.\n",
    "\n",
    "### Note\n",
    "> In general, one pass over all edges will not be enough.\n",
    "We have to repeat the process until nothing changes anymore.\n",
    "\n",
    "The challenge is now to run the edges in an optimal sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def runEdge(f, t, otypes, results):\n",
    "    resultsF = results[f]\n",
    "    resultsT = results[t]\n",
    "    newResultsF = set()\n",
    "    newResultsT = set()\n",
    "    for n in resultsT:\n",
    "        fs = set(L.u(n, otype=otypes[f])) & resultsF\n",
    "        if len(fs):\n",
    "            newResultsF |= fs\n",
    "            newResultsT.add(n)\n",
    "    results[f] = newResultsF\n",
    "    results[t] = newResultsT\n",
    "\n",
    "def runEdges(compiledEdges, otypes, results, order=None):\n",
    "    info('Filtering by {} edges'.format(len(compiledEdges)))\n",
    "    cedges = compiledEdges if order == None else sorted(compiledEdges, key=order)\n",
    "    for (f, t) in compiledEdges:\n",
    "        runEdge(f, t, otypes, results)\n",
    "        info('.', tm=False, nl=False)\n",
    "    info('\\nDone')\n",
    "    showResults(otypes, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strategy\n",
    "\n",
    "Here we develop a strategy of running edges in a good sequence.\n",
    "\n",
    "The basic intuition is this.\n",
    "\n",
    "* some query nodes filter strongly, others hardly, i.e. some atom results are small compared to the total\n",
    "  number of nodes in their otype, other atom results are nearly as big as the total otype.\n",
    "* if an edge connects a strongly filtering node with a weakly filtering node, we expect a big reduction\n",
    "* if we work within the strongest filtering query nodes, we do not have to do much work and when we reach the\n",
    "  weaker filters, they will decrease rapidly\n",
    "* so we postpone to touch the bigger sets as long as possible, and when we touch them, they are expected to decrease\n",
    "  quickly\n",
    "\n",
    "We are going to rank query nodes by how strong they have filtered their otype so far.\n",
    "\n",
    "* let $o_n$ be the otype associated with query node $n$\n",
    "* let $r_n$ be the current result set associated with query node $n$\n",
    "\n",
    "\n",
    "Then the **query fraction** $q(n)$ is the a proportion between\n",
    "the number of text nodes in the current result:\n",
    "and\n",
    "the total number of text nodes in the otype:\n",
    "\n",
    "$$q(n) = {|r_n|\\over |o_n|}$$\n",
    "\n",
    "Then we rank the edges by combined query fraction of the nodes:\n",
    "\n",
    "$$ r(f,t) = q(f)^2 + q(t)^2$$\n",
    "\n",
    "By squaring both query fractions, we strongly give precedence to edges involving few results.\n",
    "\n",
    "### Iteration\n",
    "\n",
    "We can rank the edges, then run them all in the required order.\n",
    "But we can also run a single edge, and then rank a new."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def rankEdges(edges, otypes, results):\n",
    "    queryFraction = {}\n",
    "    for (i, r) in enumerate(results):\n",
    "        otype = otypes[i]\n",
    "        (begin, end) = F.otype.sInterval(otype)\n",
    "        nOtype = 1 + end - begin\n",
    "        nResults = len(r)\n",
    "        qf = nResults / nOtype\n",
    "        queryFraction[i] = qf * qf\n",
    "    return (lambda x: queryFraction[x[0]] + queryFraction[x[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query\n",
    "\n",
    "Here we put everything together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def runQuery(nodes, edges):\n",
    "    (otypes, compiledEdges) = compileQuery(nodes, edges)\n",
    "    indent(reset=True)\n",
    "    results = []\n",
    "    runAtoms(nodes, otypes, results)\n",
    "    runEdges(compiledEdges, otypes, results, order=rankEdges(compiledEdges, otypes, results))\n",
    "    info('Done')\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Showing\n",
    "\n",
    "We want to see intermediate results.\n",
    "Query results are given as a list of lists.\n",
    "Every individual result list corresponds to the results of a single node,\n",
    "subject to more or less filtering.\n",
    "Here we show the current lengths of those lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def showResults(otypes, results):\n",
    "    indent(level=1)\n",
    "    for i in range(len(results)):\n",
    "        info('{:>2}-{:<20}: {} results'.format(\n",
    "            i, otypes[i], len(results[i]),\n",
    "        ))\n",
    "    indent(level=0)\n",
    "    info('Min-Max {:>7}-{:>7}'.format(\n",
    "        min(len(r) for r in results),\n",
    "        max(len(r) for r in results),\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bk = ('book', dict())\n",
    "ch = ('chapter', dict())\n",
    "vs = ('verse', dict())\n",
    "cl = ('clause', dict())\n",
    "ca = ('clause_atom', dict())\n",
    "ph = ('phrase', dict())\n",
    "pa = ('phrase_atom', dict())\n",
    "w = ('word', dict(lex={'JC/', '>JN/'}))\n",
    "nodes = [bk, ch, vs, cl, ca, ph, pa, w]\n",
    "edges = [\n",
    "    [bk, ch],\n",
    "    [ch, vs],\n",
    "    [vs, cl],\n",
    "    [cl, ca],\n",
    "    [ca, ph],\n",
    "    [ph, pa],\n",
    "    [pa, w],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.00s Getting results for 8 atoms\n",
      "........  0.80s \n",
      "Done\n",
      "   |    1m 12s  0-book                : 39 results\n",
      "   |    1m 12s  1-chapter             : 929 results\n",
      "   |    1m 12s  2-verse               : 23213 results\n",
      "   |    1m 12s  3-clause              : 88000 results\n",
      "   |    1m 12s  4-clause_atom         : 90562 results\n",
      "   |    1m 12s  5-phrase              : 253174 results\n",
      "   |    1m 12s  6-phrase_atom         : 267515 results\n",
      "   |    1m 12s  7-word                : 926 results\n",
      "  0.81s Min-Max      39- 267515\n",
      "  0.81s Filtering by 7 edges\n",
      ".......  7.33s \n",
      "Done\n",
      "   |    1m 18s  0-book                : 39 results\n",
      "   |    1m 18s  1-chapter             : 929 results\n",
      "   |    1m 18s  2-verse               : 23207 results\n",
      "   |    1m 18s  3-clause              : 87950 results\n",
      "   |    1m 18s  4-clause_atom         : 90007 results\n",
      "   |    1m 18s  5-phrase              : 252590 results\n",
      "   |    1m 18s  6-phrase_atom         : 923 results\n",
      "   |    1m 18s  7-word                : 926 results\n",
      "  7.34s Min-Max      39- 252590\n",
      "  7.34s Done\n"
     ]
    }
   ],
   "source": [
    "results = runQuery(nodes, edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.00s Getting results for 8 atoms\n",
      "........  0.78s \n",
      "Done\n",
      "   |   20m 56s  0-book                : 39 results\n",
      "   |   20m 56s  1-chapter             : 929 results\n",
      "   |   20m 56s  2-verse               : 23213 results\n",
      "   |   20m 56s  3-clause              : 88000 results\n",
      "   |   20m 56s  4-clause_atom         : 90562 results\n",
      "   |   20m 56s  5-phrase              : 253174 results\n",
      "   |   20m 56s  6-phrase_atom         : 267515 results\n",
      "   |   20m 56s  7-word                : 926 results\n",
      "  0.78s Min-Max      39- 267515\n",
      "  0.78s Filtering by 7 edges\n",
      ".......  7.38s \n",
      "Done\n",
      "   |   21m 02s  0-book                : 39 results\n",
      "   |   21m 02s  1-chapter             : 929 results\n",
      "   |   21m 02s  2-verse               : 23207 results\n",
      "   |   21m 02s  3-clause              : 88000 results\n",
      "   |   21m 02s  4-clause_atom         : 90088 results\n",
      "   |   21m 02s  5-phrase              : 253174 results\n",
      "   |   21m 02s  6-phrase_atom         : 923 results\n",
      "   |   21m 02s  7-word                : 926 results\n",
      "  7.38s Min-Max      39- 253174\n",
      "  7.39s Done\n"
     ]
    }
   ],
   "source": [
    "results = runQuery(nodes, edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
