{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import glob,os,re\n",
    "import xml.etree.ElementTree as ET\n",
    "import collections\n",
    "from tf.fabric import Fabric\n",
    "from tf.timestamp import Timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Text-Fabric 2.2.1\n",
      "Api reference : https://github.com/ETCBC/text-fabric/wiki/Api\n",
      "Tutorial      : https://github.com/ETCBC/text-fabric/blob/master/docs/tutorial.ipynb\n",
      "Data sources  : https://github.com/ETCBC/text-fabric-data\n",
      "Data docs     : https://etcbc.github.io/text-fabric-data\n",
      "Shebanq docs  : https://shebanq.ancient-data.org/text\n",
      "Slack team    : https://shebanq.slack.com/signup\n",
      "Questions? Ask shebanq@ancient-data.org for an invite to Slack\n",
      "0 features found and 0 ignored\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0.01s Grid feature \"otype\" not found in\n",
      "\n",
      "  0.01s Grid feature \"oslots\" not found in\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.01s Grid feature \"otext\" not found. Working without Text-API\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tm = Timestamp()\n",
    "TF = Fabric('~/github/text-fabric-data/greek/sblgnt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "DIR_PATH = '~/github/greek-new-testament/syntax-trees/sblgnt/xml/'.replace(\n",
    "    '~', os.path.expanduser('~').replace('\\\\', '/'),\n",
    ")\n",
    "\n",
    "otypeFromCat = dict(\n",
    "    np='phrase',\n",
    "    CL='clause',\n",
    "    vp='phrase',\n",
    "    noun='word',\n",
    "    verb='word',\n",
    "    V='clause_atom',\n",
    "    det='word',\n",
    "    ADV='clause_atom',\n",
    "    S='clause_atom',\n",
    "    conj='conjunction',\n",
    "    pron='word',\n",
    "    pp='phrase',\n",
    "    prep='word',\n",
    "    O='clause_atom',\n",
    "    adjp='phrase',\n",
    "    adj='word',\n",
    "    advp='phrase',\n",
    "    adv='word',\n",
    "    P='clause_atom',\n",
    "    IO='clause_atom',\n",
    "    VC='clause_atom',\n",
    "    ptcl='word',\n",
    "    nump='phrase',\n",
    "    num='word',\n",
    "    intj='word',\n",
    "    O2='clause_atom',\n",
    ")\n",
    "\n",
    "numberFeatures = set('''\n",
    "    chapter\n",
    "    End\n",
    "    Head\n",
    "    Start\n",
    "    verse\n",
    "    chapter\n",
    "    booknum\n",
    "'''.strip().split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "langHead = re.compile('\\[([^\\]]+)\\]')\n",
    "bookNames = collections.defaultdict(lambda: [])\n",
    "bookLangs = {}\n",
    "with open('blang.txt') as fb:\n",
    "    specsDone = False\n",
    "    for line in fb:\n",
    "        line = line.rstrip('\\n')\n",
    "        if line == '---':\n",
    "            specsDone = True\n",
    "            curLang = None\n",
    "            continue\n",
    "        if specsDone:\n",
    "            match = langHead.findall(line)\n",
    "            if match:\n",
    "                curLang = match[0]\n",
    "            else:\n",
    "                bookNames[curLang].append(line)\n",
    "        else:\n",
    "            (acro, langEn, lang) = line.split('=', 2)\n",
    "            bookLangs[acro] = (langEn, lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class Data:\n",
    "    def __init__(self):\n",
    "        self.tfFromXml = {}\n",
    "        self.xmlFromTf = {}\n",
    "        self.nodeNum = 1\n",
    "        self.maxSlot = 0\n",
    "        self.maxNode = 0\n",
    "        self.paths = {}\n",
    "        self.nodeFeatures = collections.defaultdict(dict)\n",
    "        self.edgeFeatures = collections.defaultdict(dict)\n",
    "\n",
    "ignoreAtts = {'Cat'}\n",
    "\n",
    "books = {}\n",
    "chapters = {}\n",
    "verses = {}\n",
    "\n",
    "def walkNode(node, path):\n",
    "    if node.tag == 'Node':\n",
    "        n = data.nodeNum\n",
    "        xmlId = node.attrib['nodeId']\n",
    "        data.tfFromXml[xmlId] = n\n",
    "        data.xmlFromTf[n] = xmlId\n",
    "        cat = node.attrib['Cat']\n",
    "        if len(node) == 0:\n",
    "            data.nodeFeatures['otype'][n] = 'word'\n",
    "            data.nodeFeatures['psp'][n] = cat\n",
    "            for parent in path:\n",
    "                data.edgeFeatures['oslots'].setdefault(parent, []).append(n)\n",
    "            book = int(xmlId[0:2])\n",
    "            chapter = int(xmlId[3:5])\n",
    "            verse = int(xmlId[5:8])\n",
    "            books.setdefault(book, []).append(n)\n",
    "            chapters.setdefault((book, chapter), []).append(n)\n",
    "            verses.setdefault((book, chapter, verse), []).append(n)\n",
    "        else:\n",
    "            if len(path) == 0:\n",
    "                otype = 'sentence'\n",
    "            else:\n",
    "                otype = otypeFromCat[cat]\n",
    "            if otype == 'word':\n",
    "                otype = 'wordx'\n",
    "            data.nodeFeatures['otype'][n] = otype\n",
    "            if otype not in {'clause', 'sentence'}:\n",
    "                data.nodeFeatures['function'][n] = cat\n",
    "        for (att, val) in node.attrib.items():\n",
    "            data.nodeFeatures[att][n] = val\n",
    "        \n",
    "        if len(path) != 0:\n",
    "            parent = path[-1]\n",
    "            data.edgeFeatures['child'].setdefault(parent, []).append(n)\n",
    "        data.paths[n] = path\n",
    "        newPath = path+(n,)\n",
    "\n",
    "        data.nodeNum += 1\n",
    "    else:\n",
    "        newPath = path\n",
    "    for child in node:\n",
    "        walkNode(child, newPath)\n",
    "\n",
    "def getNode(root):\n",
    "    walkNode(root, ())\n",
    "    data.maxNode = data.nodeNum - 1\n",
    "        \n",
    "def reorder():\n",
    "    otypeValues = set(data.nodeFeatures['otype'].values())\n",
    "    otypeRank = dict(((val, ' ' if val == 'word' else val) for val in otypeValues))\n",
    "    newIds = sorted(range(1, data.maxNode + 1), key=lambda n: (otypeRank[data.nodeFeatures['otype'][n]], n))\n",
    "    mapping = dict(((v, i+1) for (i, v) in enumerate(newIds)))\n",
    "    \n",
    "    orderedFeatures = {}\n",
    "    for (name, dat) in data.nodeFeatures.items():\n",
    "        orderedFeatures[name] = dict(((mapping[n], v) for (n, v) in dat.items()))\n",
    "    data.nodeFeatures = orderedFeatures\n",
    "\n",
    "    orderedFeatures = {}\n",
    "    for (name, dat) in data.edgeFeatures.items():\n",
    "        orderedFeatures[name] = dict(((mapping[n], [mapping[m] for m in v]) for (n, v) in dat.items()))\n",
    "    data.edgeFeatures = orderedFeatures\n",
    "\n",
    "def sections():\n",
    "    n = data.maxNode\n",
    "    data.nodeFeatures['book'] = {}\n",
    "    for (i, book) in enumerate(books):\n",
    "        n += 1\n",
    "        data.nodeFeatures['otype'][n] = 'book'\n",
    "        data.nodeFeatures['book'][n] = bookNamesOrig[book]\n",
    "        for ll in bookNames:\n",
    "            data.nodeFeatures['book@{}'.format(ll)][n] = bookNames[ll][i]\n",
    "        data.nodeFeatures['booknum'][n] = str(book - HEBREW_BOOKS)\n",
    "        data.edgeFeatures['oslots'][n] = books[book]\n",
    "    for (book, chapter) in chapters:\n",
    "        n += 1\n",
    "        data.nodeFeatures['otype'][n] = 'chapter'\n",
    "        data.nodeFeatures['chapter'][n] = str(chapter)\n",
    "        data.edgeFeatures['oslots'][n] = chapters[(book, chapter)]\n",
    "    for (book, chapter, verse) in verses:\n",
    "        n += 1\n",
    "        data.nodeFeatures['otype'][n] = 'verse'\n",
    "        data.nodeFeatures['verse'][n] = str(verse)\n",
    "        data.edgeFeatures['oslots'][n] = verses[(book, chapter, verse)]\n",
    "\n",
    "\n",
    "    data.maxNode = n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.00s Scanning XML sources of all books\n",
      "   |     1.01s matthew\n",
      "   |     0.70s mark\n",
      "   |     1.14s luke\n",
      "   |     0.93s john\n",
      "   |     1.10s acts\n",
      "   |     0.52s romans\n",
      "   |     0.27s 1corinthians\n",
      "   |     0.42s 2corinthians\n",
      "   |     0.11s galatians\n",
      "   |     0.10s ephesians\n",
      "   |     0.07s philippians\n",
      "   |     0.07s colossians\n",
      "   |     0.30s 1thessalonians\n",
      "   |     0.04s 2thessalonians\n",
      "   |     0.07s 1timothy\n",
      "   |     0.15s 2timothy\n",
      "   |     0.03s titus\n",
      "   |     0.02s philemon\n",
      "   |     0.23s hebrews\n",
      "   |     0.32s james\n",
      "   |     0.07s 1peter\n",
      "   |     0.05s 2peter\n",
      "   |     0.09s 1john\n",
      "   |     0.02s 2john\n",
      "   |     0.02s 3john\n",
      "   |     0.03s jude\n",
      "   |     0.70s revelation\n",
      "  8.64s Processing data ...\n",
      "    12s Done\n"
     ]
    }
   ],
   "source": [
    "HEBREW_BOOKS = 39\n",
    "\n",
    "bookNamesOrig = {}\n",
    "\n",
    "nodes_with_ID = collections.OrderedDict()\n",
    "nodes_without_ID = []\n",
    "\n",
    "filenamepat = re.compile('^([0-9]{2})-(.*)$')\n",
    "\n",
    "data = Data()\n",
    "\n",
    "tm.indent(reset=True)\n",
    "tm.info('Scanning XML sources of all books')\n",
    "for xmlfile in glob.glob(DIR_PATH+'*.xml'):\n",
    "    tm.indent(level=1, reset=True)\n",
    "    (dirName, baseName) = os.path.split(xmlfile)\n",
    "    (fileName, extension) = os.path.splitext(baseName)\n",
    "    match = filenamepat.findall(fileName)\n",
    "    if len(match) == 0: continue\n",
    "    (numeral, bookName) = match[0]\n",
    "    numeral = int(numeral) + HEBREW_BOOKS\n",
    "    bookNamesOrig[numeral] = bookName\n",
    "    tree = ET.parse(xmlfile)\n",
    "    root = tree.getroot()\n",
    "    getNode(root)\n",
    "    tm.info(bookName)\n",
    "tm.indent(level=0)\n",
    "tm.info('Processing data ...')\n",
    "sections()\n",
    "reorder()\n",
    "tm.info('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "metaData = {\n",
    "    '': dict(\n",
    "        createdBy='Cody Kingham and Dirk Roorda',\n",
    "    ),\n",
    "    'otext': {\n",
    "        'sectionFeatures': 'book,chapter,verse',\n",
    "        'sectionTypes': 'book,chapter,verse',\n",
    "        'fmt:text-orig-full': '{Unicode} ',\n",
    "        'fmt:lex-orig-full': '{UnicodeLemma} ',\n",
    "    },\n",
    "    'book@en': {\n",
    "        'valueType': 'str',\n",
    "        'language': 'English',\n",
    "        'languageCode': 'en',\n",
    "        'languageEnglish': 'english',\n",
    "    },\n",
    "}\n",
    "for ll in bookNames:\n",
    "    metaData['book@{}'.format(ll)] = {\n",
    "        'valueType': 'str',\n",
    "        'language': bookLangs[ll][1],\n",
    "        'languageCode': ll,\n",
    "        'languageEnglish': bookLangs[ll][0],\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Statistical features\n",
    "We add some statistical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    16s Computing statistics\n",
      "    17s Done\n",
      "    17s Adding statistics as features\n",
      "    18s Done\n"
     ]
    }
   ],
   "source": [
    "tm.info('Computing statistics')\n",
    "wstats = {\n",
    "    'freq': {\n",
    "        'lex': collections.Counter(),\n",
    "        'occ': collections.Counter(),\n",
    "    },\n",
    "    'rank': {\n",
    "        'lex': {},\n",
    "        'occ': {},\n",
    "    },\n",
    "}\n",
    "\n",
    "nodeFeatures = data.nodeFeatures\n",
    "\n",
    "words = [n[0] for n in nodeFeatures['otype'].items() if n[1] == 'word']\n",
    "\n",
    "for w in words:\n",
    "    occ = nodeFeatures['Unicode'][w]\n",
    "    lex = nodeFeatures['UnicodeLemma'][w]\n",
    "    wstats['freq']['lex'][lex] += 1\n",
    "    wstats['freq']['occ'][occ] += 1\n",
    "for tp in ['lex', 'occ']:\n",
    "    rank = -1\n",
    "    prev_n = -1\n",
    "    amount = 1\n",
    "    for (x, n) in sorted(wstats['freq'][tp].items(), key=lambda y: (-y[1], y[0])):\n",
    "        if n == prev_n:\n",
    "            amount += 1\n",
    "        else:\n",
    "            rank += amount\n",
    "            amount = 1\n",
    "        prev_n = n\n",
    "        wstats['rank'][tp][x] = rank\n",
    "tm.info('Done')\n",
    "\n",
    "tm.info('Adding statistics as features')\n",
    "occFeatures = {}\n",
    "for tp in ['occ', 'lex']:\n",
    "    for ft in ('freq_{}'.format(tp), 'rank_{}'.format(tp)):\n",
    "        occFeatures[ft] = {}\n",
    "        metaData.setdefault(ft, {})['valueType'] = 'int'\n",
    "\n",
    "for w in words:\n",
    "    occ = nodeFeatures['Unicode'][w]\n",
    "    lex = nodeFeatures['UnicodeLemma'][w]\n",
    "    for tp in ['occ', 'lex']:\n",
    "        ref = occ if tp == 'occ' else lex\n",
    "        for kn in ['freq', 'rank']:\n",
    "            ft = '{}_{}'.format(kn, tp)\n",
    "            occFeatures[ft][w] = str(wstats[kn][tp][ref])\n",
    "\n",
    "nodeFeatures.update(occFeatures)\n",
    "\n",
    "tm.info('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "otypeValues = set(data.nodeFeatures['otype'].values())\n",
    "otypeRank = dict(((val, ' ' if val == 'word' else val) for val in otypeValues))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.00s Exporting 57 node and 2 edge and 1 config features to /Users/dirk/github/text-fabric-data/greek/sblgnt:\n",
      "   |     0.20s T Case                 to /Users/dirk/github/text-fabric-data/greek/sblgnt\n",
      "   |     0.74s T Cat                  to /Users/dirk/github/text-fabric-data/greek/sblgnt\n",
      "   |     0.01s T ClType               to /Users/dirk/github/text-fabric-data/greek/sblgnt\n",
      "   |     0.00s T Degree               to /Users/dirk/github/text-fabric-data/greek/sblgnt\n",
      "   |     0.74s T End                  to /Users/dirk/github/text-fabric-data/greek/sblgnt\n",
      "   |     0.14s T Gender               to /Users/dirk/github/text-fabric-data/greek/sblgnt\n",
      "   |     0.09s T HasDet               to /Users/dirk/github/text-fabric-data/greek/sblgnt\n",
      "   |     0.57s T Head                 to /Users/dirk/github/text-fabric-data/greek/sblgnt\n",
      "   |     0.12s T Mood                 to /Users/dirk/github/text-fabric-data/greek/sblgnt\n",
      "   |     0.24s T Number               to /Users/dirk/github/text-fabric-data/greek/sblgnt\n",
      "   |     0.06s T Person               to /Users/dirk/github/text-fabric-data/greek/sblgnt\n",
      "   |     0.51s T Rule                 to /Users/dirk/github/text-fabric-data/greek/sblgnt\n",
      "   |     0.91s T Start                to /Users/dirk/github/text-fabric-data/greek/sblgnt\n",
      "   |     0.14s T Tense                to /Users/dirk/github/text-fabric-data/greek/sblgnt\n",
      "   |     0.10s T Type                 to /Users/dirk/github/text-fabric-data/greek/sblgnt\n",
      "   |     0.27s T Unicode              to /Users/dirk/github/text-fabric-data/greek/sblgnt\n",
      "   |     0.27s T UnicodeLemma         to /Users/dirk/github/text-fabric-data/greek/sblgnt\n",
      "   |     0.06s T Voice                to /Users/dirk/github/text-fabric-data/greek/sblgnt\n",
      "   |     0.00s T book                 to /Users/dirk/github/text-fabric-data/greek/sblgnt\n",
      "   |     0.00s T book@am              to /Users/dirk/github/text-fabric-data/greek/sblgnt\n",
      "   |     0.00s T book@ar              to /Users/dirk/github/text-fabric-data/greek/sblgnt\n",
      "   |     0.00s T book@bn              to /Users/dirk/github/text-fabric-data/greek/sblgnt\n",
      "   |     0.00s T book@da              to /Users/dirk/github/text-fabric-data/greek/sblgnt\n",
      "   |     0.00s T book@de              to /Users/dirk/github/text-fabric-data/greek/sblgnt\n",
      "   |     0.00s T book@el              to /Users/dirk/github/text-fabric-data/greek/sblgnt\n",
      "   |     0.00s T book@en              to /Users/dirk/github/text-fabric-data/greek/sblgnt\n",
      "   |     0.00s T book@es              to /Users/dirk/github/text-fabric-data/greek/sblgnt\n",
      "   |     0.00s T book@fa              to /Users/dirk/github/text-fabric-data/greek/sblgnt\n",
      "   |     0.00s T book@fr              to /Users/dirk/github/text-fabric-data/greek/sblgnt\n",
      "   |     0.00s T book@he              to /Users/dirk/github/text-fabric-data/greek/sblgnt\n",
      "   |     0.00s T book@hi              to /Users/dirk/github/text-fabric-data/greek/sblgnt\n",
      "   |     0.00s T book@id              to /Users/dirk/github/text-fabric-data/greek/sblgnt\n",
      "   |     0.00s T book@ja              to /Users/dirk/github/text-fabric-data/greek/sblgnt\n",
      "   |     0.00s T book@ko              to /Users/dirk/github/text-fabric-data/greek/sblgnt\n",
      "   |     0.00s T book@la              to /Users/dirk/github/text-fabric-data/greek/sblgnt\n",
      "   |     0.00s T book@nl              to /Users/dirk/github/text-fabric-data/greek/sblgnt\n",
      "   |     0.00s T book@pa              to /Users/dirk/github/text-fabric-data/greek/sblgnt\n",
      "   |     0.00s T book@pt              to /Users/dirk/github/text-fabric-data/greek/sblgnt\n",
      "   |     0.00s T book@ru              to /Users/dirk/github/text-fabric-data/greek/sblgnt\n",
      "   |     0.00s T book@sw              to /Users/dirk/github/text-fabric-data/greek/sblgnt\n",
      "   |     0.00s T book@syc             to /Users/dirk/github/text-fabric-data/greek/sblgnt\n",
      "   |     0.00s T book@tr              to /Users/dirk/github/text-fabric-data/greek/sblgnt\n",
      "   |     0.00s T book@ur              to /Users/dirk/github/text-fabric-data/greek/sblgnt\n",
      "   |     0.00s T book@yo              to /Users/dirk/github/text-fabric-data/greek/sblgnt\n",
      "   |     0.00s T book@zh              to /Users/dirk/github/text-fabric-data/greek/sblgnt\n",
      "   |     0.00s T booknum              to /Users/dirk/github/text-fabric-data/greek/sblgnt\n",
      "   |     0.00s T chapter              to /Users/dirk/github/text-fabric-data/greek/sblgnt\n",
      "   |     0.52s T freq_lex             to /Users/dirk/github/text-fabric-data/greek/sblgnt\n",
      "   |     0.37s T freq_occ             to /Users/dirk/github/text-fabric-data/greek/sblgnt\n",
      "   |     0.53s T function             to /Users/dirk/github/text-fabric-data/greek/sblgnt\n",
      "   |     0.43s T morphId              to /Users/dirk/github/text-fabric-data/greek/sblgnt\n",
      "   |     0.88s T nodeId               to /Users/dirk/github/text-fabric-data/greek/sblgnt\n",
      "   |     0.32s T otype                to /Users/dirk/github/text-fabric-data/greek/sblgnt\n",
      "   |     0.27s T psp                  to /Users/dirk/github/text-fabric-data/greek/sblgnt\n",
      "   |     0.24s T rank_lex             to /Users/dirk/github/text-fabric-data/greek/sblgnt\n",
      "   |     0.22s T rank_occ             to /Users/dirk/github/text-fabric-data/greek/sblgnt\n",
      "   |     0.01s T verse                to /Users/dirk/github/text-fabric-data/greek/sblgnt\n",
      "   |     1.13s T child                to /Users/dirk/github/text-fabric-data/greek/sblgnt\n",
      "   |     1.14s T oslots               to /Users/dirk/github/text-fabric-data/greek/sblgnt\n",
      "   |     0.00s M otext                to /Users/dirk/github/text-fabric-data/greek/sblgnt\n",
      "    11s Exported 57 node features and 2 edge features and 1 config features to /Users/dirk/github/text-fabric-data/greek/sblgnt\n"
     ]
    }
   ],
   "source": [
    "for nf in data.nodeFeatures:\n",
    "    metaData.setdefault(nf, {})['valueType'] = 'int' if nf in numberFeatures else 'str'\n",
    "for ef in data.edgeFeatures:\n",
    "    metaData.setdefault(ef, {})['valueType'] = 'int' if ef in numberFeatures else 'str'\n",
    "\n",
    "TF.save(nodeFeatures=data.nodeFeatures, edgeFeatures=data.edgeFeatures, metaData=metaData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
