{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"right\" src=\"tf-small.png\"/>\n",
    "\n",
    "# Tutorial\n",
    "\n",
    "This notebook gets you started with Text-Fabric.\n",
    "It performs most functions of its API on the ETCBC4C data set (Hebrew Bible)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys, collections\n",
    "from tf.fabric import Fabric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Text-Fabric\n",
    "Use default locations, so no `locations=...`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Text-Fabric 0.0.14\n",
      "Api reference: https://github.com/dirkroorda/text-fabric/wiki/Api\n",
      "Data sources: https://github.com/dirkroorda/text-fabric-data\n",
      "Data feature docs: https://shebanq.ancient-data.org/static/docs/featuredoc/texts/welcome.html\n",
      "Questions? Ask shebanq@ancient-data.org for an invite to Slack\n",
      "95 features found and 0 ignored\n"
     ]
    }
   ],
   "source": [
    "TF = Fabric()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Features\n",
    "Specify the features to load, and receive the API to work with that data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.00s loading features ...\n",
      "  5.23s All features loaded/computed - for details use loadLog()\n"
     ]
    }
   ],
   "source": [
    "api = TF.load('sp lex')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us see that `loadLog()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   |     0.07s B otype                from /Users/dirk/github/text-fabric-data/hebrew/etcbc4c\n",
      "   |     0.55s B oslots               from /Users/dirk/github/text-fabric-data/hebrew/etcbc4c\n",
      "   |     0.00s M otext                from /Users/dirk/github/text-fabric-data/hebrew/etcbc4c\n",
      "   |     0.01s B book                 from /Users/dirk/github/text-fabric-data/hebrew/etcbc4c\n",
      "   |     0.01s B chapter              from /Users/dirk/github/text-fabric-data/hebrew/etcbc4c\n",
      "   |     0.01s B verse                from /Users/dirk/github/text-fabric-data/hebrew/etcbc4c\n",
      "   |     0.14s B g_cons               from /Users/dirk/github/text-fabric-data/hebrew/etcbc4c\n",
      "   |     0.24s B g_cons_utf8          from /Users/dirk/github/text-fabric-data/hebrew/etcbc4c\n",
      "   |     0.42s B g_voc_lex            from /Users/dirk/github/text-fabric-data/hebrew/etcbc4c\n",
      "   |     0.42s B g_voc_lex_utf8       from /Users/dirk/github/text-fabric-data/hebrew/etcbc4c\n",
      "   |     0.17s B g_word               from /Users/dirk/github/text-fabric-data/hebrew/etcbc4c\n",
      "   |     0.29s B g_word_utf8          from /Users/dirk/github/text-fabric-data/hebrew/etcbc4c\n",
      "   |     0.25s B lex                  from /Users/dirk/github/text-fabric-data/hebrew/etcbc4c\n",
      "   |     0.21s B lex_utf8             from /Users/dirk/github/text-fabric-data/hebrew/etcbc4c\n",
      "   |     0.07s B qere                 from /Users/dirk/github/text-fabric-data/hebrew/etcbc4c\n",
      "   |     0.07s B qere_utf8            from /Users/dirk/github/text-fabric-data/hebrew/etcbc4c\n",
      "   |     0.08s B trailer              from /Users/dirk/github/text-fabric-data/hebrew/etcbc4c\n",
      "   |     0.09s B trailer_utf8         from /Users/dirk/github/text-fabric-data/hebrew/etcbc4c\n",
      "   |     0.00s B __levels__           from otype, oslots\n",
      "   |     0.04s B __order__            from otype, oslots, __levels__\n",
      "   |     0.03s B __rank__             from otype, __order__\n",
      "   |     1.09s B __levUp__            from otype, oslots, __rank__\n",
      "   |     0.80s B __levDown__          from otype, __levUp__, __rank__\n",
      "   |     0.04s B __sections__         from otype, oslots, otext, __levUp__, __levels__, book, chapter, verse\n",
      "   |     0.14s B sp                   from /Users/dirk/github/text-fabric-data/hebrew/etcbc4c\n",
      "   |     0.00s B book@am              from /Users/dirk/github/text-fabric-data/hebrew/etcbc4c\n",
      "   |     0.00s B book@ar              from /Users/dirk/github/text-fabric-data/hebrew/etcbc4c\n",
      "   |     0.00s B book@bn              from /Users/dirk/github/text-fabric-data/hebrew/etcbc4c\n",
      "   |     0.00s B book@da              from /Users/dirk/github/text-fabric-data/hebrew/etcbc4c\n",
      "   |     0.00s B book@de              from /Users/dirk/github/text-fabric-data/hebrew/etcbc4c\n",
      "   |     0.00s B book@el              from /Users/dirk/github/text-fabric-data/hebrew/etcbc4c\n",
      "   |     0.00s B book@en              from /Users/dirk/github/text-fabric-data/hebrew/etcbc4c\n",
      "   |     0.00s B book@es              from /Users/dirk/github/text-fabric-data/hebrew/etcbc4c\n",
      "   |     0.00s B book@fa              from /Users/dirk/github/text-fabric-data/hebrew/etcbc4c\n",
      "   |     0.00s B book@fr              from /Users/dirk/github/text-fabric-data/hebrew/etcbc4c\n",
      "   |     0.00s B book@he              from /Users/dirk/github/text-fabric-data/hebrew/etcbc4c\n",
      "   |     0.00s B book@hi              from /Users/dirk/github/text-fabric-data/hebrew/etcbc4c\n",
      "   |     0.00s B book@id              from /Users/dirk/github/text-fabric-data/hebrew/etcbc4c\n",
      "   |     0.00s B book@ja              from /Users/dirk/github/text-fabric-data/hebrew/etcbc4c\n",
      "   |     0.00s B book@ko              from /Users/dirk/github/text-fabric-data/hebrew/etcbc4c\n",
      "   |     0.00s B book@la              from /Users/dirk/github/text-fabric-data/hebrew/etcbc4c\n",
      "   |     0.00s B book@nl              from /Users/dirk/github/text-fabric-data/hebrew/etcbc4c\n",
      "   |     0.00s B book@pa              from /Users/dirk/github/text-fabric-data/hebrew/etcbc4c\n",
      "   |     0.00s B book@pt              from /Users/dirk/github/text-fabric-data/hebrew/etcbc4c\n",
      "   |     0.00s B book@ru              from /Users/dirk/github/text-fabric-data/hebrew/etcbc4c\n",
      "   |     0.00s B book@sw              from /Users/dirk/github/text-fabric-data/hebrew/etcbc4c\n",
      "   |     0.00s B book@syc             from /Users/dirk/github/text-fabric-data/hebrew/etcbc4c\n",
      "   |     0.00s B book@tr              from /Users/dirk/github/text-fabric-data/hebrew/etcbc4c\n",
      "   |     0.00s B book@ur              from /Users/dirk/github/text-fabric-data/hebrew/etcbc4c\n",
      "   |     0.00s B book@yo              from /Users/dirk/github/text-fabric-data/hebrew/etcbc4c\n",
      "   |     0.00s B book@zh              from /Users/dirk/github/text-fabric-data/hebrew/etcbc4c\n"
     ]
    }
   ],
   "source": [
    "api.loadLog()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make it so that the members of the API are directly accessible as global variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "api.makeAvailableIn(globals())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just check that `F` and `N` are defined and look like `api.F` and `api.N`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.api.NodeFeatures object at 0x169d0cf98>\n",
      "<tf.api.NodeFeatures object at 0x169d0cf98>\n",
      "<bound method Api.N of <tf.api.Api object at 0x10e6c7828>>\n",
      "<bound method Api.N of <tf.api.Api object at 0x10e6c7828>>\n"
     ]
    }
   ],
   "source": [
    "print(F)\n",
    "print(api.F)\n",
    "print(N)\n",
    "print(api.N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting acquainted\n",
    "\n",
    "We start with simple tasks, to get a feel for the Text-Fabric API.\n",
    "\n",
    "Count all nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.00s Counting nodes ...\n",
      "  0.35s 1436894 nodes\n"
     ]
    }
   ],
   "source": [
    "indent(reset=True)\n",
    "info('Counting nodes ...')\n",
    "i = 0\n",
    "for n in N(): i += 1\n",
    "info('{} nodes'.format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get some nodes, slot and non-slot, and sort them in the canonical order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[426581,\n",
       " 0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 426582,\n",
       " 426583,\n",
       " 426584,\n",
       " 426585,\n",
       " 426586,\n",
       " 426587,\n",
       " 426588,\n",
       " 426589]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sortNodes(list(range(F.otype.maxSlot+1, F.otype.maxSlot+10))+list(range(10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get information that is readily available in the GRID feature `otype`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slotType  = word\n",
      "maxSlot  =426580\n",
      "maxNode  =1436894\n",
      "All otypes:\n",
      "\tbook\n",
      "\tchapter\n",
      "\tverse\n",
      "\thalf_verse\n",
      "\tsentence\n",
      "\tsentence_atom\n",
      "\tclause\n",
      "\tclause_atom\n",
      "\tphrase\n",
      "\tphrase_atom\n",
      "\tsubphrase\n",
      "\tword\n"
     ]
    }
   ],
   "source": [
    "info('{:<9} = {}\\n{:<9}={}\\n{:<9}={}'.format(\n",
    "    'slotType', F.otype.slotType,\n",
    "    'maxSlot', F.otype.maxSlot,\n",
    "    'maxNode', F.otype.maxNode,\n",
    "), tm=False)\n",
    "info('All otypes:\\n\\t', nl=False, tm=False)\n",
    "info('\\n\\t'.join(F.otype.all), tm=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count the individual object types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.00s counting objects ...\n",
      "   |     0.00s      39 books\n",
      "   |     0.00s     929 chapters\n",
      "   |     0.00s   23213 verses\n",
      "   |     0.01s   45180 half_verses\n",
      "   |     0.01s   63570 sentences\n",
      "   |     0.01s   64339 sentence_atoms\n",
      "   |     0.03s   88000 clauses\n",
      "   |     0.02s   90562 clause_atoms\n",
      "   |     0.06s  253174 phrases\n",
      "   |     0.05s  267515 phrase_atoms\n",
      "   |     0.02s  113792 subphrases\n",
      "   |     0.08s  426581 words\n",
      "  0.33s Done\n"
     ]
    }
   ],
   "source": [
    "indent(reset=True)\n",
    "info('counting objects ...')\n",
    "for otype in F.otype.all:\n",
    "    i = 0\n",
    "    indent(level=1, reset=True)\n",
    "    for n in F.otype.s(otype): i+=1\n",
    "    info('{:>7} {}s'.format(i, otype))\n",
    "indent(level=0)\n",
    "info('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect the top 10 frequent verbs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">MR[: 5378\n",
      "HJH[: 3561\n",
      "<FH[: 2629\n",
      "BW>[: 2570\n",
      "NTN[: 2017\n",
      "HLK[: 1554\n",
      "R>H[: 1298\n",
      "CM<[: 1168\n",
      "DBR[: 1138\n",
      "JCB[: 1082\n",
      "\n"
     ]
    }
   ],
   "source": [
    "verbs = collections.Counter()\n",
    "for w in F.otype.s('word'):\n",
    "    if F.sp.v(w) != 'verb': continue\n",
    "    verbs[F.lex.v(w)] +=1\n",
    "print(''.join(\n",
    "    '{}: {}\\n'.format(verb, cnt) for (verb, cnt) in sorted(\n",
    "        verbs.items() , key=lambda x: (-x[1], x[0]))[0:10],\n",
    "    )\n",
    ")       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We count the words of each part of speech, and we list to top 10 of frequent lexemes.\n",
    "\n",
    "**NB**: mind the pretty progress messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.00s Starting tasks\n",
      "   |     0.00s Counting the words by part-of-speech ...\n",
      "   |     0.44s Done: 14 categories\n",
      "   |      |   subs  : 121481x\n",
      "   |      |   verb  : 73710x\n",
      "   |      |   prep  : 73273x\n",
      "   |      |   conj  : 62722x\n",
      "   |      |   nmpr  : 33082x\n",
      "   |      |   art   : 30384x\n",
      "   |      |   adjv  :  9464x\n",
      "   |      |   nega  :  6053x\n",
      "   |      |   prps  :  5011x\n",
      "   |      |   advb  :  4550x\n",
      "   |      |   prde  :  2660x\n",
      "   |      |   intj  :  1885x\n",
      "   |      |   inrg  :  1285x\n",
      "   |      |   prin  :  1021x\n",
      "   |     0.00s Listing the top 10 frequent words ...\n",
      "   |     0.42s Done: 8776 lexemes\n",
      "   |      |   W     : 51003x\n",
      "   |      |   H     : 30390x\n",
      "   |      |   L     : 20447x\n",
      "   |      |   B     : 15768x\n",
      "   |      |   >T    : 11002x\n",
      "   |      |   MN    :  7681x\n",
      "   |      |   JHWH/ :  6828x\n",
      "   |      |   <L    :  5870x\n",
      "   |      |   >L    :  5521x\n",
      "   |      |   >CR   :  5500x\n",
      "  0.92s All tasks completed\n"
     ]
    }
   ],
   "source": [
    "partOfSpeech = collections.Counter()\n",
    "freqLex = collections.Counter()\n",
    "\n",
    "indent(level=0, reset=True)\n",
    "info('Starting tasks')\n",
    "indent(level=1, reset=True)\n",
    "info('Counting the words by part-of-speech ...')\n",
    "for w in F.otype.s('word'):\n",
    "    partOfSpeech[F.sp.v(w)] += 1\n",
    "info('Done: {} categories'.format(len(partOfSpeech)))\n",
    "indent(level=2)\n",
    "info('\\n'.join('{:<6}: {:>5}x'.format(*x) for x in sorted(\n",
    "    partOfSpeech.items(),\n",
    "    key=lambda x: (-x[1], x[0])\n",
    ")), tm=False)\n",
    "indent(level=1, reset=True)\n",
    "info('Listing the top 10 frequent words ...')\n",
    "for w in F.otype.s('word'):\n",
    "    freqLex[F.lex.v(w)] += 1\n",
    "info('Done: {} lexemes'.format(len(freqLex)))\n",
    "indent(level=2)\n",
    "info('\\n'.join('{:<6}: {:>5}x'.format(*x) for x in sorted(\n",
    "    freqLex.items(),\n",
    "    key=lambda x: (-x[1], x[0])\n",
    ")[0:10]), tm=False)\n",
    "indent(level=0)\n",
    "info('All tasks completed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layer API\n",
    "We travel upwards and downwards through the node hierarchy.\n",
    "The Layer-API (`L`) provides two functions: `u()` for going up, and `d()` for going down.\n",
    "\n",
    "Upwards is going to nodes that embed the node you started from.\n",
    "Downwards is the opposite direction, to those that are contained in the start node.\n",
    "\n",
    "Embedding and containment are an indirect notion: nodes are just numbers, but by means of the\n",
    "`oslots` feature they are linked to slots. One node *contains* an other node, if the one is linked to a set of slots that contains the set of slots that the other is linked to.\n",
    "\n",
    "Both functions yield nodes of all possible otypes. By passing an optional parameter, you can restrict the results to nodes of that type.\n",
    "\n",
    "The result is ordered in the canonical node ordering.\n",
    "Both functions return always a tuple, even if there is just one node in the result.\n",
    "\n",
    "## Going up\n",
    "We go from the first word to the book it contains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1367533,)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L.u(0, otype='book')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Going down"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We go to the chapters of the that book, and just count them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "chapters = L.d(L.u(0, otype='book')[0], otype='chapter')\n",
    "print(len(chapters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We pick the first verse and the first word, and explore what is above and below them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 0\n",
      "   |   UP\n",
      "   |      |   605143          phrase\n",
      "   |      |   858317          phrase_atom\n",
      "   |      |   1368501         half_verse\n",
      "   |      |   514581          clause_atom\n",
      "   |      |   426581          clause\n",
      "   |      |   1413681         verse\n",
      "   |      |   1189402         sentence_atom\n",
      "   |      |   1125832         sentence\n",
      "   |      |   1367572         chapter\n",
      "   |      |   1367533         book\n",
      "   |   DOWN\n",
      "   |      |   \n",
      "Node 1413681\n",
      "   |   UP\n",
      "   |      |   1189402         sentence_atom\n",
      "   |      |   1125832         sentence\n",
      "   |      |   1367572         chapter\n",
      "   |      |   1367533         book\n",
      "   |   DOWN\n",
      "   |      |   426581          clause\n",
      "   |      |   514581          clause_atom\n",
      "   |      |   1368501         half_verse\n",
      "   |      |   858317          phrase_atom\n",
      "   |      |   605143          phrase\n",
      "   |      |   0               word\n",
      "   |      |   1               word\n",
      "   |      |   858318          phrase_atom\n",
      "   |      |   2               word\n",
      "   |      |   605144          phrase\n",
      "   |      |   858319          phrase_atom\n",
      "   |      |   3               word\n",
      "   |      |   605145          phrase\n",
      "   |      |   858320          phrase_atom\n",
      "   |      |   1368502         half_verse\n",
      "   |      |   605146          phrase\n",
      "   |      |   1253741         subphrase\n",
      "   |      |   4               word\n",
      "   |      |   5               word\n",
      "   |      |   6               word\n",
      "   |      |   7               word\n",
      "   |      |   1253742         subphrase\n",
      "   |      |   8               word\n",
      "   |      |   9               word\n",
      "   |      |   10              word\n",
      "18m 54s Done\n"
     ]
    }
   ],
   "source": [
    "for n in [0, L.u(0, otype='verse')[0]]:\n",
    "    indent(level=0)\n",
    "    info('Node {}'.format(n), tm=False)\n",
    "    indent(level=1)\n",
    "    info('UP', tm=False)\n",
    "    indent(level=2)\n",
    "    info('\\n'.join(['{:<15} {}'.format(u, F.otype.v(u)) for u in L.u(n)]), tm=False)\n",
    "    indent(level=1)\n",
    "    info('DOWN', tm=False)\n",
    "    indent(level=2)\n",
    "    info('\\n'.join(['{:<15} {}'.format(u, F.otype.v(u)) for u in L.d(n)]), tm=False)\n",
    "indent(level=0)\n",
    "info('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text API\n",
    "\n",
    "We examine the functions of the Text API: `T`.\n",
    "\n",
    "First the formats that we have available to represent the actual text.\n",
    "These formats have been defined in the `otext` feature.\n",
    "This is an optional GRID config feature: it has only metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lex-orig-full',\n",
       " 'lex-orig-plain',\n",
       " 'lex-trans-full',\n",
       " 'lex-trans-plain',\n",
       " 'text-orig-full',\n",
       " 'text-orig-full-ketiv',\n",
       " 'text-orig-plain',\n",
       " 'text-trans-full',\n",
       " 'text-trans-full-ketiv',\n",
       " 'text-trans-plain']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(T.formats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use those formats to print out the first verse of the Hebrew Bible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lex-orig-full:\n",
      "\tבְּ רֵאשִׁית ברא אֱלֹהִים אֵת הַ שָׁמַיִם וְ אֵת הַ אֶרֶץ \n",
      "lex-orig-plain:\n",
      "\tב ראשׁית֜ ברא אלהים֜ את ה שׁמים֜ ו את ה ארץ֜ \n",
      "lex-trans-full:\n",
      "\tB.: R;>CIJT BR> >:ELOHIJM >;T HA C@MAJIM W: >;T HA >EREY \n",
      "lex-trans-plain:\n",
      "\tB R>CJT/ BR>[ >LHJM/ >T H CMJM/ W >T H >RY/ \n",
      "text-orig-full:\n",
      "\tבְּרֵאשִׁ֖ית בָּרָ֣א אֱלֹהִ֑ים אֵ֥ת הַשָּׁמַ֖יִם וְאֵ֥ת הָאָֽרֶץ׃ \n",
      "text-orig-full-ketiv:\n",
      "\tבְּרֵאשִׁ֖ית בָּרָ֣א אֱלֹהִ֑ים אֵ֥ת הַשָּׁמַ֖יִם וְאֵ֥ת הָאָֽרֶץ׃ \n",
      "text-orig-plain:\n",
      "\tבראשׁית ברא אלהים את השׁמים ואת הארץ׃ \n",
      "text-trans-full:\n",
      "\tB.:-R;>CI73JT B.@R@74> >:ELOHI92JM >;71T HA-C.@MA73JIM W:->;71T H@->@75REY00 \n",
      "text-trans-full-ketiv:\n",
      "\tB.:-R;>CI73JT B.@R@74> >:ELOHI92JM >;71T HA-C.@MA73JIM W:->;71T H@->@75REY00 \n",
      "text-trans-plain:\n",
      "\tBR>CJT BR> >LHJM >T HCMJM W>T H>RY00 \n"
     ]
    }
   ],
   "source": [
    "for fmt in sorted(T.formats):\n",
    "    print('{}:\\n\\t{}'.format(fmt, T.text(range(11), fmt=fmt)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we do not specify a format, the default format is used (`text-orig-full`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "בְּרֵאשִׁ֖ית בָּרָ֣א אֱלֹהִ֑ים אֵ֥ת הַשָּׁמַ֖יִם וְאֵ֥ת הָאָֽרֶץ׃ \n"
     ]
    }
   ],
   "source": [
    "print(T.text(range(11)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Whole text in all formats in just 10 seconds\n",
    "We are going to produce the complete text of the Hebrew Bible in all available formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.00s writing plain text of whole Bible in all formats\n",
      "  8.42s done 10 formats\n",
      "lex-orig-full\n",
      "בְּ רֵאשִׁית ברא אֱלֹהִים אֵת הַ שָׁמַיִם וְ אֵת הַ אֶרֶץ \n",
      "וְ הַ אֶרֶץ היה תֹּהוּ וְ בֹּהוּ וְ חֹשֶׁךְ עַל פָּנֶה תְּהֹום וְ רוּחַ אֱלֹהִים רחף עַל פָּנֶה הַ מַיִם \n",
      "וְ אמר אֱלֹהִים היה אֹור וְ היה אֹור \n",
      "וְ ראה אֱלֹהִים אֵת הַ אֹור כִּי טוב וְ בדל אֱלֹהִים בַּיִן הַ אֹור וְ בַּיִן הַ חֹשֶׁךְ \n",
      "וְ קרא אֱלֹהִים לְ הַ אֹור יֹום וְ לְ הַ חֹשֶׁךְ קרא לַיְלָה וְ היה עֶרֶב וְ היה בֹּקֶר יֹום אֶחָד \n",
      "\n",
      "lex-orig-plain\n",
      "ב ראשׁית֜ ברא אלהים֜ את ה שׁמים֜ ו את ה ארץ֜ \n",
      "ו ה ארץ֜ היה תהו֜ ו בהו֜ ו חשׁך֜ על פנה֜ תהום֜ ו רוח֜ אלהים֜ רחף על פנה֜ ה מים֜ \n",
      "ו אמר אלהים֜ היה אור֜ ו היה אור֜ \n",
      "ו ראה אלהים֜ את ה אור֜ כי טוב ו בדל אלהים֜ בין֜ ה אור֜ ו בין֜ ה חשׁך֜ \n",
      "ו קרא אלהים֜ ל ה אור֜ יום֜ ו ל ה חשׁך֜ קרא לילה֜ ו היה ערב֜ ו היה בקר֜ יום֜ אחד֜ \n",
      "\n",
      "lex-trans-full\n",
      "B.: R;>CIJT BR> >:ELOHIJM >;T HA C@MAJIM W: >;T HA >EREY \n",
      "W: HA >EREY HJH T.OHW. W: B.OHW. W: XOCEK: <AL P.@NEH T.:HOWM W: RW.XA >:ELOHIJM RXP <AL P.@NEH HA MAJIM \n",
      "W: >MR >:ELOHIJM HJH >OWR W: HJH >OWR \n",
      "W: R>H >:ELOHIJM >;T HA >OWR K.IJ VWB W: BDL >:ELOHIJM B.AJIN HA >OWR W: B.AJIN HA XOCEK: \n",
      "W: QR> >:ELOHIJM L: HA >OWR JOWM W: L: HA XOCEK: QR> LAJ:L@H W: HJH <EREB W: HJH B.OQER JOWM >EX@D \n",
      "\n",
      "lex-trans-plain\n",
      "B R>CJT/ BR>[ >LHJM/ >T H CMJM/ W >T H >RY/ \n",
      "W H >RY/ HJH[ THW/ W BHW/ W XCK/ <L PNH/ THWM/ W RWX/ >LHJM/ RXP[ <L PNH/ H MJM/ \n",
      "W >MR[ >LHJM/ HJH[ >WR/ W HJH[ >WR/ \n",
      "W R>H[ >LHJM/ >T H >WR/ KJ VWB[ W BDL[ >LHJM/ BJN/ H >WR/ W BJN/ H XCK/ \n",
      "W QR>[ >LHJM/ L H >WR/ JWM/ W L H XCK/ QR>[ LJLH/ W HJH[ <RB/ W HJH[ BQR=/ JWM/ >XD/ \n",
      "\n",
      "text-orig-full\n",
      "בְּרֵאשִׁ֖ית בָּרָ֣א אֱלֹהִ֑ים אֵ֥ת הַשָּׁמַ֖יִם וְאֵ֥ת הָאָֽרֶץ׃ \n",
      "וְהָאָ֗רֶץ הָיְתָ֥ה תֹ֨הוּ֙ וָבֹ֔הוּ וְחֹ֖שֶׁךְ עַל־פְּנֵ֣י תְהֹ֑ום וְר֣וּחַ אֱלֹהִ֔ים מְרַחֶ֖פֶת עַל־פְּנֵ֥י הַמָּֽיִם׃ \n",
      "וַיֹּ֥אמֶר אֱלֹהִ֖ים יְהִ֣י אֹ֑ור וַֽיְהִי־אֹֽור׃ \n",
      "וַיַּ֧רְא אֱלֹהִ֛ים אֶת־הָאֹ֖ור כִּי־טֹ֑וב וַיַּבְדֵּ֣ל אֱלֹהִ֔ים בֵּ֥ין הָאֹ֖ור וּבֵ֥ין הַחֹֽשֶׁךְ׃ \n",
      "וַיִּקְרָ֨א אֱלֹהִ֤ים׀ לָאֹור֙ יֹ֔ום וְלַחֹ֖שֶׁךְ קָ֣רָא לָ֑יְלָה וַֽיְהִי־עֶ֥רֶב וַֽיְהִי־בֹ֖קֶר יֹ֥ום אֶחָֽד׃ פ \n",
      "\n",
      "text-orig-full-ketiv\n",
      "בְּרֵאשִׁ֖ית בָּרָ֣א אֱלֹהִ֑ים אֵ֥ת הַשָּׁמַ֖יִם וְאֵ֥ת הָאָֽרֶץ׃ \n",
      "וְהָאָ֗רֶץ הָיְתָ֥ה תֹ֨הוּ֙ וָבֹ֔הוּ וְחֹ֖שֶׁךְ עַל־פְּנֵ֣י תְהֹ֑ום וְר֣וּחַ אֱלֹהִ֔ים מְרַחֶ֖פֶת עַל־פְּנֵ֥י הַמָּֽיִם׃ \n",
      "וַיֹּ֥אמֶר אֱלֹהִ֖ים יְהִ֣י אֹ֑ור וַֽיְהִי־אֹֽור׃ \n",
      "וַיַּ֧רְא אֱלֹהִ֛ים אֶת־הָאֹ֖ור כִּי־טֹ֑וב וַיַּבְדֵּ֣ל אֱלֹהִ֔ים בֵּ֥ין הָאֹ֖ור וּבֵ֥ין הַחֹֽשֶׁךְ׃ \n",
      "וַיִּקְרָ֨א אֱלֹהִ֤ים׀ לָאֹור֙ יֹ֔ום וְלַחֹ֖שֶׁךְ קָ֣רָא לָ֑יְלָה וַֽיְהִי־עֶ֥רֶב וַֽיְהִי־בֹ֖קֶר יֹ֥ום אֶחָֽד׃ פ \n",
      "\n",
      "text-orig-plain\n",
      "בראשׁית ברא אלהים את השׁמים ואת הארץ׃ \n",
      "והארץ היתה תהו ובהו וחשׁך על־פני תהום ורוח אלהים מרחפת על־פני המים׃ \n",
      "ויאמר אלהים יהי אור ויהי־אור׃ \n",
      "וירא אלהים את־האור כי־טוב ויבדל אלהים בין האור ובין החשׁך׃ \n",
      "ויקרא אלהים׀ לאור יום ולחשׁך קרא לילה ויהי־ערב ויהי־בקר יום אחד׃ פ \n",
      "\n",
      "text-trans-full\n",
      "B.:-R;>CI73JT B.@R@74> >:ELOHI92JM >;71T HA-C.@MA73JIM W:->;71T H@->@75REY00 \n",
      "W:-H@->@81REY H@J:T@71H TO33HW.03 W@-BO80HW. W:-XO73CEK: <AL&P.:N;74J T:HO92WM W:-R74W.XA >:ELOHI80JM M:RAXE73PET <AL&P.:N;71J HA-M.@75JIM00 \n",
      "WA-J.O71>MER >:ELOHI73JM J:HI74J >O92WR WA45-J:HIJ&>O75WR00 \n",
      "WA-J.A94R:> >:ELOHI91JM >ET&H@->O73WR K.IJ&VO92WB WA-J.AB:D.;74L >:ELOHI80JM B.;71JN H@->O73WR W.-B;71JN HA-XO75CEK:00 \n",
      "WA-J.IQ:R@63> >:ELOHI70JM05 L@-->OWR03 JO80WM W:-LA--XO73CEK: Q@74R@> L@92J:L@H WA45-J:HIJ&<E71REB WA45-J:HIJ&BO73QER JO71WM >EX@75D00_P \n",
      "\n",
      "text-trans-full-ketiv\n",
      "B.:-R;>CI73JT B.@R@74> >:ELOHI92JM >;71T HA-C.@MA73JIM W:->;71T H@->@75REY00 \n",
      "W:-H@->@81REY H@J:T@71H TO33HW.03 W@-BO80HW. W:-XO73CEK: <AL&P.:N;74J T:HO92WM W:-R74W.XA >:ELOHI80JM M:RAXE73PET <AL&P.:N;71J HA-M.@75JIM00 \n",
      "WA-J.O71>MER >:ELOHI73JM J:HI74J >O92WR WA45-J:HIJ&>O75WR00 \n",
      "WA-J.A94R:> >:ELOHI91JM >ET&H@->O73WR K.IJ&VO92WB WA-J.AB:D.;74L >:ELOHI80JM B.;71JN H@->O73WR W.-B;71JN HA-XO75CEK:00 \n",
      "WA-J.IQ:R@63> >:ELOHI70JM05 L@-->OWR03 JO80WM W:-LA--XO73CEK: Q@74R@> L@92J:L@H WA45-J:HIJ&<E71REB WA45-J:HIJ&BO73QER JO71WM >EX@75D00_P \n",
      "\n",
      "text-trans-plain\n",
      "BR>CJT BR> >LHJM >T HCMJM W>T H>RY00 \n",
      "WH>RY HJTH THW WBHW WXCK <L&PNJ THWM WRWX >LHJM MRXPT <L&PNJ HMJM00 \n",
      "WJ>MR >LHJM JHJ >WR WJHJ&>WR00 \n",
      "WJR> >LHJM >T&H>WR KJ&VWB WJBDL >LHJM BJN H>WR WBJN HXCK00 \n",
      "WJQR> >LHJM05 L>WR JWM WLXCK QR> LJLH WJHJ&<RB WJHJ&BQR JWM >XD00_P \n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = collections.defaultdict(list)\n",
    "indent(reset=True)\n",
    "info('writing plain text of whole Bible in all formats')\n",
    "for v in F.otype.s('verse'):\n",
    "    words = L.d(v, 'word')\n",
    "    for fmt in sorted(T.formats):\n",
    "        text[fmt].append(T.text(words, fmt=fmt))\n",
    "info('done {} formats'.format(len(text)))\n",
    "for fmt in sorted(text):\n",
    "    print('{}\\n{}\\n'.format(fmt, '\\n'.join(text[fmt][0:5])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sections and book names\n",
    "Here are the languages that we can use for book names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'am': {'language': 'ኣማርኛ', 'languageEnglish': 'amharic'},\n",
       " 'ar': {'language': 'العَرَبِية', 'languageEnglish': 'arabic'},\n",
       " 'bn': {'language': 'বাংলা', 'languageEnglish': 'bengali'},\n",
       " 'da': {'language': 'Dansk', 'languageEnglish': 'danish'},\n",
       " 'de': {'language': 'Deutsch', 'languageEnglish': 'german'},\n",
       " 'el': {'language': 'Ελληνικά', 'languageEnglish': 'greek'},\n",
       " 'en': {'language': 'English', 'languageEnglish': 'english'},\n",
       " 'es': {'language': 'Español', 'languageEnglish': 'spanish'},\n",
       " 'fa': {'language': 'فارسی', 'languageEnglish': 'farsi'},\n",
       " 'fr': {'language': 'Français', 'languageEnglish': 'french'},\n",
       " 'he': {'language': 'עברית', 'languageEnglish': 'hebrew'},\n",
       " 'hi': {'language': 'हिन्दी', 'languageEnglish': 'hindi'},\n",
       " 'id': {'language': 'Bahasa Indonesia', 'languageEnglish': 'indonesian'},\n",
       " 'ja': {'language': '日本語', 'languageEnglish': 'japanese'},\n",
       " 'ko': {'language': '한국어', 'languageEnglish': 'korean'},\n",
       " 'la': {'language': 'Latina', 'languageEnglish': 'latin'},\n",
       " 'nl': {'language': 'Nederlands', 'languageEnglish': 'dutch'},\n",
       " 'pa': {'language': 'ਪੰਜਾਬੀ', 'languageEnglish': 'punjabi'},\n",
       " 'pt': {'language': 'Português', 'languageEnglish': 'portuguese'},\n",
       " 'ru': {'language': 'Русский', 'languageEnglish': 'russian'},\n",
       " 'sw': {'language': 'Kiswahili', 'languageEnglish': 'swahili'},\n",
       " 'syc': {'language': 'ܠܫܢܐ ܣܘܪܝܝܐ', 'languageEnglish': 'syriac'},\n",
       " 'tr': {'language': 'Türkçe', 'languageEnglish': 'turkish'},\n",
       " 'ur': {'language': 'اُردُو', 'languageEnglish': 'urdu'},\n",
       " 'yo': {'language': 'èdè Yorùbá', 'languageEnglish': 'yoruba'},\n",
       " 'zh': {'language': '中文', 'languageEnglish': 'chinese'}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T.languages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the book names in Swahili."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1367533 = Mwanzo\n",
      "1367534 = Kutoka\n",
      "1367535 = Mambo_ya_Walawi\n",
      "1367536 = Hesabu\n",
      "1367537 = Kumbukumbu_la_Torati\n",
      "1367538 = Yoshua\n",
      "1367539 = Waamuzi\n",
      "1367540 = 1_Samweli\n",
      "1367541 = 2_Samweli\n",
      "1367542 = 1_Wafalme\n",
      "1367543 = 2_Wafalme\n",
      "1367544 = Isaya\n",
      "1367545 = Yeremia\n",
      "1367546 = Ezekieli\n",
      "1367547 = Hosea\n",
      "1367548 = Yoeli\n",
      "1367549 = Amosi\n",
      "1367550 = Obadia\n",
      "1367551 = Yona\n",
      "1367552 = Mika\n",
      "1367553 = Nahumu\n",
      "1367554 = Habakuki\n",
      "1367555 = Sefania\n",
      "1367556 = Hagai\n",
      "1367557 = Zekaria\n",
      "1367558 = Malaki\n",
      "1367559 = Zaburi\n",
      "1367560 = Ayubu\n",
      "1367561 = Mithali\n",
      "1367562 = Ruthi\n",
      "1367563 = Wimbo_Ulio_Bora\n",
      "1367564 = Mhubiri\n",
      "1367565 = Maombolezo\n",
      "1367566 = Esta\n",
      "1367567 = Danieli\n",
      "1367568 = Ezra\n",
      "1367569 = Nehemia\n",
      "1367570 = 1_Mambo_ya_Nyakati\n",
      "1367571 = 2_Mambo_ya_Nyakati\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nodeToSwahili = ''\n",
    "for b in F.otype.s('book'):\n",
    "    nodeToSwahili += '{} = {}\\n'.format(b, T.bookName(b, lang='sw'))\n",
    "print(nodeToSwahili)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, there they are. We copy them into a string, and do the opposite: get the nodes back."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Going from nodes to booknames and back yields the original nodes\n"
     ]
    }
   ],
   "source": [
    "swahiliNames = '''\n",
    "Mwanzo\n",
    "Kutoka\n",
    "Mambo_ya_Walawi\n",
    "Hesabu\n",
    "Kumbukumbu_la_Torati\n",
    "Yoshua\n",
    "Waamuzi\n",
    "1_Samweli\n",
    "2_Samweli\n",
    "1_Wafalme\n",
    "2_Wafalme\n",
    "Isaya\n",
    "Yeremia\n",
    "Ezekieli\n",
    "Hosea\n",
    "Yoeli\n",
    "Amosi\n",
    "Obadia\n",
    "Yona\n",
    "Mika\n",
    "Nahumu\n",
    "Habakuki\n",
    "Sefania\n",
    "Hagai\n",
    "Zekaria\n",
    "Malaki\n",
    "Zaburi\n",
    "Ayubu\n",
    "Mithali\n",
    "Ruthi\n",
    "Wimbo_Ulio_Bora\n",
    "Mhubiri\n",
    "Maombolezo\n",
    "Esta\n",
    "Danieli\n",
    "Ezra\n",
    "Nehemia\n",
    "1_Mambo_ya_Nyakati\n",
    "2_Mambo_ya_Nyakati\n",
    "'''.strip().split()\n",
    "\n",
    "swahiliToNode = ''\n",
    "for nm in swahiliNames:\n",
    "    swahiliToNode += '{} = {}\\n'.format(T.bookNode(nm, lang='sw'), nm)\n",
    "    \n",
    "if swahiliToNode != nodeToSwahili:\n",
    "    print('Something is not right with the book names')\n",
    "else:\n",
    "    print('Going from nodes to booknames and back yields the original nodes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some experiments that get the section that corresponds to a node and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Genesis', '1', '1')\n",
      "1413681\n",
      "1413681\n",
      "1367533\n",
      "1367572\n"
     ]
    }
   ],
   "source": [
    "for x in (\n",
    "    T.sectionFromNode(0, lastSlot=True),\n",
    "    T.nodeFromSection(('Genesis', '1', '1')),\n",
    "    T.nodeFromSection(('Mwanzo', '1', '1'), lang='sw'),\n",
    "    T.nodeFromSection(('Genesis',)),\n",
    "    T.nodeFromSection(('Genesis', '1')),\n",
    "): print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentences spanning multiple verses\n",
    "If you go up from a sentence node, you expect to find a verse node.\n",
    "But some sentences span multiple verses, and in that case, you will not find the enclosing\n",
    "verse node, because it is not there.\n",
    "\n",
    "Here is a piece of code to detect and list all cases where sentences span multiple verses.\n",
    "\n",
    "The idea is to pick the first and the last word of a sentence, use `T.sectionFromNode` to\n",
    "discover the verse in which that word occurs, and if they are different: bingo!\n",
    "\n",
    "We show the first 10 of 915 cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.00s Get sentences that span multiple verses\n",
      "  4.34s Found 915 cases\n",
      "  4.34s \n",
      "Genesis 1:17-18\n",
      "Genesis 1:29-30\n",
      "Genesis 2:4-7\n",
      "Genesis 7:2-3\n",
      "Genesis 7:8-9\n",
      "Genesis 7:13-14\n",
      "Genesis 9:9-10\n",
      "Genesis 10:11-12\n",
      "Genesis 10:13-14\n",
      "Genesis 10:15-18\n"
     ]
    }
   ],
   "source": [
    "indent(reset=True)\n",
    "info('Get sentences that span multiple verses')\n",
    "spanSentences = []\n",
    "for s in F.otype.s('sentence'):\n",
    "    f = T.sectionFromNode(s, lastSlot=False)\n",
    "    l = T.sectionFromNode(s, lastSlot=True)\n",
    "    if f != l:\n",
    "        spanSentences.append('{} {}:{}-{}'.format(f[0], f[1], f[2], l[2]))\n",
    "info('Found {} cases'.format(len(spanSentences)))\n",
    "info('\\n{}'.format('\\n'.join(spanSentences[0:10])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
